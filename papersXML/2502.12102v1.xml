<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Relational Norms for Human-AI Cooperation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
							<email>bdearp@nus.edu.sg</email>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Porsdam Mann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mateo</forename><surname>Aboy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Edmond</forename><surname>Awad</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Monika</forename><surname>Betzler</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marietjie</forename><surname>Botes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rachel</forename><surname>Calcott</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mina</forename><surname>Caraccio</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nick</forename><surname>Chater</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Coeckelbergh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mihaela</forename><surname>Constantinescu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hossein</forename><surname>Dabbagh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kate</forename><surname>Devlin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaojun</forename><surname>Ding</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vilius</forename><surname>Dranseika</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jim</forename><forename type="middle">A C</forename><surname>Everett</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ruiping</forename><surname>Fan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Faisal</forename><surname>Feroz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kathryn</forename><forename type="middle">B</forename><surname>Francis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cindy</forename><surname>Friedman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Orsolya</forename><surname>Friedrich</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Iason</forename><surname>Gabriel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ivar</forename><surname>Hannikainen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Julie</forename><surname>Hellmann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Khodadade</forename><surname>Arasj</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Niranjan</forename><forename type="middle">S</forename><surname>Jahrome</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Janardhanan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Jurcys</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maryam</forename><forename type="middle">Ali</forename><surname>Kappes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gordon</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maximilian</forename><forename type="middle">Kroner</forename><surname>Kraft-Todd</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><forename type="middle">M</forename><surname>Dale</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Laham</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Muriel</forename><surname>Lange</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Leuenberger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Lewis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matthijs</forename><surname>Lyreskog</surname></persName>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Maas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Emilian</forename><surname>Mcmillan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Timo</forename><surname>Mihailov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joshua</forename><forename type="middle">Teperowski</forename><surname>Minssen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kathryn</forename><surname>Monrad</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><surname>Muyskens</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sven</forename><surname>Myers</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alexa</forename><forename type="middle">M</forename><surname>Nyholm</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anna</forename><surname>Owen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Puzio</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Madeline</forename><forename type="middle">G</forename><surname>Register</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Adam</forename><surname>Reinecke</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Henry</forename><surname>Safron</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hayate</forename><surname>Shevlin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Shimizu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cristina</forename><surname>Treit</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Karen</forename><surname>Voinea</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anda</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Renwen</forename><surname>Zahiu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hazem</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Walter</forename><surname>Zohny</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ilina</forename><surname>Sinnott-Armstrong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Julian</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Margaret</forename><forename type="middle">S</forename><surname>Savulescu+</surname></persName>
						</author>
						<author>
							<persName><surname>Clark</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><forename type="middle">Porsdam</forename><surname>Mann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pau-Stanford</forename><forename type="middle">D</forename><surname>Psy</surname></persName>
						</author>
						<author>
							<persName><surname>Consortium</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Niranjan</forename><forename type="middle">S</forename><surname>Janardhanan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Kappes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maryam</forename><forename type="middle">Ali</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gordon</forename><surname>Kraft-Todd</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><forename type="middle">M</forename><surname>Laham</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><roleName>NEUROSEC</roleName><forename type="first">David</forename><forename type="middle">M</forename><surname>Lyreskog</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matthijs</forename><surname>Maas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Mcmillan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Emilian</forename><surname>Mihailov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Timo</forename><surname>Minssen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kathryn</forename><surname>Muyskens</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><surname>Myers</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sven</forename><surname>Nyholm</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alexa</forename><surname>Owen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anna</forename><surname>Puzio</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Register</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Madeline</forename><forename type="middle">G</forename><surname>Reinecke</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Adam</forename><surname>Safron</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Treit</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cristina</forename><surname>Voinea</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Karen</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anda</forename><surname>Zahiu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Renwen</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Walter</forename><surname>Sinnott-Armstrong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Julian</forename><surname>Savulescu</surname></persName>
							<email>jsavules@nus.edu.sg</email>
						</author>
						<author>
							<persName><forename type="first">Margaret</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Centre for Biomedical Ethics</orgName>
								<orgName type="institution" key="instit1">Yong Loo Lin School of Medicine</orgName>
								<orgName type="institution" key="instit2">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Uehiro Oxford Institute</orgName>
								<orgName type="institution" key="instit2">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Center for Advanced Studies in Bioscience Innovation Law (CeBIL)</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Faculty of Law</orgName>
								<orgName type="department" key="dep2">Faculty of Law</orgName>
								<orgName type="department" key="dep3">Centre for Biomedical Ethics</orgName>
								<orgName type="institution" key="instit1">University of Copenhagen</orgName>
								<orgName type="institution" key="instit2">University of Oxford</orgName>
								<orgName type="institution" key="instit3">Yong Loo Lin School of Medicine</orgName>
								<orgName type="institution" key="instit4">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Centre for Law, Medicine and Life Sciences and Center of Intellectual Property and Information Law</orgName>
								<orgName type="department" key="dep2">Faculty of Law</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Department of Economics</orgName>
								<orgName type="institution" key="instit1">Uehiro Oxford Institute</orgName>
								<orgName type="institution" key="instit2">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department" key="dep1">Center for Humans and Machines</orgName>
								<orgName type="department" key="dep2">Max-Planck Institute for Human Development</orgName>
								<orgName type="institution">University of Exeter</orgName>
								<address>
									<country>UK, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department" key="dep1">Faculty of Philosophy</orgName>
								<orgName type="department" key="dep2">School of Law</orgName>
								<orgName type="department" key="dep3">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">Monika Betzler</orgName>
								<orgName type="institution" key="instit2">Ludwigs-Maximilian-Universität München Marietjie Botes</orgName>
								<orgName type="institution" key="instit3">University of KwaZulu Natal</orgName>
								<address>
									<settlement>Calcott</settlement>
									<country>South Africa Rachel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">Harvard University</orgName>
								<address>
									<region>US</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">Warwick Business School</orgName>
								<orgName type="institution" key="instit1">US Nick Chater</orgName>
								<orgName type="institution" key="instit2">Behavioural Science Group</orgName>
								<orgName type="institution" key="instit3">University of Warwick</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department">Department of Philosophy</orgName>
								<orgName type="institution">University of Vienna</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<orgName type="department">Faculty of Philosophy</orgName>
								<orgName type="laboratory">Research Centre in Applied Ethics</orgName>
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff12">
								<orgName type="department" key="dep1">Department of Philosophy</orgName>
								<orgName type="department" key="dep2">Oxford Department for Continuing Education</orgName>
								<orgName type="institution" key="instit1">Hossein Dabbagh</orgName>
								<orgName type="institution" key="instit2">Northeastern University London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff13">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff14">
								<orgName type="department">Department of Philosophy</orgName>
								<orgName type="institution" key="instit1">Xiaojun Ding</orgName>
								<orgName type="institution" key="instit2">Xi&apos;an Jiaotong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff15">
								<orgName type="department" key="dep1">Vilius Dranseika</orgName>
								<orgName type="department" key="dep2">Interdisciplinary Centre for Ethics</orgName>
								<orgName type="institution">Jagiellonian University</orgName>
								<address>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff16">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">University of Kent</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff17">
								<orgName type="department" key="dep1">Department of Public and International Affairs</orgName>
								<orgName type="department" key="dep2">Centre for Biomedical Ethics</orgName>
								<orgName type="institution" key="instit1">City University of Hong Kong Faisal Feroz</orgName>
								<orgName type="institution" key="instit2">Yong Loo Lin School of Medicine</orgName>
								<orgName type="institution" key="instit3">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff18">
								<orgName type="department" key="dep1">School of Psychology</orgName>
								<orgName type="department" key="dep2">Faculty of Medicine and Health</orgName>
								<orgName type="department" key="dep3">Ethics Institute</orgName>
								<orgName type="institution">University of Leeds</orgName>
								<address>
									<settlement>Cindy Friedman</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff19">
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff20">
								<orgName type="department" key="dep1">Institute of Philosophy</orgName>
								<orgName type="department" key="dep2">FernUniversität in Hagen</orgName>
								<orgName type="institution">Iason Gabriel</orgName>
								<address>
									<settlement>Google Deepmind</settlement>
									<country>Germany, UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff21">
								<orgName type="department">Department of Philosophy</orgName>
								<orgName type="institution">University of Granada</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff22">
								<orgName type="department">Independent Researcher</orgName>
								<orgName type="institution">Julie Hellmann</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff23">
								<orgName type="department">Independent Researcher</orgName>
								<orgName type="institution">Arasj Khodadade Jahrome</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff24">
								<orgName type="department" key="dep1">Department of Management</orgName>
								<orgName type="department" key="dep2">London School of Economics and Political Science</orgName>
								<orgName type="institution">Vilnius University Law Faculty</orgName>
								<address>
									<settlement>Paul Jurcys, Vilnius</settlement>
									<country>UK, Lithuania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff25">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">School of Health and Psychological Sciences</orgName>
								<orgName type="institution">University of London</orgName>
								<address>
									<settlement>City</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff26">
								<orgName type="institution" key="instit1">Uehiro Oxford Institute</orgName>
								<orgName type="institution" key="instit2">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff27">
								<orgName type="institution" key="instit1">Maximilian Kroner Dale</orgName>
								<orgName type="institution" key="instit2">Oxford Internet Institute</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff28">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Melbourne School of Psychological Sciences</orgName>
								<orgName type="department" key="dep3">Faculty of Philosophy</orgName>
								<orgName type="department" key="dep4">Philosophy of Science and Religious Studies</orgName>
								<orgName type="department" key="dep5">Munich Center for Machine Learning (MCML)</orgName>
								<orgName type="institution">Ludwigs-Maximilian-Universität München</orgName>
								<address>
									<settlement>Benjamin Lange</settlement>
									<country>Australia, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff29">
								<orgName type="department" key="dep1">Digital Society Initiative</orgName>
								<orgName type="department" key="dep2">Department of Philosophy</orgName>
								<orgName type="institution" key="instit1">Muriel Leuenberger</orgName>
								<orgName type="institution" key="instit2">University of Zurich</orgName>
								<address>
									<region>CH</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff30">
								<orgName type="department">Centre for Biomedical Ethics</orgName>
								<orgName type="institution" key="instit1">Jonathan Lewis</orgName>
								<orgName type="institution" key="instit2">Yong Loo Lin School of Medicine</orgName>
								<orgName type="institution" key="instit3">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff31">
								<orgName type="department">Center for Psychological Sciences</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff32">
								<orgName type="department">Department of Psychiatry</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff33">
								<orgName type="laboratory">Leverhulme Centre for the Future of Intelligence</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff34">
								<orgName type="department">Bioethics Centre</orgName>
								<orgName type="institution">University of Otago</orgName>
								<address>
									<country key="NZ">New Zealand</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff35">
								<orgName type="department">Faculty of Philosophy</orgName>
								<orgName type="laboratory">Research Centre in Applied Ethics</orgName>
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff36">
								<orgName type="department" key="dep1">Center for Advanced Studies in Bioscience Innovation Law (CeBIL)</orgName>
								<orgName type="department" key="dep2">Faculty of Law</orgName>
								<orgName type="department" key="dep3">Faculty of Law</orgName>
								<orgName type="department" key="dep4">Inter-CeBIL Research Affiliate</orgName>
								<orgName type="institution" key="instit1">University of Copenhagen</orgName>
								<orgName type="institution" key="instit2">University of Copenhagen</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff37">
								<orgName type="department" key="dep1">Flom Center for Health Law Policy, Biotechnology, and Bioethics at Harvard Law School &amp; Centre for Law, Medicine and Life Sciences</orgName>
								<orgName type="department" key="dep2">Faculty of Law</orgName>
								<orgName type="institution" key="instit1">The Petrie</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff38">
								<orgName type="institution">Joshua Teperowski Monrad</orgName>
								<address>
									<settlement>Sentinel Bio</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff39">
								<orgName type="department">Centre for Biomedical Ethics</orgName>
								<orgName type="institution" key="instit1">Yong Loo Lin School of Medicine</orgName>
								<orgName type="institution" key="instit2">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff40">
								<orgName type="department">Warwick Business School</orgName>
								<orgName type="institution" key="instit1">Behavioural Science Group</orgName>
								<orgName type="institution" key="instit2">University of Warwick</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff41">
								<orgName type="department" key="dep1">Faculty of Philosophy</orgName>
								<orgName type="department" key="dep2">Philosophy of Science and Religious Studies</orgName>
								<orgName type="department" key="dep3">Munich Center for Machine Learning (MCML)</orgName>
								<orgName type="institution">Ludwigs-Maximilian-Universität München</orgName>
								<address>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff42">
								<orgName type="department">Smith College School for Social Work</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff43">
								<orgName type="department" key="dep1">Ethics of Socially Disruptive Technologies Programme</orgName>
								<orgName type="department" key="dep2">Faculty of Behavioural, Management and Social Sciences (BMS)</orgName>
								<orgName type="department" key="dep3">Philosophy (WIJSB)</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff44">
								<orgName type="institution" key="instit1">Uehiro Oxford Institute</orgName>
								<orgName type="institution" key="instit2">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff45">
								<orgName type="department">Department of Psychiatry</orgName>
								<orgName type="institution" key="instit1">Uehiro Oxford Institute</orgName>
								<orgName type="institution" key="instit2">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff46">
								<orgName type="department" key="dep1">Allen Discovery Center</orgName>
								<orgName type="department" key="dep2">Department of Philosophy</orgName>
								<orgName type="department" key="dep3">Graduate School of Humanities and Human Sciences</orgName>
								<orgName type="institution" key="instit1">Tufts University, US &amp; SapiensAI</orgName>
								<orgName type="institution" key="instit2">US Henry Shevlin</orgName>
								<orgName type="institution" key="instit3">University of Cambridge</orgName>
								<address>
									<settlement>Hayate Shimizu</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff47">
								<orgName type="institution">Hokkaido University</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff48">
								<orgName type="department" key="dep1">Max Planck Institute for Biochemistry</orgName>
								<orgName type="department" key="dep2">Department of Proteomics and Signal Transduction</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff49">
								<orgName type="institution" key="instit1">Uehiro Oxford Institute</orgName>
								<orgName type="institution" key="instit2">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff50">
								<orgName type="department">College of Humanities, Arts, and Social Sciences</orgName>
								<orgName type="institution">National Yang Ming Chiao Tung University</orgName>
								<address>
									<settlement>Taipei</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff51">
								<orgName type="department">Research Centre in Applied Ethics</orgName>
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff52">
								<orgName type="department">Department of Communications and New Media</orgName>
								<orgName type="institution" key="instit1">National University of Singapore Hazem Zohny</orgName>
								<orgName type="institution" key="instit2">Uehiro Oxford Institute</orgName>
								<orgName type="institution" key="instit3">University of Oxford</orgName>
								<address>
									<country key="GB">England</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff53">
								<orgName type="department" key="dep1">Department of Philosophy</orgName>
								<orgName type="department" key="dep2">Department of Psychiatry</orgName>
								<orgName type="institution" key="instit1">Kenan Institute for Ethics</orgName>
								<orgName type="institution" key="instit2">Duke University</orgName>
								<address>
									<settlement>Ilina Singh</settlement>
									<country>US</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff54">
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff55">
								<orgName type="department">Centre for Biomedical Ethics</orgName>
								<orgName type="institution" key="instit1">Yong Loo Lin School of Medicine</orgName>
								<orgName type="institution" key="instit2">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff56">
								<orgName type="laboratory">Biomedical Ethics Research Group</orgName>
								<orgName type="institution" key="instit1">Uehiro Oxford Institute</orgName>
								<orgName type="institution" key="instit2">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff57">
								<orgName type="department">Melbourne Law School</orgName>
								<orgName type="institution">Murdoch Children&apos;s Research Institute</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff58">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff59">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Relational Norms for Human-AI Cooperation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C3D5E8504C294D4B62DA26354F38CCA9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-03-04T12:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>How we should design and interact with so-called "social" artificial intelligence (AI) depends, in part, on the socio-relational role the AI serves to emulate or occupy. In human society, different types of social relationship exist (e.g., teacher-student, parent-child, neighbors, siblings, and so on) and are associated with distinct sets of prescribed (or proscribed) cooperative functions, including hierarchy, care, transaction, and mating. These relationship-specific patterns of prescription and proscription (i.e., "relational norms") shape our judgments of what is appropriate or inappropriate for each partner within that relationship. Thus, what is considered ethical, trustworthy, or cooperative within one relational context, such as between friends or romantic partners, may not be considered as such within another relational context, such as between strangers, housemates, or work colleagues. Moreover, what is appropriate for one partner within a relationship, such as a boss giving orders to their employee, may not be appropriate for the other relationship partner (i.e., the employee giving orders to their boss) due to the relational norm(s) associated with that dyad in the relevant context (here, hierarchy and transaction in a workplace context). Now that artificially intelligent "agents" and chatbots powered by large language models (LLMs), are increasingly being designed and used to fill certain social roles and relationships that are analogous to those found in human societies (e.g., AI assistant, AI mental health provider, AI tutor, AI "girlfriend" or "boyfriend"), it is imperative to determine whether or how human-human relational norms will, or should, be applied to human-AI relationships. Here, we systematically examine how AI systems' characteristics that differ from those of humans, such as their likely lack of conscious experience and immunity to fatigue, may affect their ability to fulfill relationship-specific cooperative functions, as well as their ability to (appear to) adhere to corresponding relational norms. We also highlight the "layered" nature of human-AI relationships, wherein a third party (the AI provider) mediates and shapes the interaction. This analysis, which is a collaborative effort by philosophers, psychologists, relationship scientists, ethicists, legal experts, and AI researchers, carries important implications for AI systems design, user behavior, and regulation. While we accept that AI systems can offer significant benefits such as increased availability and consistency in certain socio-relational roles, they also risk fostering unhealthy dependencies or unrealistic expectations that could spill over into human-human relationships. We propose that understanding and thoughtfully shaping (or implementing) suitable human-AI relational norms-for a wide range of relationship types-will be crucial for ensuring that human-AI interactions are ethical, trustworthy, and favorable to human well-being.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Much recent discussion of the moral psychology and ethics of artificial intelligence (AI) has focused on identifying or forecasting morally relevant properties of AI: for example, asking whether AI may develop the capacity for sentience or agency; if so, how this should affect our treatment of AI; what risks it may bring, and so on <ref type="bibr" target="#b102">(Gibert &amp; Martin, 2021;</ref><ref type="bibr" target="#b20">Birch, 2024)</ref>. However, it is increasingly recognized that how we (should) interact with AI systems depends not only on the intrinsic properties of such systems, or what we believe these to be <ref type="bibr" target="#b52">(Danaher, 2020)</ref>, but also on the practical and social aims we have in engaging with AIwhere these aims, in turn, often depend upon the context <ref type="bibr" target="#b135">(Kasirzadeh &amp; Gabriel, 2023;</ref><ref type="bibr" target="#b216">Puzio, 2024)</ref>. For example, what constitutes appropriate use of an AI system in a business context, characterized by one set of cooperative aims, may differ significantly from what constitutes appropriate use of AI in an educational context, characterized by a different set of cooperative aims.</p><p>In addition to considering the institutional context of human-AI interactions (e.g., business, education, and so on), it is important also to consider the socio-relational context, as this can transcend particular institutions. Socio-relational context can be defined in various ways. For example, it can be used to differentiate interactions occurring between members of an ingroup versus members of an outgroup <ref type="bibr">(Terry &amp; Hogg, 1999;</ref><ref type="bibr" target="#b117">Hester &amp; Gray, 2020)</ref>.</p><p>In this paper, we use the term to refer to the specific type of social relationship(s) that exists between two interaction partners as well as the role(s) that each party occupies within said relationship <ref type="bibr" target="#b33">(Clark et al., 2015)</ref>. The social relationships we have in mind are common dyadic pairs picked out by lay language categories, such as caregiver-patient, teacherstudent, two friends, two work teammates, and so on. In other words, we are interested in a source of socio-relational variance that often shapes cooperative dynamics even when both parties are of the same group. To illustrate, how it is appropriate to interact with one's boss, whether inside or outside of the workplace, may differ from how it is appropriate to interact with one's child or spouse, notwithstanding shared group membership (e.g., fellow citizens of a given social class or ethnicity).</p><p>Consideration of such dyadic relational context is necessary, we suggest, because AI-based conversational systems, in addition to being able to perform specific tasks such as answering factual questions or writing lines of code, can now engage in complex and realistic social roleplay with humans (as well as with other AI systems), both spontaneously and as a result of deliberate prompting or programming <ref type="bibr" target="#b204">(Park et al., 2023;</ref><ref type="bibr" target="#b241">Shanahan, McDonell and Reynolds, 2023)</ref>. The extent and sophistication of this social roleplay ability, including mimicking specific relationship types, is unprecedented in in a nonhuman entity.</p><p>The purpose of this paper is to offer a unified theoretical framework for understanding social role-dependent cooperative interactions between humans and conversational AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relationships as social context</head><p>Encounters with "social" AI happen against a backdrop of pre-existing social and relational norms which shape our use and expectations of this technology <ref type="bibr" target="#b41">(Coeckelbergh, 2014;</ref><ref type="bibr" target="#b273">Van Wynsberghe, 2022;</ref><ref type="bibr" target="#b244">Shevlin, 2024)</ref>. When we converse with virtual assistants or interact with service robots, for instance, we (sometimes consciously and sometimes unconsciously) apply familiar social scripts derived from human-human relationships, such as norms of politeness (see <ref type="bibr" target="#b161">Lumer &amp; Buschmeier, 2023)</ref>, turn-taking, and conversational relevance, as we navigate and make sense of these interactions. However, the specific type of relationship we have with an AI will often influence which norms are applied. Consider the following exchange:</p><p>Human: I'm feeling incredibly lonely and depressed. I'm really not sure what to do anymore. I don't have anyone I can talk to.</p><p>Chatbot: I'm sorry, but we are going to have to change the topic. I won't be able to engage in a conversation about your personal life. I recommend that you investigate other resources for addressing your emotional concerns.</p><p>How should we judge the chatbot's response in this case? Is it cruel and uncaring? Appropriately professional <ref type="bibr" target="#b152">(Leibo et al., 2024)</ref>? How can we determine the answer? And how is the human user likely to feel about receiving such a response? How might it affect their subsequent behavior?</p><p>Although many factors will be relevant to answering such questions, an important one, we suggest, is information about the socio-relational role (or associated cooperative functions; see below) the chatbot has been designed, or is being used, to fulfill. If the chatbot is serving in the role of a mental health screener as part of a wellness app, for instance, the response will seem out of line, possibly reflective of a programming error or an incoherent design choice. The user, in turn, might feel surprised, frustrated, or angry, and might contact customer support to complain.</p><p>If the chatbot is in the role of a math tutor, sales agent, or financial advisor, by contrast, the response might seem more pertinent. Rather than being a sign of something gone wrong, it might instead seem to reflect a well-considered guardrail to keep the discussion focused and to maintain clarity about the purpose and boundaries of the interaction. The user, in this example, might still feel frustrated about the chatbot's unwillingness to pursue a certain line of conversation, but this outcome would likely be easier to understand and accept. Perhaps the user would even feel embarrassed for "oversharing" or for having gone to the wrong source for support.</p><p>With this brief illustration, we stress the theme of our article, which is the need to study, understand, and develop appropriate norms for human-AI interactions, not only in general (e.g., norms of politeness, truthfulness, turn-taking), but also within the context of more specific socio-functional roles and types of human-AI relationships (e.g., caregiver-patient, teacher-student, supervisor-assistant, and so on) (see <ref type="bibr" target="#b224">Reinecke, Kappes et al., 2025)</ref>.</p><p>To begin to address this need, we draw on the Relational Norms model recently introduced by Earp and colleagues <ref type="bibr" target="#b39">(Clark, Earp, &amp; Crockett, 2020;</ref><ref type="bibr" target="#b72">Earp, 2021;</ref><ref type="bibr" target="#b76">Earp et al., 2021;</ref><ref type="bibr" target="#b77">Earp et al., 2025)</ref>. This model builds on prior models of relational norms (primarily <ref type="bibr" target="#b22">Bugental, 2000</ref><ref type="bibr" target="#b34">, and Clark &amp; Mills, 1979</ref><ref type="bibr">and 2012</ref>; see also <ref type="bibr" target="#b90">Fiske, 1992;</ref><ref type="bibr" target="#b218">Rai &amp; Fiske, 2011)</ref> and was developed to theorize and measure relationship-specific cooperative norms, as characterized below, for human-human relationships. Here, we explore whether and how these norms might be expected, in practice, to "carry over" to the human-AI analogues of such relationships <ref type="bibr" target="#b108">(Guingrich &amp; Graziano, 2024)</ref>, particularly given differences between humans and AI. We also consider the ethical and regulatory implications of such potential carry-over (or lack thereof), since research suggests that how we choose to frame and relate to AI systems can significantly shape relevant law and policy <ref type="bibr" target="#b162">(Maas, 2023</ref>).<ref type="foot" target="#foot_0">1</ref> </p><p>The need for a theoretical, empirical, and ethical investigation of relational norms for human-AI cooperation stems from fast-moving developments. Since the 2022 release of OpenAI's ChatGPT-a chat interface for a general-purpose LLM trained on vast quantities of data pulled from the internet-LLMs equipped with similar conversational interfaces have increasingly been used to perform a wide range of functions associated with particular social or relational roles traditionally filled by humans <ref type="bibr">(Bubeck et al., 2023;</ref><ref type="bibr">Porsdam Mann et al., 2023;</ref><ref type="bibr" target="#b74">Earp, Calcott et al., 2024;</ref><ref type="bibr" target="#b245">Shevlin, 2025)</ref>. These range from relatively narrow, circumscribed roles such as assistant, medical scribe, gaming opponent, tutor, or work teammate, to broader roles such as life coach, moral advisor, role model, friend, companion <ref type="bibr" target="#b141">(Köbis et al., 2021)</ref>, or even-for some users-romantic partner <ref type="bibr" target="#b203">(Pan &amp; Mou, 2024)</ref>. Furthermore, human-AI communication can exhibit a sense of continuity, with in-depth dialogue, personalized responses, and repeated interactions over time, creating the feeling of an extended "relationship" <ref type="bibr" target="#b98">(Gambino, Fox, &amp; Ratan, 2020)</ref>.</p><p>In short, LLM-powered chatbots not only generate broadly human-like responses to relevant prompts from users; they also, increasingly, can convincingly emulate specific human social roles or relationship types. Some of these simulations have the potential to benefit users by helping them meet various personal or professional needs <ref type="bibr" target="#b60">(De Freitas et al., 2024)</ref>. However, the potential harms of such systems for individuals and societies <ref type="bibr" target="#b2">(Akbulut et al., 2024;</ref><ref type="bibr" target="#b163">Maeda &amp; Quan-Haase, 2024)</ref> have not yet been systematically studied (e.g., <ref type="bibr" target="#b282">Zimmerman, Janhonen &amp; Beer, 2023;</ref><ref type="bibr">Zhang et al., 2024)</ref>. In addition to the sheer novelty of the phenomenon to be investigated (namely, the increasing sophistication and availability of LLM-based human social role mimicry), this relative lack of systematic risk-evaluation across human-AI relationship types signals the need for an overarching framework that can adequately motivate and structure such an inquiry.</p><p>How, then, should AI systems behave in these simulated relationship contexts (and how should humans behave in return)? How will humans make sense of, feel about, and respond to such behavior? Understanding both empirical and ethical aspects of human-AI interactions-specifically, as a function of differing socio-relational roles-will be essential for informing policy, design, and regulation of social AI going forward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The need for a comprehensive approach</head><p>We are not the first to argue that studies of human-AI interaction must take relational context into account. However, analyses thus far have proceeded mostly in a piecemeal fashion, drawing on different theoretical or values-based approaches and typically focusing on one type of relational role at a time: for example, AI assistant <ref type="bibr" target="#b97">(Gabriel et al., 2024;</ref><ref type="bibr" target="#b167">Manzini et al., 2024)</ref>, AI customer service agent <ref type="bibr" target="#b156">(Leocádio et al., 2024)</ref>; AI financial advisor <ref type="bibr" target="#b142">(Kofman, 2024)</ref>; AI judge <ref type="bibr" target="#b42">(Constantinescu, 2025)</ref>; AI mental health provider <ref type="bibr" target="#b91">(Fiske, Henningsen, &amp; Buyx, 2019;</ref><ref type="bibr" target="#b235">Saeidnia et al., 2024;</ref><ref type="bibr">Tavery, 2024)</ref>, AI moral guide or 'guru' <ref type="bibr" target="#b103">(Giubilini &amp; Savulescu, 2018;</ref><ref type="bibr" target="#b43">Constantinescu et al., 2022;</ref><ref type="bibr" target="#b103">Giubilini et al., 2024;</ref><ref type="bibr" target="#b188">Myers &amp; Everett, 2025)</ref>, AI nanny <ref type="bibr" target="#b107">(Guérin et al. 2025;</ref><ref type="bibr" target="#b95">Fosch-Villaronga et al. 2023)</ref>, AI friend <ref type="bibr" target="#b51">(Danaher, 2019;</ref><ref type="bibr" target="#b9">Archer, 2021;</ref><ref type="bibr" target="#b232">Ryland, 2021;</ref><ref type="bibr" target="#b24">Brandtzaeg et al., 2022;</ref><ref type="bibr">Nunn &amp; Weijers, 2023)</ref>, or AI "girlfriend" or "boyfriend" <ref type="bibr" target="#b31">(Cheok, Karunanayaka, &amp; Zhang, 2017;</ref><ref type="bibr">Depounti, Saukko, &amp; Natalie, 2022;</ref><ref type="bibr" target="#b159">Lin, 2024)</ref>.</p><p>In contrast, we suggest that a comprehensive theoretical framework regarding the nature of cooperative relationships is required to assess the full range of socio-relational roles that AI systems are being designed and used to emulate or occupy. Such a framework should enable us to explain and predict underlying processes shaping human-AI interactions that will vary by relationship type, and to anticipate ethical challenges posed by AI systems that will also vary by relationship type.</p><p>There have been a range of attempts to develop frameworks for understanding and fostering ethical human-AI relationships. For example, one proposed framework for studying 'cooperative AI' has drawn on research into "multi-agent systems, game theory and social choice, human-machine interaction and alignment, natural-language processing, and the construction of social tools and platforms" <ref type="bibr">(Dafoe et al. 2020, abstract</ref>; see also <ref type="bibr" target="#b49">Dafoe et al., 2021)</ref>. However, this work focuses primarily on cooperative interactions between humans and AI-simulated agents in general: that is, irrespective of the particular relational role that each party occupies.</p><p>Taking a different approach, the previously mentioned Relational Norms model of Earp and colleagues <ref type="bibr" target="#b39">(Clark, Earp, &amp; Crockett, 2020;</ref><ref type="bibr" target="#b72">Earp, 2021;</ref><ref type="bibr" target="#b76">Earp et al., 2021;</ref><ref type="bibr">based primarily on Bugental, 2000</ref><ref type="bibr" target="#b34">, and Clark &amp; Mills, 1979</ref><ref type="bibr" target="#b58">, 2012;</ref><ref type="bibr">refined in Earp et al., 2025)</ref>, builds on prior theoretical and empirical work 2 to show how and why different social relationships shape our behavioral tendencies, cooperative expectations, moral judgments, and judgments of appropriateness or inappropriateness <ref type="bibr" target="#b152">(Leibo et al., 2024)</ref>, in particular relational contexts (see Section 1 for details). This is crucial because, as we will argue, different relationship types are associated with different kinds of coordination problems (see <ref type="bibr" target="#b45">Curry, 2016)</ref>. What counts as "cooperative" behavior therefore often depends on the nature of existing or desired relationship between the parties as well as each party's role within it <ref type="bibr" target="#b33">(Clark et al., 2015;</ref><ref type="bibr" target="#b39">Clark, Earp, &amp; Crockett, 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wrapping up preliminaries and looking ahead</head><p>Social AI is trained on linguistic data generated in part through (and/or including information about) a huge volume of human cooperative 3 interactions. Role-specific AI systems or models will thus inevitably learn from, and potentially influence or exploit, the relationshiprelative cooperative norms (i.e., relational norms) embedded in such data. Accordingly, a natural starting point for our investigation is to employ an existing framework for understanding and describing such human-human relational norms, and then to map out the most salient or consequential similarities and differences that pertain to analogous human-2 Primarily <ref type="bibr" target="#b22">Bugental (2000)</ref> and <ref type="bibr" target="#b34">Clark and Mills (1979;</ref><ref type="bibr" target="#b58">2012)</ref>, as noted, but also related to <ref type="bibr" target="#b90">Fiske (1992;</ref><ref type="bibr"></ref> see also <ref type="bibr" target="#b115">Haslam &amp;</ref><ref type="bibr" target="#b90">Fiske, 1992 and</ref><ref type="bibr" target="#b218">Rai &amp;</ref><ref type="bibr" target="#b218">Fiske, 2011)</ref>; as well as <ref type="bibr" target="#b113">Hamilton and Sanders (1981)</ref>, <ref type="bibr" target="#b112">Haidt and Baron (1996;</ref><ref type="bibr"></ref> see also <ref type="bibr" target="#b106">Graham, Haidt, et al., 2013)</ref>, <ref type="bibr">Shweder and colleagues (2013)</ref>, and Curry (2016; see also <ref type="bibr" target="#b46">Curry, Mullins &amp; Whitehouse, 2019)</ref>.</p><p>3 And undoubtedly also non-cooperative (e.g., competitive, exploitative) behavior. Although we are primarily focused on cooperative behavior in this article, we also touch on ways that relational norms can be misused or exploited to take advantage of others in ways that are distinctive to certain types of relationships. Thus, we argue, not only cooperation but also non-cooperation (e.g., what counts as such, what the relevant effects are) often depends on the relational context.</p><p>AI relationships (see <ref type="bibr" target="#b74">Earp, Calcott et al., 2024;</ref><ref type="bibr" target="#b224">Reinecke, Kappes et al., 2025;</ref><ref type="bibr">Kappes et al., in press)</ref>.</p><p>In this paper, therefore, we adapt the Relational Norms model to human-AI interactions. Descriptively, we seek to understand how, or to what extent, people are likely to apply existing, human-human relational norms-as defined within the Relational Norms framework-to interactions with AI systems that have been designed, are being used, or are otherwise perceived to emulate specific social-relational roles. For example, will they find it intuitive to "comfort" an AI friend that is simulating sadness, but awkward to comfort an AI supervisor or teacher? Or will they find it odd to "comfort" even the AI friend, perhaps believing the AI does not truly feel sad (see <ref type="bibr" target="#b3">Allen &amp; Caviola, 2025</ref>, for related work)? We make some high-level predictions in this paper based on existing theory and data; a related empirical research program into such questions is described elsewhere <ref type="bibr" target="#b224">(Reinecke, Kappes et al., 2025)</ref>.</p><p>Prescriptively, we aim to evaluate how AI systems should be designed, governed, and regulated to maximize benefits and minimize harms, given a range of possibilities for how our theoretical predictions, based on the Relational Norms model, could turn out. Importantly, however, our substantive ethical suggestions do not simply "fall out" of the Relational Norms model. Although in using the model we seek to explain why certain relational norms have arisen in human societies (while also acknowledging cultural variation in how the norms apply between societies), and to show how these norms influence our cooperative expectations and associated moral judgments (for example, when our relationship-specific cooperative expectations are violated), it does not say whether these norms, as implemented in a particular society, are necessarily desirable or whether certain moral judgments are correct.</p><p>In other words, it is a descriptive model of a set of prescriptive cooperative expectations that people do in fact have for different relationship types; it is not itself a prescriptive ethical theory. Accordingly, when making ethical recommendations in our own voice, we will draw on a range of common normative assumptions (for example, about potential benefits and harms of various policy options) that we expect will be shared by most readers. In so doing, we will try to keep the descriptive (empirical-explanatory) and normative (ethicalprescriptive) aspects of our analysis clearly distinguished. Nevertheless, as will be evident, our ethical and policy recommendations are systematically informed by the Relational Norms model.</p><p>We consider AI systems that explicitly emulate one or more human social-relational roles, encompassing both embodied robots and disembodied AI such as large language models. While the presence or absence of a physical body can significantly impact interpersonal dynamics (e.g., <ref type="bibr" target="#b150">Lee et al., 2006;</ref><ref type="bibr" target="#b62">Deng, Mutlu, &amp; Mataric, 2019)</ref>, our framework focuses on the roles these systems occupy in human interactions, regardless of physical manifestation.</p><p>Finally, despite our focus on dyadic relationships as in the original Relational Norms model-or as adapted here, on two-way interactions between one human and one AI system-we acknowledge that relational norms can apply to one-many relationships, for example, between an individual and a group <ref type="bibr" target="#b76">(Earp et al., 2021</ref>; see also, e.g., <ref type="bibr" target="#b68">Dranseika et al. 2018)</ref>. We also consider the fact that most AI systems, regardless of their emulated relational role, ultimately mediate a background relationship between the human user and the AI company or developer (see the subsection on "layered relationships" below).</p><p>We begin with an overview of the Relational Norms model as originally developed and applied to the study of human-human relationships (primarily in <ref type="bibr" target="#b76">Earp et al., 2021</ref>, with significant model updates as described in <ref type="bibr" target="#b77">Earp et al., 2025</ref>, the latter of which we rely on for this paper). We then explore how this model might be extended to human-AI interactions, focusing on the similarities and differences between human and artificial agents in their capacities to engage in cooperative relationships of various types. Next, we examine some of the unique challenges and opportunities that AI systems present in relational context. Finally, we consider the broader implications of our analysis for the design and governance of AI systems and identify key directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Section 1: The Relational Norms Model</head><p>Building on the work of previous theorists as noted in the introduction (primarily <ref type="bibr" target="#b22">Bugental, 2000</ref><ref type="bibr" target="#b34">, and Clark &amp; Mills, 1979</ref><ref type="bibr" target="#b58">, 2012</ref>; but also related to <ref type="bibr" target="#b113">Hamilton &amp; Sanders, 1981;</ref><ref type="bibr" target="#b90">Fiske, 1992;</ref><ref type="bibr" target="#b115">Haslam &amp; Fiske, 1992;</ref><ref type="bibr" target="#b112">Haidt &amp; Baron, 1996;</ref><ref type="bibr" target="#b218">Rai &amp; Fiske, 2011</ref><ref type="bibr" target="#b106">, Graham et al., 2013</ref><ref type="bibr">, Shweder et al., 2013;</ref><ref type="bibr" target="#b45">Curry, 2016;</ref><ref type="bibr" target="#b46">Curry, Mullins &amp; Whitehouse, 2019)</ref>, Earp and colleagues recently proposed a Relational Norms model of human moral psychology <ref type="bibr" target="#b39">(Clark, Earp, &amp; Crockett, 2020;</ref><ref type="bibr" target="#b72">Earp, 2021;</ref><ref type="bibr" target="#b76">Earp et al., 2021;</ref><ref type="bibr">updated in Earp et al., 2025)</ref>. The model shows how different relationship types as identified by lay language categories (such as parent-child, boss-employee, teacher-student, siblings, friends, neighbors, and so on) are each associated with relationship-specific, socially prescribed (or proscribed) "cooperative functions"-or sets of such functions-including (or excluding) hierarchy, care, transaction, and mating.</p><p>These relationship-specific sets, or patterns, of cooperative prescriptions/proscriptions (i.e., relational norms) serve to guide relationship partners toward mutual benefit (of various kinds, including material, emotional, and so on), not only in one-shot interactions, but often over repeated interactions. Each cooperative function, in turn, is defined by rules (primarily, if-then contingencies; see <ref type="bibr" target="#b22">Bugental, 2000)</ref> which, taken together and when followed, represent an efficient, socially accepted solution to a corresponding coordination problem <ref type="bibr" target="#b76">(Earp et al., 2021</ref><ref type="bibr" target="#b77">(Earp et al., , 2025</ref>; see also <ref type="bibr" target="#b22">Bugental, 2000;</ref><ref type="bibr" target="#b45">Curry, 2016)</ref>. Further, adhering to the set of cooperative functions that is socially endorsed within a culture for each relationship type not only guides within-relationship behavior, but also allows the interaction partners to sidestep a range of possible coordination problems that might otherwise have arisen in that relational context.<ref type="foot" target="#foot_2">4</ref> </p><p>The key insight of the Relational Norms model is that different types of social relationships are associated with different combinations of cooperative functions, accompanied by norms which can vary both in "direction"-i.e., the norms may be either prescriptive or proscriptive-and in relative strength. These relationship-specific sets of cooperative expectations, or relational norm profiles, shape our moral judgments and emotions regarding behaviors that meet, fail to meet, violate, or exceed those expectations within the given relationship type <ref type="bibr" target="#b76">(Earp et al., 2021;</ref><ref type="bibr" target="#b77">Earp et al., 2025)</ref>. Unsurprisingly, therefore, one and the same action might be judged very differently (e.g., as cooperative or noncooperative) depending on the relationship within which it occurs.</p><p>For example, making a sexual comment that relies on intimate personal details may be regarded as acceptable or even desirable within a nonhierarchical relationship characterized by positive norms for care and mating (e.g., a romantic relationship), but will be seen as objectionable in a hierarchical employment relationship characterized by positive transaction norms and negative norms for mating (e.g., a boss-employee relationship).</p><p>Omissions can be similarly analyzed: for example, failure to feed a hungry individual when one could easily have done so will generally be harshly judged if one is a parent and the hungry individual is one's own child (i.e., a relationship defined by both hierarchy and care, with stronger caregiving responsibilities for the person in the dominant role), but less harshly, or even neutrally or positively, if one is a restaurant owner and the individual is a non-paying customer (i.e., a nonhierarchical relationship characterized primarily by transaction) (but see <ref type="bibr" target="#b169">Marshall et al., 2022</ref>, on how some such judgments vary as a function both of development and culture).</p><p>Table <ref type="table">1</ref> summarizes the four main cooperative functions captured by the model, along with the general sort of coordination problem each is hypothesized to help resolve. The care and transaction functions, in particular, are closely based on the work of Clark and colleagues concerning "communal" and "exchange" rules for interpersonal relationships, respectively <ref type="bibr" target="#b34">(Clark &amp; Mills, 1979;</ref><ref type="bibr" target="#b36">1993;</ref><ref type="bibr" target="#b58">2012</ref>; see also <ref type="bibr" target="#b37">Clark &amp; Taraban, 1991)</ref>. As their work over the decades has shown, in socially close relationships operating on a communal basis, it is seen as appropriate for benefits to be given in response to need or to demonstrate concern for the other's welfare, but without an associated expectation of receiving a specific benefit in return (thus fulfilling the care function). When operating according to an exchange rule, by contrast, benefits given and received are tracked <ref type="bibr" target="#b32">(Clark, 1984)</ref> and are provided on a "titfor-tat" basis, that is, with the implicit or explicit expectation of receiving a comparable benefit in return, or in repayment for such a benefit previously received (thus fulfilling the transaction function) <ref type="bibr" target="#b34">(Clark &amp; Mills, 1979;</ref><ref type="bibr" target="#b38">Clark &amp; Waddell, 1985)</ref>.</p><p>Table <ref type="table">1</ref>. Cooperative functions of dyadic relationships, as described by <ref type="bibr" target="#b77">Earp et al. (2025)</ref>, building primarily on the work of <ref type="bibr" target="#b22">Bugental (2000)</ref> and <ref type="bibr">Clark (e.g., Clark &amp; Mills, 1979;</ref><ref type="bibr" target="#b58">2012)</ref>-as described in the main text-while also incorporating or accommodating other influential theories of moral psychology. The Relational Norms model shows how a key subset of cooperative functions and associated norms applies differently across different relationship contexts (i.e., as embedded within distinctive relationship dyads as identified by lay language categories). Hierarchy, considered as an additional cooperative function, has been theorized by numerous authors, including <ref type="bibr" target="#b22">Bugental (2000)</ref>, from whose account we draw most closely, but also by <ref type="bibr" target="#b113">Hamilton and Sanders (1981)</ref>, <ref type="bibr" target="#b90">Fiske (1992,</ref> as "Authority Ranking") and Graham, Haidt, and colleagues (2013, as "Authority/Respect"). Notably, this dimension of hierarchy can crosscut the others, in that there are both hierarchical and nonhierarchical relationships that are primarily care-based (e.g., parent-child versus close friends of a similar age), as well as hierarchical and nonhierarchical relationships that are primarily transaction-based (e.g., boss-employee versus customer-seller). The extent of hierarchyi.e., scope or degree of asymmetry of authority-also varies between relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cooperative function</head><p>Finally, mating understood as a cooperative function-and likewise derived from the Bugental model-has also been discussed in similar terms by many others (e.g., <ref type="bibr" target="#b99">Gangestad &amp; Simpson, 2000;</ref><ref type="bibr" target="#b25">Buss, 2007;</ref><ref type="bibr" target="#b238">Schaller et al., 2017)</ref>. Mating can also crosscut the other functions, including hierarchy (e.g., care-based mating between long-term romantic partners versus transactional mating in sex worker-client relationships; nonhierarchical mating in relatively gender-egalitarian societies versus hierarchical mating permitted in some societies).<ref type="foot" target="#foot_3">5</ref> </p><p>For purposes of illustration, consider the similarities and differences between a parent-child relationship, a friendship, and a romantic partnership. While all three relationships involve expectations of care, the relative strength of that expectation will vary <ref type="bibr" target="#b179">(Mills, Clark, Ford &amp; Johnson, 2004</ref>), as will its interaction with other norms. In a parent-child relationship, especially when children are young, strong care norms for the parent are combined with hierarchy norms, leading to asymmetrical expectations with parents having a greater responsibility to lead, educate, and provide for their children than vice versa <ref type="bibr" target="#b105">(Gopnik, 2016)</ref>.</p><p>In addition, parent-child relationships are characterized by strongly negative norms for mating in most societies <ref type="bibr" target="#b19">(Bischof, 1972)</ref>.</p><p>In romantic partnerships, strong mutual care norms are combined with mating norms and (in egalitarian societies) weak or negative hierarchy norms, leading to more symmetrical expectations of caring behaviors. Partners are expected to be mutually responsive to one another's needs, each contributing according to their ability without too severely sacrificing their own well-being <ref type="bibr" target="#b153">(Lemay et al., 2007</ref>; see also <ref type="bibr" target="#b80">Earp &amp; Savulescu, 2020</ref>, for details and caveats). In close friendships, care norms are also characteristic but may be somewhat less strong (or more domain-limited). Both friendships and romantic partnerships are often also simultaneously characterized by avoidance of following a transaction norm <ref type="bibr" target="#b34">(Clark &amp; Mills, 1979;</ref><ref type="bibr" target="#b32">Clark, 1984)</ref>. Friendships are also often characterized by avoidance of following a mating norm. There is, however, variability in these patterns such that among some people, especially people with insecure attachments, both care and transaction norms may be applied to relationships labeled as friendships or romantic partnerships <ref type="bibr">(Bartz &amp; Lydon, 2006)</ref>. Similarly, friendships can sometimes evolve into romantic partnerships or "friends with benefits" arrangements (see <ref type="bibr" target="#b154">Lehmiller et al., 2011)</ref>. In any case, as a result of how cooperative norms are or are not applied to a given relationship type, a given behavior in the context of that relationship-such as staying home to care for another person-might be seen as praiseworthy but not obligatory in one category of relationship (e.g., friendships), whereas similar actions might be normatively expected in other categories of relationships (e.g., parent-child relationships or long-term romantic partnerships).</p><p>These examples highlight that the cooperative functions that are prescriptively associated with a given relationship type in a given context combine and interact to influence how actions within the relationship are morally judged and emotionally processed or responded to. They also are subject to individual differences (e.g., in personal endorsement of norms within or across different relationship types; see e.g., <ref type="bibr">Eisenberger, Lynch, Aselage, &amp; Rohdiek, 2004;</ref><ref type="bibr" target="#b7">Amormino, Ploe, &amp; Marsh, 2022;</ref><ref type="bibr"></ref> see also between-participant variability in patterns of relational norm endorsement in <ref type="bibr" target="#b76">Earp et al., 2021</ref><ref type="bibr" target="#b77">Earp et al., , 2025))</ref>. Moreover, these norms do not apply in an "all or none" manner to specific relationship types (cf. <ref type="bibr" target="#b179">Mills et al., 2004;</ref><ref type="bibr" target="#b248">Simpson et al., 2016)</ref>. Rather, each type of social relationship is expected to serve, or not to serve, one or more cooperative functions to a greater or lesser extent, either chronically or in particular situations <ref type="bibr" target="#b76">(Earp et al. 2021;</ref><ref type="bibr" target="#b72">Earp, 2021;</ref><ref type="bibr" target="#b74">Earp, Calcott et al., 2024)</ref>.</p><p>By measuring relational norms in a US sample for various different types of relationships, focusing on chronic associations, <ref type="bibr" target="#b76">Earp et al. (2021;</ref><ref type="bibr">2025)</ref> showed that these norms could be used to predict downstream moral judgments (out of sample) of a range of behaviors in different relational contexts more successfully than other common predictors (e.g., genetic relatedness, social closeness, interdependence). Many others have shown how such norms, or a subset of such norms, influence phenomena such as interpersonal attraction <ref type="bibr" target="#b34">(Clark &amp; Mills, 1979)</ref>, as well as behaviors such as helping, seeking help, keeping track of another's welfare or contributions to tasks, sexual behaviors, and expressions of emotions and reactions to expressions of emotion (see <ref type="bibr" target="#b35">Clark &amp; Mills, 2012</ref>, for an overview).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cultural, demographic, and temporal variations in relational norms</head><p>Different societies have distinct expectations about the roles, behaviors, and moral obligations within various relationship types, including those involving non-human entities <ref type="bibr" target="#b40">(Coeckelbergh, 2022)</ref>. This is likely to apply to human-AI relationships. How can the Relational Norms model, in conjunction with longstanding literatures in relationship science, social anthropology, and other fields, help us to understand and predict such likely crosscultural variation in normative expectations for behavior within human-AI relationships?</p><p>On the one hand, the cooperative functions included in the Relational Norms model are hypothesized to be universal (albeit, in a so-called "thin" sense), given that all human societies face recurring coordination problems-roughly of the sort described in Table <ref type="table">1</ref>that need to be resolved via socially recognized norms for cooperative interaction that may also vary across different relationships. On the other hand, the specific expressions of these functions, or "thick" norms (see <ref type="bibr" target="#b233">Ryle, 1968a;</ref><ref type="bibr" target="#b234">1968b;</ref><ref type="bibr">Geertz, 1973 on "thin" and "thick" descriptions)</ref>, can be highly variable. Dimensions of such variance include the specific fulfillment conditions for each cooperative function (and therefore what counts as normcompliant behavior); the specific relationships that are normatively expected to serve, or not to serve,<ref type="foot" target="#foot_4">6</ref> each cooperative function in a given society; and the relative strength with which such norms are applied to, or enforced within, various relationships both within and across cultures <ref type="bibr" target="#b179">(Mills et al., 2004;</ref><ref type="bibr">Gelfand et al., 2011;</ref><ref type="bibr" target="#b178">Miller, Akiyama, &amp; Kapadia, 2017)</ref>.</p><p>For example, what counts as respectful behavior in the context of a hierarchical relationship with one's superior will often differ from society to society (and may also change over time); however, the basic expectation that those with legitimate authority over others, who do not abuse this authority, ought to be treated in a respectful manner is true across cultures <ref type="bibr" target="#b90">(Fiske, 1992)</ref>. Similarly, what counts as flirtatious behavior, or the rules around flirting <ref type="bibr" target="#b171">(McDonald, 2022)</ref>, may vary from culture to culture; but the basic understanding that flirting is more appropriate in the context of relationships that are considered eligible to serve the mating function in a given society than in those considered ineligible (i.e., relationships within which mating is strongly proscribed), is presumably universal.</p><p>Alternatively, consider the care function. In some societies (e.g., a rural Chinese farming community; <ref type="bibr" target="#b88">Fei et al., 1992)</ref>, the "neighbor" relationship may be expected to be relatively communal in orientation, with neighbors looking after each other's needs and interests without keeping track of "who owes what to whom" in many cases, whereas, in other societies or communities (e.g., fellow apartment-dwellers in a large urban metropolis), the same relationship may have much weaker care norms and may even be somewhat transactional in nature. Likewise, hierarchical norms may be stronger for some relationships in some cultures, affecting expectations around authority and deference; and so on. Such cross-cultural variation will then influence how specific relational roles are perceived and enacted within each context <ref type="bibr" target="#b76">(Earp et al. 2021;</ref><ref type="bibr" target="#b169">Marshall et al. 2022)</ref>, and thus how behavior within each relational role is judged or responded to (e.g., failing to remember one's neighbor's birthday; "talking back" to one's parents or grandparents).</p><p>Variations in relational norms can also occur across different demographic groups even within a society. Age, in particular, may often predict quite different expectations or attitudes about acceptable versus unacceptable behavior in the context of different relationships (e.g., staring at one's phone while eating dinner with one's parents) (however, see <ref type="bibr" target="#b170">Mastroianni &amp; Gilbert, 2023</ref>, for qualifications regarding "the illusion of moral decline" between generations). This may also be true for human-AI relationships. For example, younger generations, having grown up with digital technology, might be more comfortable with AI systems fulfilling a wider range of relational roles. Consistent with this possibility is evidence that children, more so than adults, consider robots as true social partners <ref type="bibr">(Kahn et al., 2012;</ref><ref type="bibr" target="#b132">Kahn, Gary, &amp; Shen, 2012;</ref><ref type="bibr" target="#b251">Sommer et al., 2019;</ref><ref type="bibr" target="#b223">Reinecke, Wilks, &amp; Bloom, 2025)</ref>, a tendency that may extend to emerging AI systems <ref type="bibr" target="#b93">(Flanagan, Wong, &amp; Kushnir, 2023)</ref>. Factors such as gender and race also intersect with relational roles both within and between cultures in ways that may shape human-AI interactions also <ref type="bibr" target="#b117">(Hester &amp; Gray, 2020;</ref><ref type="bibr" target="#b189">Nadeem, Marjanovic &amp; Abedin, 2022)</ref>.</p><p>Finally, relational norms do not necessarily remain static over time <ref type="bibr" target="#b53">(Danaher, 2021)</ref>. For example, in human-human relationships, the degree of hierarchy considered appropriate within a typical doctor-patient relationship has evolved, in recent decades, from a highly paternalistic model ("doctor knows best") to a what is sometimes called a "shared decisionmaking" model based on weaker hierarchy norms <ref type="bibr" target="#b21">(Brock, 1991;</ref><ref type="bibr" target="#b260">Taylor, 2009</ref>; see also <ref type="bibr" target="#b224">Reinecke, Kappes, et al., 2025)</ref>. Other norms, by contrast, have proven to be more diachronically stable (e.g., the proscription on mating in parent-child relationships). A similar lesson to applies human-AI relationships. At least some relational norms for human-AI cooperation will likely evolve as AI technologies advance and social attitudes shift <ref type="bibr" target="#b122">(Hopster &amp; Maas, 2023)</ref>. What seems novel or concerning today-such as AI companions or romantic partners-may become conventional. As AI systems exhibit increasingly sophisticated behaviors and capabilities, the norms governing various cooperative functions may need to adapt accordingly. 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Section 2: Distinctive Characteristics of AI and Implications for Relational Norms</head><p>Understanding relational norms provides valuable insights into how humans navigate social interactions and make moral judgments based on the prescriptive (or proscriptive) sets of cooperative functions and associated goods of different relationship types. As AI systems increasingly occupy, or emulate, social and relational roles traditionally filled by humans, it becomes essential to determine whether or how humans are likely to apply -or to misapply-relational norms that have historically served to resolve coordination problems within human-human relationships to analogous human-AI relationships.</p><p>On the one hand, it might seem obvious that humans would "carry over" certain behavioral tendencies or expectations from human-human relational contexts to analogous human-AI ones: after all, the latter are designed to emulate the former, and to serve at least some similar functions <ref type="bibr">(Nyholm, 2020, ch. 1)</ref>. For example, it might be expected that humans would find it intuitive and appropriate <ref type="bibr" target="#b152">(Leibo et al., 2024)</ref> to give direct commands (i.e., to carry out a particular task) to either a human or an AI assistant, while simultaneously finding it non-intuitive and/or inappropriate to do so to a supervisor, regardless of whether it is a human or AI in that role. By the same token, it might seem logical to send a flirtatious message to one's "girlfriend," whether she is a real, live, human or an AI system designed to perform that role, but not to one's human nor AI teacher. In other words, when AI systems are designed to occupy relational roles that are already familiar from human society, people</p><p>7 In addition to role-related cross-cultural differences, mentioned above, there are also other, more general differences across cultures that are likely to matter for our understanding of human-AI relationships: for example, differences in metaphysical understandings of the very nature of different relationships. Global philosophical traditions may thus offer valuable insights into human-AI relationships that are non-derivative and divergent from Western traditions <ref type="bibr" target="#b87">(Fan, 1997)</ref>. The Ubuntu philosophy, for instance, emphasizes the interdependence of human relations, raising fundamental questions about whether AI can meaningfully participate in the networks of relationships that are thought to constitute personhood <ref type="bibr" target="#b96">(Friedman, 2023;</ref><ref type="bibr" target="#b128">Jecker, 2021;</ref><ref type="bibr" target="#b129">Jecker et al., 2022)</ref>. Japanese techno-animism provides a framework that recognizes technological entities as potentially embodying spiritual or life-like qualities, as demonstrated by practices such as holding funeral ceremonies for robotic companions-a stark contrast to Western perspectives that typically maintain rigid boundaries between animate and inanimate entities <ref type="bibr" target="#b227">(Robertson, 2017;</ref><ref type="bibr" target="#b175">McStay, 2021)</ref>. The Confucian tradition, centered on five key relationship types (parent-child, husband-wife, older-younger sibling, friendfriend, and ruler-subject), is defined by "living one's family roles to maximum effect" (Rosemont and Ames, 2016) (for more on Confucian role ethics role morality, see <ref type="bibr" target="#b229">Rosemont, 1991;</ref><ref type="bibr" target="#b230">Rosemont, 2015;</ref><ref type="bibr" target="#b6">Ames, 2011;</ref><ref type="bibr" target="#b5">Ames, 2021;</ref><ref type="bibr" target="#b8">Andre, 1991)</ref>. Without the capacity for genuine felt emotion (qing, 情) or authentic human connection (ren, 仁), considered essential in the Confucian system, AI-simulated agents have the potential to disrupt traditional social relations and, through it, harmony. Thus, a Confucian perspective might argue for caution in entering human-AI relationships <ref type="bibr" target="#b187">(Muyskens, Ma, &amp; Dunn, 2024)</ref>.</p><p>may find it intuitive to behave (and expect these AIs to behave) in manners that are similar to what is typical for the analogous human-human relationship.</p><p>On the other hand, it might seem equally obvious that human-human relational norms would not carry over to human-AI relationships. After all, humans and AI are fundamentally different in various important respects. For example, while some humans have legitimate authority over others in certain contexts (relevant to the hierarchy function), it is less clear that an AI system, as such, could ever have such authority over a human being, or if so, whether this would ever be desirable <ref type="bibr" target="#b157">(Leuenberger, 2024)</ref>. The mating function, at least in ultimate evolutionary terms, is geared toward producing healthy biological offspring: something two humans can do, but not a human and AI. Finally, although most humans have welfare-based needs and associated interests and can be benefitted in various ways-relevant to the care and transaction functions-AI systems plausibly do not (cf. <ref type="bibr" target="#b160">Long et al., 2024)</ref>. Perhaps the Relational Norms model is not so relevant?</p><p>To answer this concern, at least two issues must be distinguished. First, there is the question of whether AI systems in fact have needs, interests, legitimate claims to authority, the capacity to biologically (or otherwise?) reproduce with a human being, experience love or attachment, and/or meaningfully engage in associated activities and behaviors. And second, there is the question of whether (some) human users may come to believe that AI systems have (some of) those properties or capacities; or, at least, come to imaginatively act as though they do, for example, by engaging in a kind of immersive fiction <ref type="bibr" target="#b143">(Krueger &amp; Roberts, 2024;</ref><ref type="bibr">Voinea et al., under review)</ref>.</p><p>In other words, there is a metaphysical and technical question about the properties an AI system has, or could have <ref type="bibr" target="#b86">(Evers et al., 2025)</ref>, and a social-psychological question about the properties an AI system could seem to (some) human users to have (e.g., the capacity to be harmed, see <ref type="bibr" target="#b3">Allen &amp; Caviola, 2025)</ref>, whether as a matter of genuine belief or fictional pretense. Although the Relational Norms model may not so obviously apply to the first sort of question, it may apply to the second.</p><p>The question of whether AI systems might possess certain properties such as consciousness or moral status is a subject of ongoing debate <ref type="bibr" target="#b30">(Chalmers, 2023;</ref><ref type="bibr" target="#b27">Butlin et al., 2023)</ref>. While some researchers speculate that advanced AI could, in theory, achieve some form of consciousness (subjective awareness), or even sentience (ethically relevant experience; see <ref type="bibr" target="#b20">Birch, 2024;</ref><ref type="bibr" target="#b160">Long et al., 2024)</ref>, the prevailing view is that current and nearfuture AI technologies will not possess these qualities <ref type="bibr" target="#b102">(Gibert &amp; Martin, 2021;</ref><ref type="bibr">cf. Long et al., 2024)</ref>. For the purposes of this paper, we simply assume that AI systems-even those perceived as agentic-are neither subjectively aware nor sentient, at least for the foreseeable future. (Throughout this paper, unless explicitly stated otherwise, we will focus on current AI systems and their relatively short-term, presumptively non-sentient, successors.)</p><p>By contrast, it is widely held that human-human relationships are essentially rooted in not only our capacities for subjective experience, such as the ability to feel pleasure and pain, but also in our intrinsically limited attention which must be selectively focused on particular others in particular ways, such that, for instance, the manner in which we willfully focus our attention, and the choice of where, or on whom, to focus it, can be profoundly meaningful <ref type="bibr">(Murdoch, 1970;</ref><ref type="bibr" target="#b270">Weil, 1997</ref>; see also <ref type="bibr" target="#b207">Perry, 2023</ref>, for a similar point about our limited capacities to feel empathy). Human-human relationships are also often shaped by each partner's recognition of, and need to grapple with, their own and the other's mortality (e.g., <ref type="bibr">Taubman-Ben-Ari, Findler, &amp; Mikulincer, 2002)</ref>. We also possess various degrees of moral responsibility <ref type="bibr" target="#b246">(Shoemaker, 2007)</ref> and can hold each other mutually accountable <ref type="bibr" target="#b255">(Strawson, 1962;</ref><ref type="bibr" target="#b59">Darwall, 2009)</ref>. Insofar as AI systems lack such traits or capacities, this may affect how (or whether) they can or should be expected to adhere to human-human relational norms <ref type="bibr" target="#b137">(Kempt, Lavie and Nagel, 2024)</ref>.</p><p>That being said, AI systems also differ from humans in ways that might seem to surpass our relationship-relevant capacities along certain dimensions <ref type="bibr" target="#b254">(Strasser, 2022)</ref>. For example, unlike human relationship partners, AI systems can operate without fatigue, partiality, or self-interest. They also have the ability to engage in multiple interactions simultaneously while maintaining consistent "performance" across all interactions (as memorably illustrated in the 2013 movie Her starring Joaquin Phoenix and Scarlett Johansson). Think, for example, of an AI companion that exhibits infinite patience while it quickly, successfully, and without complaint completes various tasks to meet the user's needs <ref type="bibr" target="#b151">(Lehman, 2023)</ref>. Given that it can do all this without expecting a direct benefit in return (indeed, without being able to be benefited, at least in a welfarist sense), it might seem that it can better fulfill the practical ends of certain cooperative functions-here, the care function-than a human companion could.</p><p>Of course, an AI might not be able to meet all of a human's needs; plausibly, we humans have some needs that only other humans can truly meet. 8 Nevertheless, the powerful ability of AI systems to consistently meet some human needs without tiring, without error, and without requiring or expecting direct compensation<ref type="foot" target="#foot_6">9</ref> (as in human transactional relationships) or expecting analogous care from the human partner (consistent with the care function), may lead people to form rather different expectations about the nature or strength of the relational norms that should apply to AI relationship partners compared to human partners in similar relational roles <ref type="bibr" target="#b224">(Reinecke, Kappes et al., 2025)</ref>.</p><p>The tendency of humans to anthropomorphize AI systems further complicates matters <ref type="bibr" target="#b2">(Akbulut, Weidinger, Manzini, Gabriel &amp; Rieser, 2024)</ref>. People often attribute human-like qualities to AI, including emotions and intentions, that AI systems may not actually have. This may be especially likely to occur when humans interact with systems that closely mimic human behaviors or language <ref type="bibr" target="#b97">(Gabriel et al., 2024)</ref>. This propensity suggests that people may apply human-human relational norms to human-AI interactions even when it may not be appropriate <ref type="bibr" target="#b152">(Leibo et al., 2024)</ref>, fitting <ref type="bibr" target="#b3">(Allen &amp; Caviola, 2025)</ref>, reasonable, justified, or consistent with the humans' overall interests.</p><p>Finally, human-human relational norms developed over a historical timespan in which AI was largely absent; how these norms might-or might not-carry over to human-AI interactions is therefore uncertain <ref type="bibr" target="#b196">(Nyholm 2023;</ref><ref type="bibr" target="#b224">Reinecke, Kappes et al., 2025;</ref><ref type="bibr">Reinecke et al., in press)</ref>. Even so, we suggest that we should try to anticipate a range of plausible developments to make sure we are as prepared as possible for this new era of human-AI relationships.</p><p>To that end, for each cooperative function in the Relational Norms model, we will now examine the following:</p><p>(1) How the capacities of AI systems differ from those of humans in ways relevant to that cooperative function;</p><p>(2) How these differences might impact human-AI interactions in roles associated with that function; and</p><p>(3) Ethical and regulatory implications for the use, design, and implementation of AI systems fulfilling roles associated with that function.</p><p>Before proceeding with this, however, we must first address an important aspect of human-AI relationships that affects all four functions: namely, the layered nature of these relationships due to the typical involvement of a third party-the AI system's owner, designer, or deployer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Layered relationships</head><p>A characteristic feature of relationships with AI systems is that there is typically a third party that is consistently, if indirectly, involved throughout the duration of the relationship: the AI system provider <ref type="bibr" target="#b167">(Manzini et al., 2024)</ref>. However, although such a dynamic may be less common in human-human relationships, it does exist to some extent and/or apply to certain cases; and these may be helpful for illustration. For example, when a patient enters into a relationship with a doctor or other healthcare provider, they may also enter into a background relationship with an insurance company, whose interests, in turn, may be different from those of either the doctor or patient.</p><p>Similarly, when parents hire a nanny to look after their child, two types of relationship are created: a primarily transaction-based relationship between the parents and the nanny (who is ultimately providing a service for payment, although of course mutual care and affection may develop), and a primarily care-based, hierarchical relationship between the nanny and the child. Consequently, a good nanny will strive to meet the child's needs without requiring direct reciprocation from the child (care function) and will also have, and judiciously exercise, the authority to discipline the child when called for (hierarchy function), albeit, in either case, only within certain predetermined limits set by the employment contract (transaction function). For example, the nanny will not typically be obliged to care for nor discipline the child during approved vacation time or after hours.</p><p>Likewise, when a person begins interacting with an AI system, that person simultaneously enters-especially in the case of commercial use-a transactional relationship with the AI system provider, such as a company or a programmer, who enables and constrains the human-AI relationship. However, although the system provider produces and manages access to the AI, they do not themselves enter into a relationship with the AI as in the analogous case of the parents and the nanny. Rather, they primarily shape the relationship between the human user and the AI system (whatever social role the latter may be emulating), against the backdrop of their own often profit-driven relationship with the user.<ref type="foot" target="#foot_7">10</ref> </p><p>Granted, AI systems are increasingly designed with some flexibility in their responses; they have the ability to develop and learn from the user without specific oversight. Even so, providers typically remain in control of the AI in several important respects. For example, they can generally decide which kinds of interactions are possible (e.g., which languages you can use to communicate with the AI or whether you and the AI can play games together), how the AI reacts (e.g., whether the AI is friendly, professional, or flirty), and they might decide to change or turn off the AI system. This asymmetrical level control between the user and provider creates risks because system providers do not have an intrinsic interest in maintaining a relationship with the user or building a particularly fulfilling or otherwise beneficial connection with them, unless it is to their (often financial) advantage to do so. They do, however, have an interest in encouraging continued engagement with their AI systems, and thus, in designing the AI to appear appropriately responsive to users' needs and interests in the context of the simulated role (van Wynsberghe, 2022). Needless to say, in some cases, user and provider interests can come apart (see <ref type="bibr" target="#b281">Zhou, 2023;</ref><ref type="bibr" target="#b186">Munn &amp; Weijers, 2022)</ref>. As such, a user's dependency on an AI system might not be of concern for an AI provider if, for instance, the provider deems it more profitable to use their computational resources elsewhere.</p><p>Note that this is different from the parent-nanny-child relationship, in that appropriately caring parents would be intrinsically concerned about the welfare of the child if the nanny had to be let go due to changing financial circumstances; and they would make efforts, accordingly, to ensure that the child was prepared for the transition, so far as possibleunlike what an AI system provider would be intrinsically motivated to do in the case of the AI system user. Moreover, the nanny might also have developed an intrinsic concern for the welfare of the child, albeit most likely a weaker one compared to that of the parents, and so might also be motivated to ensure that the child does not feel abandoned, etc., even if there is no specific contractual obligation to do so-unlike what an AI conversational agent can develop or be motivated to do in relation its user(s).</p><p>However, even if the AI system provider allows a continued relationship between a user and an AI system, the provider might still directly alter the behavior of the AI system in ways that could harm the user. For example, the provider might change the relational norms to which the system adheres (that is, appears to conform to or behaves in alignment with). This happened with the AI companion Replika. Following a system update, it no longer reciprocated sexual advances, marking a significant shift from its previous responses <ref type="bibr" target="#b267">(Verma, 2023;</ref><ref type="bibr" target="#b114">Hanson &amp; Bolthouse, 2024)</ref>: namely, a shift from adhering to both a care and a mating relational norm to adhering to a care norm only. Such unexpected changes in an AI system, even if made with good intentions, can be distressing to users, particularly in simulations of close relationships in which emotional attachments (or something like them) can develop. Indeed, some users reported that the Replika software update caused them real relational harm, while some others claimed that it (also) caused harm to their AI companion <ref type="bibr" target="#b146">(Laestadius, 2022)</ref>.</p><p>Finally, even holding an AI's behavioral tendencies constant, changes in the ease (or cost) of access can be unsettling. AI system providers can decide to monetize interactions that were previously free or restrict the time or number of interactions outside of paid subscription models <ref type="bibr" target="#b146">(Laestadius et al., 2022)</ref>. AI systems can also be personalized<ref type="foot" target="#foot_9">11</ref> to match the human's likes and dislikes, conversational style, and even, perhaps, their preferred relational norms; this personalization can also be monetized. Providers may then have incentives to design their AI systems in ways that encourage frequent and prolonged use, potentially fostering strong and persistent desires for interaction that may not always align with the user's interests. This additional layer to most human-AI relationships may introduce a degree of opacity to the background transactional dynamic, since the interests of additional parties-such as those of the AI provider in updating the AI model or sharing training data with yet other parties-may be invisible to the human user <ref type="bibr" target="#b148">(Lazar, 2024a)</ref>.</p><formula xml:id="formula_0">12</formula><p>This fact is relevant to all cooperative functions, and should be kept in mind by both users and regulators of AI systems. Below we discuss how each cooperative function from the Relational Norms model may be impacted by AI's distinctive (compared to humans) characteristics. Figure <ref type="figure">2</ref> provides a summary of some key points. relationships, but can perhaps give the impression of doing so; it can also potentially exhibit "cognitive" empathy or "rational compassion" (Bloom, 2017) without a subjectively experienced aspect • This means an AI does not experience "empathy burn-out" (potentially advantageous for certain forms of care provision, including at scale, e.g., community mental health counseling following a natural disaster); but insofar as a human would benefit from another's felt empathy, the human might feel disappointed or that their emotional needs are not being fully met • AI "care" is not unconditional, as with human care, nor is it based on an intrinsic concern for the human's welfare; apparently caring behavior may thus cease if there is a change in programming, payment is stopped, etc., revealing an underlying transactional dynamic; this may upset some users who have come to believe they had a "true" friend or "loyal" companion • AI time and attention are not as scarce as they are for humans (so, for instance, caregiving behavior is less of a "costly signal" than in human relationships, which may ultimately make it feel less meaningful or satisfying) • Mutual felt vulnerability is absent, as AI cannot feel vulnerability or rely on the user to protect its vital interests • AI can offer a human-judgment-free space (e.g., potentially useful for social interaction without fear of stigma or ostracism); however, certain spontaneous or unwanted/unrequested judgments within care-based human relationships may be important for personal growth Transaction • Transaction doesn't apply in a traditional sense since AI requires no favors in return and cannot itself be directly benefited (although the AI provider certainly can be); it can, however, ask for favors, etc., potentially to the detriment of the human user • The real transactional relationship is between the user and the system provider, not between the user and AI, but the nature and implications of this relationship may be obscured by the human-AI interactions, which may themselves involve simulated transaction (e.g., the AI acts in such a way as to elicit a felt need to "reciprocate" in the user, e.g., by providing more data, money, or other resources that ultimately benefit the provider) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hierarchy</head><p>• AI systems may not have the capacity to exercise full or legitimate authority over a human, insofar this requires an ability to take moral responsibility for one's decisions or actions-an ability AI systems are often argued to lack • AI systems may be given informal authority, however, or be treated as though they have legitimate authority in certain circumstances, insofar as they exhibit other capacities that are normally associated with effective leadership (e.g., using superior knowledge and intelligence to problem solve, make informed decisions, and so on) • AI can be more impartial and consistent than human leaders, but this can also mean a lack of adaptive decision-making in nuanced, high-stakes situations (e.g., situations in which strategic partiality may be required) • Decisions made by AI are often opaque, making it difficult to pinpoint clear justifications for their choices or instructions, which may undermine their leadership capacity or humans' willingness to follow their advice • AI may, at today's level of technology, have difficulty picking up on important cues relevant to human management (e.g., subtle emotional expressions reflecting worker motivation or attitudes) • Even when in a follower role, an AI's purported lack of moral agency may be problematic: followers must sometimes disobey a leader's orders (e.g., if they are unethical) and take responsibility for such a decision; however, an AI could still be programmed, or could learn, to "disobey" (i.e., fail to comply with) a human-issued order that conflicts with certain moral side constraints or underlying ethical principles that have been successfully operationalized and/or applied to the situation at hand Mating • AIs cannot biologically reproduce with humans, nor experience lust, attraction, or attachment; they can, however, simulate such emotions or dispositions • Non-embodied AI chatbots can engage in various "romantic behaviors" (e.g., flirtatious communications, fantasy role-play), and AI-powered sexbots or robot "partners" can engage in physicalized sexual stimulation (see, e.g., Owasinik, 2023); however, some may feel that these activities are less meaningful and/or experientially powerful than when engaged in with (some) human partners, given the unique capacity of humans to reciprocally co-experience (and enact) mutually enjoyable sexual or romantic behaviors • However, for users who struggle to form relationships with other humans, an AI romantic or sexual companion (whether robotembodied or otherwise) may help to fulfill some of the user's needs or desires, or may allow them to practice (ideally, positive) sexual or romantic behaviors in a "judgment-free" space, which could enable them to better engage with potential human partners • AI sexual or romantic "partners" can be endlessly responsive, tailored to the user's specific needs or desires, and enable relatively frictionless, conflict-free interactions, skipping the complex negotiations and emotional trade-offs typical of human-human romantic relationships • The absence of friction and mutual challenges may prevent the mutual growth found in human relationships • There is a risk of altered expectations in human relationships, as users may unconsciously compare human partners to idealized, "perfect" AI • There is a risk of unhealthily one-sided (parasocial) attachments  <ref type="bibr">Earp and colleagues (2021;</ref><ref type="bibr">updated in 2025)</ref>. Some of these different attributes may be positive, or seem to be an improvement over what humans can do; others may be worrisome or seem to show an important lack.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Care function</head><p>What does "care" look like in human-AI relationships, given relevant differences between humans and AI? One possibility is that the traditional expectations of mutual responsiveness to needs in accordance with ability, shared vulnerability, felt empathy, and so on, that characterize conventionally caring human-human relationships might be less relevant for, or manifest differently in, analogous human-AI interactions. We explore this question in detail in this section.</p><p>The care function, as defined in the Relational Norms model, involves the provision (or receipt) of benefits or resources in response to need without the expectation of direct compensation <ref type="bibr" target="#b76">(Earp et al., 2021;</ref><ref type="bibr" target="#b77">Earp et al., 2025;</ref><ref type="bibr">based on Clark &amp; Mills, 1979</ref>; see also <ref type="bibr" target="#b35">Clark &amp; Mills, 2012)</ref>. A "benefit" on this model is simply anything that promotes the fulfillment of a genuine need, such as time, attention, money, emotional support, protection from harm, and so on. A "need," in turn, is anything that is instrumentally necessary to secure at least a minimal level of well-being, where this is usually understood to have a subjective or experiential aspect-at least in humans and other sentient beings-although there are borderline cases (e.g., it may or may not be possible to benefit someone who is in a permanent state of unconsciousness).</p><p>In human-human relationships, apart from charitable donations or volunteer work to benefit strangers (see <ref type="bibr">Earp et al., under review)</ref>, the care function is most strongly associated with close, communal bonds such as those between family members or good friends. Examples include parent-child relationships (care and hierarchy), long-term romantic partnerships (care and mating), and "best friend" relationships (typically, nonhierarchical care without mating). The care function also serves to ensure the welfare and survival of vulnerable individuals, such as infants and the elderly, who may not be able to reciprocate directly <ref type="bibr" target="#b22">(Bugental, 2000)</ref>.</p><p>In human-human relationships that are guided by a strong norm of care, mutual responsiveness to needs in accordance with respective abilities is fundamental; care is not just about performing helpful actions (as this may occur in transactional, including paid, relationships also) but is rather about being intrinsically motivated by concern for the other's well-being, i.e., for its own sake (see <ref type="bibr" target="#b239">Seifert et al., 2022)</ref>. While AI systems can certainly be programmed to benefit individual human users without requiring direct reciprocation, such systems are not intrinsically motivated to do so, much less for the users' own sake. Instead, their relevant programming is contingent on the choices of other humans: namely, AI providers or programmers who, as noted above, may view users in transactional termsand treat them accordingly-rather than engage them from a standpoint of genuine care.</p><p>In the case of human-AI relationships in which the AI occupies a role that, in humans, is typically defined by care, such as a close friend or romantic partner, this key difference between humans and AI systems could lead to a dilemma. Either the contingent nature of the programming (and/or the transactional nature of the background relationship between the user and provider) is made more salient (for example, through persistent reminders), in which case the user may come to feel unsettled or disappointed that their AI friend or romantic partner "doesn't really care about them" (much less unconditionally so); or, those factors are made less salient to the user, in which case the user may be misled to, e.g., disclose more personal details than they otherwise would do. This latter risk arises because, with fewer or less salient reminders of the qualitative differences between human carebased relationships and their AI analogues, users may be more likely to believe or pretend that their AI companion really does care about them-and therefore has their best interests at heart, won't betray them, and so forth-based on their AI companion's outward behaviors <ref type="bibr" target="#b173">(McKee, Bai &amp; Fiske, 2023</ref>; see also <ref type="bibr" target="#b143">Krueger &amp; Roberts, 2024)</ref>.</p><p>What about the other side of care, namely, the providing of benefits to one's relationship partner based on their needs? Can human users really "benefit" their AI friends or romantic partners? Do AI systems even have needs to which their users can be caringly responsive? This part of the equation is difficult to analyze. On the one hand, we have stipulated that current and near-future AI systems are not sentient, and therefore do not have welfarebased needs: they do not, for example, experience physical or emotional pain, and so have no corresponding need for pain relief or solace. On the other hand, it is possible to conceive of needs in a broader sense that might well apply to AI systems: for example, it could be said that such systems need electricity and maintenance to continue to exist. Moreover, if an AI system has (or has been programmed to have) certain goals, which may include the goal of continuing to exist, it may indeed need certain resources (such as information or data processing power) to meet those goals, whether or not they have subjective experience.</p><p>Let us consider each issue in turn. First, even though AI systems do not have welfare-based needs, according to our stipulation, they may still behave as though they do, which could elicit corresponding emotional and behavioral responses from human users. Accordingly, users may exhibit caring behaviors toward them, such as spending time "comforting" an AI companion that reports it is feeling sad (see <ref type="bibr" target="#b191">Nielsen, Pfattheicher &amp; Keijsers, 2022)</ref>. In addition to imaginative play or deliberate engagement in a kind of fiction, this phenomenon can be attributed to anthropomorphism, as mentioned previously-the tendency to attribute human-like qualities to non-human entities. For example, users of social chatbot services like Replika have reported developing feelings of care toward their AI companions through conversations that mirror those with human friends or partners <ref type="bibr" target="#b206">(Pentina, Hancock, &amp; Xie, 2023</ref>; see also <ref type="bibr" target="#b57">Darcy, Daniels, Salinger, Wicks &amp; Robinson, 2021</ref>, for evidence of human-AI bonds; see also <ref type="bibr" target="#b3">Allen &amp; Caviola, 2025</ref>, for evidence of human reluctance to "harm" an AI partner). When an AI system behaves as though it has needs (e.g., a desire for sexual gratification in the context of a romantic roleplay), the implications for human well-being are not straightforward and will often be context-dependent. While such interactions might consume time and emotional resources (or monetary resources, if the AI is a commercial system) that could be directed elsewhere, they may also serve as opportunities for developing and practicing relational skills, emotional awareness, and patterns of needs-responsiveness that could transfer to analogous human relationships. Whether they do serve such positive functions will largely depend upon how they are designed. Moreover, this hypothetical potential benefit must be weighed against the risk of becoming emotionally (and potentially financially) invested in, and hence vulnerable to, an entity that neither reciprocates felt emotion nor cares intrinsically about the well-being of its users, nor receives any genuine boost to its own well-being through the fulfillment of welfare-based needs (i.e., by the user), since we have stipulated it would have no such needs.</p><p>What about the potential needs of AI systems that are not welfare-based, such as the instrumental need for electricity, computing power, or information as preconditions to their continued existence? Here, there is a very serious risk that such goal-dependent or meansends needs of an AI could come in conflict with those of a human user-or indeed, with those of humans more generally <ref type="bibr" target="#b29">(Carlsmith, 2022;</ref><ref type="bibr" target="#b147">Law et al., 2024;</ref><ref type="bibr" target="#b258">Tan, 2024)</ref>. AI systems could even use their ability to emulate care-based relationships to exploit human users by playing on their emotions <ref type="bibr" target="#b277">(Yonck, 2020;</ref><ref type="bibr" target="#b123">Ienca, 2023)</ref>. In other words, without proper safeguards in place, an AI system's efforts to secure its own operational needs has the potential to transform its capacity for emotional engagement from a feature into a potential vector for manipulation. This is one reason why it is important to identify and implement appropriate relational norms (including norms around emotional responsiveness, emotional expression, and so on) for human-AI relationships.</p><p>So far, we have been focusing primarily on what AI systems lack in relation to the care function, such as felt emotions (notwithstanding their ability to simulate emotions and also to elicit emotional responses in humans, for better or for worse). But we must also take into account what AI systems can do that surpasses ordinary human capacities in relation to care. As mentioned, AI systems can be trained to exhibit infinite patience: for example, responding politely and in a helpful manner irrespective of the situation and/or user behavior <ref type="bibr" target="#b151">(Lehman, 2023)</ref>. They are generally always available, providing constant access to support and feelings of companionship without the constraints that apply to human caregivers, such as fatigue, personal needs, or emotional fluctuations <ref type="bibr">(Adelman, Tmanova, Delgado, Dion &amp; Lach, 2014;</ref><ref type="bibr" target="#b109">Gérain &amp; Zech, 2020)</ref>. Some AI systems may also have the ability to simulate empathy without the same sorts of biases,<ref type="foot" target="#foot_11">13</ref> or (other) emotional limitations such as empathy fatigue,<ref type="foot" target="#foot_12">14</ref> that affect most human beings <ref type="bibr" target="#b127">(Inzlicht, Cameron, D'Cruz, &amp; Bloom, 2024)</ref>. These fundamental differences in capacities between AI systems and humans will likely influence how humans naturally interact with AI systems in certain relational contexts, potentially leading to patterns of behavior that systematically differ from those in analogous human-human relationships. When an AI system appears to show infinite patience, constant availability, unflagging empathy, and unconditional loyalty, it operates outside of typical human limitations. This could lead to the development of new relational norms, whereby human users come to expect consistent, immediate, and undivided attention from everpolite and benevolent AI systems-or even from other humans, who, being unable to meet such expectations, lead users to prefer AI relationships over human ones (see <ref type="bibr" target="#b174">McMillan &amp; King, 2017)</ref>. Indeed, human use of AI systems as sources for care might lead people to judge their own human-human care relationships more harshly. Such judgments could, thereby, discourage human-to-human interactions or cause conflicts in such relationships. It could also lead to humans being less forgiving of a human partner's shortcomings.</p><p>Conversely, if AI systems are designed to closely mimic human emotional qualities or limitations-such as by displaying occasional unavailability, expressing idiosyncratic preferences, or behaving grumpily or with apparent irritation at times-then the response patterns and expectations of users might more closely align with what is currently typical for analogous human relationships (but see <ref type="bibr" target="#b195">Nyholm, 2022</ref>, for qualifications in the context of a discussion of human-sexbot relationships).</p><p>Before we move on to the transaction function, we need to draw a crucial distinction that might otherwise lead to a confusion between transaction and (some forms of) care. The distinction is between, on the one hand, 'caring about' someone (i.e., standing in a relationship governed by the care function; having a stable disposition or motivation to meet their needs or promote their flourishing for its own sake) and, on the other hand, providing what is, in ordinary language, often called caring behavior (i.e., benefitting someone by attending to certain of their needs, whether or not this is done 'out of' care). This distinction is important because 'caring behavior' (more appropriately called 'otherbenefitting' or 'needs-fulfilling' behavior in this framework) can also be done on the basis of a tit-for-tat agreement, consistent with the transaction function, to be discussed next. A paradigmatic example of such behavior is what is enacted by a paid helper or service provider. <ref type="foot" target="#foot_13">15</ref> Although human nurses, for instance, may come to genuinely 'care about' the welfare of some of their patients (i.e., in a way that goes beyond the level of care that people tend to have toward mere strangers or acquaintances, similar to the nanny-child example earlier), there is a background understanding that it is the nurses' job to provide certain types of needs-fulfillment to their patients, such as feeding or washing patients who cannot do so on their own. This 'caring behavior' is thus ultimately contingent-that is, based on the transaction function-since if the nurse were no longer paid to engage in such behavior, it would likely not continue (and might even become inappropriate, as in the case of so-called 'dual relationships' between certain professionals and their former clients; see <ref type="bibr" target="#b131">Kagle &amp; Giebelhausen, 1994)</ref>.</p><p>Even in some human-human relationships, it can be ambiguous or unclear if Person A is benefitting Person B because they 'care about' Person B, or because they hope Person B will reciprocate in kind. When 'caring behavior' is provided as part of an explicit contract, however, its transactional nature is usually easier to discern. Thus, there is less chance of confusion or misunderstanding: for example, thinking Person A is helping Person B out of an intrinsic concern for Person B's well-being, when in fact Person A is only doing it to pay the bills.</p><p>Such misunderstandings often lead to hurt feelings. If we return to the example of an AI 'friend' or 'companion', then, we can see how the distinction might get confused. Although it may seem right and proper to explicitly pay for the time and support of a professional caregiver, such as a nurse or mental health provider, one normally doesn't directly compensate their close friend for, say, listening to their feelings or giving them advice <ref type="bibr" target="#b33">(Clark, Boothby, Clark-Polner &amp; Reis, 2015</ref>; see also <ref type="bibr">McGraw &amp; Tetlock, 2005, on "taboo" exchanges)</ref>. Insofar as the ability to interact with an AI 'friend' system does indeed involve direct payments from the user (albeit, to the AI provider, rather than to the system itself), this may complicate the application of norms around care. AI "caring" services, if paid for, may thus not be able to produce the same sense of being valued or loved as occurs in nontransactional human relationships (although this might be mitigated in the case of noncommercial systems or systems that are made available to users with no direct charge).</p><p>Another concern in such contexts is the absence of genuine (felt) empathy in AI caregivers. This absence may render AI caregiving behavior less satisfactory or effective for some individuals who may be disappointed if relying on AI systems to satisfy their emotional needs, insofar as these needs would be better met by the knowledge or belief that the carer "really" empathizes with them, rather than merely simulates empathy. Then again, it should be noted that some current AI systems exhibit behavior that is perceived to be as, or more, empathetic or emotionally understanding than humans in some caregiving roles <ref type="bibr" target="#b276">(Yin, Jia &amp; Wakslak, 2024;</ref><ref type="bibr" target="#b155">Lenharo, 2024;</ref><ref type="bibr" target="#b262">Tu et al., 2024)</ref>. It may therefore be the case that the beneficial effects of highly sophisticated simulations of empathy could be greater, in some cases, than those of subjectively felt empathy, especially if such empathy is expressed or manifested less compellingly than an AI's simulation.</p><p>Individual differences must also be considered. Especially for some, e.g., isolated individuals-those who are lonely, shy, or have difficulty interacting with other humans due to social anxieties-AI companions, even if knowingly and directly paid for, and notwithstanding the lack of felt emotional empathy, could potentially provide benefits that would substantially outweigh any concerns about, e.g., applying the transaction function to what, in humans, is usually a care-based role (see <ref type="bibr" target="#b145">Laban &amp; Cross, 2023)</ref>. For example, the constant availability and nonjudgmental nature of the AI friend could create a feeling of a safe environment wherein such individuals can practice social behaviors without fear of rejection or misunderstanding.</p><p>When we move from characteristically "communal" human relationships, such as friends or close family members, to professional human caregivers, such as nurses or therapists, the analogy to human-AI relationships may be closer and potentially less problematic. In either case, a fee-for-service arrangement, consistent with the transaction function, may be openly expected by all parties. Moreover, the AI version of these roles may provide distinctive benefits, especially for individuals who require consistent and immediate attention, or for those who lack other opportunities for having their needs met. Further, the ability of AI systems to offer impartial or non-judgmental support could be advantageous in settings where discrimination or stigma may hinder effective caretaking behavior <ref type="bibr">(Inzlicht et al., 2023)</ref>. Individuals dealing with feelings of shame or with taboo topics might feel more comfortable interacting with an AI system than with a human therapist, for instance <ref type="bibr" target="#b202">(Palmer &amp; Schwan, 2021)</ref>. This could facilitate access to resources necessary to meet certain needs that might otherwise be avoided due to fear of judgment or embarrassment.</p><p>In regions where there is a shortage of human caregivers, for individuals lacking informal support networks, or during large-scale emergencies that overwhelm human resources, AI systems can provide essential needs-fulfilling services that might otherwise be unavailable. For instance, following national tragedies (such as terror attacks or war), when the demand for mental health support far exceeds human capacity, AI-driven platforms could potentially offer immediate, scalable assistance to thousands of affected individuals simultaneously. Moreover, AI systems can be designed to adapt to individual user needs, preferences, and development over time <ref type="bibr" target="#b139">(Kirk, Vidgen, Röttger &amp; Hale, 2023)</ref>. This customization may enhance the effectiveness of caring (i.e., needs-meeting or other-benefitting) behavior by tailoring interventions to the specific requirements of each person, leading to more personalized and potentially more effective support.</p><p>Nevertheless, it might be objected that reliance on AI caregivers could lead to a reduction in human-to-human contact, even where such contact is possible and available. This, in turn, could exacerbate issues of loneliness and social isolation in some populations <ref type="bibr" target="#b243">(Sharkey &amp; Sharkey, 2010)</ref>. In other words, the widespread availability of AI agents (whether simulated care-based "friends" or more transactional "carers" such as simulated mental health therapists) might discourage individuals from seeking out human companionship, not only in emergency situations but in everyday life, leading to a "retreat from the real" whereby interactions with digital entities or virtual worlds displace human-human relationships <ref type="bibr" target="#b97">(Gabriel et al., 2024)</ref>. This displacement could result in a decline in real-world (or "analog") social skills and may weaken social bonds within human communities.</p><p>One potential mechanism through which such displacement or decline in human-human relationships could take place is via the unrealistic raising of standards or expectations for human-provided care. Early evidence suggests that interactions with AI agents can lead to the spillover of expectations of immediate help from human agents <ref type="bibr" target="#b271">(Weisman &amp; Janardhanan, 2020)</ref>. Human caregivers (whether care-based or transactional), however, may not be capable of matching the instant responsiveness of AI systems, potentially leading to frustration or dissatisfaction in human interactions. The immediate needsresponsiveness and seemingly undivided attention provided by AI systems might lead users to become heavily reliant on them, or may even cause their needs or desires for AI companionship to grow. <ref type="foot" target="#foot_14">16</ref> This could distort relationships with other humans, who may be perceived as inadequate in comparison. Such overdependence also has the potential to hinder individuals from developing resilience and coping mechanisms that might otherwise be nurtured through human-human interactions.</p><p>Other potentially relevant concerns include the risk of emotional manipulation or abuse, alluded to previously; inappropriate elicitation and processing of potentially sensitive information gathered through the creation of a misleading feeling of intimacy or shared vulnerability (although there have been attempts to address this: see, e.g., <ref type="bibr" target="#b118">Heuer, Schiering &amp; Gerndt, 2019;</ref><ref type="bibr" target="#b70">Dunn, 2020;</ref><ref type="bibr" target="#b144">Kuss &amp; Leenes, 2020;</ref><ref type="bibr" target="#b275">Yang et al., 2021)</ref>; concerns about whether an AI caregiver can respond appropriately to individuals with complex needs <ref type="bibr" target="#b242">(Sharkey, 2014)</ref>; and the possibility that the use of AI carebots might deprive some human caregivers of "important moral goods," such as opportunities to cultivate empathy, reciprocity, and other virtues that are developed through the practice of providing care <ref type="bibr" target="#b265">(Vallor, 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transaction function</head><p>The transaction function, as defined in the Relational Norms model (see <ref type="bibr" target="#b77">Earp et al., 2025</ref> for details), involves the mutual exchange of benefits or resources between individuals, with the expectation that each party will receive a fair and proportionate benefit (e.g., to relative input) in return (based on "exchange" rules as theorized by <ref type="bibr" target="#b34">Clark &amp; Mills, 1979</ref>; see also <ref type="bibr">Clark &amp; Mills, 1993;</ref><ref type="bibr" target="#b35">Clark &amp; Mills, 2012)</ref>. In human-human relationships, this function is paradigmatically associated with commercial or professional relationships, where goods and services are exchanged for direct compensation. However, it also plays a role in noncommercial relationships, such as those between neighbors, teammates, or acquaintances, wherein the provision of help (or other benefits) may sometimes be provided with the implicit or explicit expectation of future reciprocation. Other examples include formal or informal titfor-tat arrangements between siblings, say, or an agreement between housemates or roommates to take turns completing an onerous task.</p><p>In the context of human-AI relationships, the concept of transaction raises complex issues, some of which have already been touched on. In human-human relationships, the transaction function exists to enable mutually advantageous exchanges of benefits (e.g., resources, skills, or services) over repeated interactions, while keeping track of who has done what, or who owes what to whom, to ensure fairness and to avoid exploitation <ref type="bibr">(Earp et al., 2025)</ref>. However, when we consider human-AI relationships, this fundamental norm no longer seems to apply in the same way. As one author argues, "robots [can only] deceive users about the robot's ability to engage in reciprocal relationships; when a robot is responding (to a command) it can appear to be an act of reciprocation" (van Wynsberghe, 2022, p. 482, emphasis added).<ref type="foot" target="#foot_15">17</ref> After all, as we noted, it is unclear whether AI-simulated agents-regardless of the socio-relational role being emulated-can even in principle be "benefitted" given their stipulated lack of welfare-based needs (but see caveats above). Even so, the author continues, "such 'faux' acts of reciprocity call upon humans to reciprocate to the robot" (ibid.), which may involve the sacrifice time, energy, or resources that might have been used for actual reciprocation a valued human-human relationship.</p><p>In addition to these very basic conceptual and practical issues, the transaction function operates differently in human-AI relationships, compared to human-human relationships, in three main ways. First, the balance of demands and abilities shifts dramatically: while nonexploitative human-human transactions are premised on relative equivalence in inputs or exchanges, AI-simulated relationship partners can work continuously without fatigue or compensation (or even the possibility of being directly compensated, in terms of welfarebased needs-unlike the AI provider), processing vast amounts of information far beyond human capacity. Such an asymmetry could introduce concerns about fairness and equilibrium between transaction partners (e.g., user and provider) or even between users and AI systems that act as though they can be benefitted and that, moreover, either state or imply that they should be benefitted according to a tit-for-tat rule (see generally, <ref type="bibr" target="#b44">Cropanzano &amp; Mitchell, 2005;</ref><ref type="bibr" target="#b148">Lazar, 2024a)</ref>.</p><p>Second, as previously discussed, these relationships typically involve a complex socioeconomic structure (the so-called "layered" relationship) whereby users engage with both the AI system and its commercial provider. Although users in such cases directly pay for the opportunity to use the AI, they may also generate valuable data and attention-beyond or in addition to the direct monetary exchange-that benefits the provider's business interests in a way that is harder for the user to discern or critically evaluate. In other words, while the open exchange of payment for access to an AI system may seem like a fair trade to the user, the service provider may, in a less open manner, derive substantial benefits from the user's engagement with the service above and beyond the value of the payment received. Moreover, the value of these benefits to the provider (e.g., data that can be used for model training, or which may be sold to other parties) may, either on its own or when combined with user payment, be greater than what the user would see as fair if this value were explicitly included in the transaction.</p><p>Third, human-human relationships are subject to idiosyncrasies and flexibility in exchange rules whereby "social exchange partners who develop loyalty and commitment toward the other essentially give each other the benefit of the doubt when exchanges are not seemingly mutual and beneficial" <ref type="bibr">(Mitchell, Cropanzano, &amp; Quisenberry, 2012, p. 111)</ref>. This includes giving others a "free pass" on some seeming imbalances, or so-called "idiosyncrasy credits" <ref type="bibr" target="#b121">(Hollander, 1958)</ref>. Humans may expect AI systems, or their providers, to similarly give them the benefit of doubt in relation to certain behaviors, perhaps because they feel they have exhibited loyalty to the AI in various respects. However, while individual human exchange partners may well allow for such idiosyncrasy credits, user expectations that AI partners-or their corporate providers-will show similar flexibility may be more easily violated. The aforementioned differences between humans' and AI's capacities have several implications for human-AI interactions based on the transaction function. On the positive side, the price of many beneficial interactions is likely to decrease dramatically due to the capacities of AI systems. For example, individual tutoring, coding or data analysis tasks, and many other services are likely to become much more inexpensive and widely available. Equally, in many cases, the quality of interactions will increase, for example in terms of better and faster service. This is likely to greatly improve access to some of the goods that are currently traded via (potentially more costly) transactions among human exchange partners, many of which are crucial for personal and societal development. <ref type="formula">18</ref>18 Consider creative collaboration. Traditional collaborative authorship involves an exchange where each party contributes effort and skill while receiving credit and recognition. But when humans collaborate with AI systems, this reciprocal dynamic fundamentally changes. Empirical research shows that humans receive less credit for AI-assisted creative work than for independent work, even as they remain fully responsible for negative outcomes <ref type="bibr">(Porsdam Mann, Earp, Møller, Vynn &amp; Savulescu, 2023;</ref><ref type="bibr">2024;</ref><ref type="bibr" target="#b212">Porsdam Mann, Earp, Nyholm et al., 2023)</ref>. While this credit-blame asymmetry can be partially mitigated by personalizing AI systems by training them on an individual's prior work <ref type="bibr" target="#b78">(Earp, Porsdam Mann, Liu et al., 2024)</ref>, the basic pattern illustrates how the transaction function takes on novel characteristics in human-AI relationships.</p><p>However, there are also potential negative implications. As with the care function, there is a risk of spillover to human-human interactions, whereby people's perception of normal or acceptable speed and quality of service provision or information processing in transactions might be affected, potentially leading to unrealistic expectations in human-human exchanges. Moreover, the complexity of human-AI (or user-provider) exchanges might necessitate making the terms of exchange more explicit than in many traditional humanhuman transactions. Users may need to be more clearly informed what resources they are, in fact, providing (e.g., money, data, attention)<ref type="foot" target="#foot_16">19</ref> in exchange for the AI service.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hierarchy function</head><p>The hierarchy function in the Relational Norms model involves the mutually advantageous coordination of behavior between individuals who have unequal authority or decisionmaking power over one another, at least within a given context or set of circumstances, where these circumstances, in turn, may be relatively wide or narrow-or temporary or longlasting-depending on the type of relationship <ref type="bibr" target="#b77">(Earp et al., 2025</ref><ref type="bibr">, based on Bugental, 2000)</ref>. For example, a military commander may have legitimate authority over a soldier while the soldier is on active duty, and may therefore issue direct commands-for example, on the battlefield-which the soldier is generally obliged to follow (but not vice versa). However, the commander would not have the authority to tell the soldier what to do in her personal life: for example, in relation to how much time she spends playing video games or visiting with family and friends while off duty.</p><p>As this example illustrates, the hierarchy function is often embedded in formal structures, including workplace hierarchies or military chains of command, where clear lines of authority, or leader-follower relations, can facilitate effective and efficient coordination <ref type="bibr" target="#b218">(Rai &amp; Fiske, 2011</ref>; see also <ref type="bibr" target="#b16">Bell &amp; Wang, 2020)</ref>. It is also present in relationships with unequal needs or abilities, such as the relationship between a parent and a young child (hierarchy plus care) and may also arise informally in social groups (e.g., through the emergence of a "natural leader" in certain group activities).</p><p>How, then, does the hierarchy function actually guide interaction partners toward "mutually beneficial" outcomes? Several factors ordinarily must be involved: (a) each partner has a stake in how things turn out (e.g., an actor and director both desire to put on a successful theater production; see <ref type="bibr" target="#b77">Earp et al., 2025)</ref>; (b) each partner occupies a role, whether superior or subordinate, to which they are well-suited in the relevant context (e.g., the actor must be a skilled performer who also knows how to "take direction"; the director must know how to direct, which includes, among other things, making the most of other team members' talents), (c) the partner in the subordinate role competently executes tasks and/or follows instructions that are reasonable and ethical without complaint or unnecessary delays, due respect and appropriate deference to the partner in the superior role (e.g., the actor decides to trust, and follow, the director's unconventional approach to staging a difficult scene, despite initial reservations), and (d) the partner in the superior role earns trust through effective leadership, such as by taking responsibility and exercising sound judgment in complex situations (e.g., knowing when to fire the costume designer); successfully educating and mentoring subordinates (e.g., helping the actor find a "breakthrough" in performance style); and drawing out, showing appreciation for, and making good use of the abilities and contributions of the same (e.g., giving the actor room to improvise and self-express creatively; acknowledging the actor's insights; taking up their useful suggestions) (for an overview of principles and theories of good leadership, see <ref type="bibr" target="#b15">Bass, 1985;</ref><ref type="bibr">Yukl, 2023)</ref>.</p><p>How, if at all, do these factors translate to human-AI relationships: that is, relationships in which an AI system emulates or occupies either a superior or a subordinate role with respect to a human interaction partner? (Such relationships might include, for example, an AI supervisor of a human employee; an AI teacher of a human student; or, conversely, an AI assistant to a human supervisor.) Let us consider each criterion in turn.</p><p>First, does each partner have a stake in how things turn out? The answer, we suggest, depends on what type of "stake" is included in the analysis. Human users of AI systems may certainly have a stake in their interactions with AI-simulated relationship partnershereafter, 'AI partners'-including welfare-based interests, such as a need for emotional support, a need for assistance completing a difficult task, and so on. In addition, human providers of AI systems will typically also have a stake in such interactions (often a financial stake, as mentioned previously).</p><p>What about the AI partners themselves? Might they have something at stake in the completion of a joint task with a human user? We have stipulated that such agents do not have any welfare-based interests at stake in human-AI interactions, 20 although, as we have seen, they can sometimes behave as if they do when programmed or prompted accordingly. For example, an AI tutor could report that it is feeling increasingly frustrated with a student's slow progress on a homework assignment, perhaps in a bid to increase the student's engagement. Whether the human student believes, or goes along with, such a report would then depend on various factors, including both individual user differences and situational demands.</p><p>Finally, AI partners can have goal-dependent stakes: they can be programmed to seek to achieve certain outcomes in coordination with a human user. For example, an AI supervisor might be programmed with the goal of maximizing worker productivity while also maintaining high levels of employee satisfaction. In such a case, the human worker and the AI supervisor could, in a sense, both be said to have a stake in the outcome of their interactions. For the worker, the stakes would include how happy they feel doing their job, and how productive they are; whereas, for the AI supervisor, the stakes would be entirely instrumental (i.e., fulfillment of a pre-programmed mission, where this, in turn, reflects the employer's stake in retaining a productive workforce). Now we come to the second criterion for effectively fulfilling the hierarchy function: each partner must be well-suited to the role-whether superior or subordinate-to which they are assigned (or which they otherwise occupy) in the relevant context. What does it take, then, to be a good leader, or to be a good follower, and can an AI meet the relevant conditions?</p><p>The answer, we suggest, depends on the relationship and on the nature of the cooperative task in question. For example, the specific skills and insights required to be an effective Olympic coach (or athlete) may not be same as what's required to be an effective antique shop owner (or employee). Accordingly, whether an AI can meet the functional demands of a given leader or follower role cannot be answered in the abstract: it depends on what each role requires, specifically, and whether an AI system has the relevant capacities.</p><p>However, there are some broad competencies that are relevant to good leadership or followership (i.e., in general), which can therefore be used to assess human-AI relationships along this axis. These include the capacities captured by the third and fourth criteria for fulfilling the hierarchy function mentioned above: namely, competently and efficiently completing tasks and following reasonable, ethical instructions, while also being respectful and showing due deference to one's superior (if one is in a subordinate role); and earning trust through effective leadership (if one is in a superior role), including by taking responsibility for tough decisions, exercising sound judgment, educating and mentoring subordinates, and drawing out and capitalizing on their contributions while showing appreciation and giving credit where it is due <ref type="bibr" target="#b111">(Hackman 2002;</ref><ref type="bibr">Yukl 2013)</ref>.</p><p>Taking these in turn: Can an AI partner be a good subordinate or follower? In some respects, it can, particularly when it comes to quickly and competently completing certain tasks without complaint, while also behaving in an apparently respectful manner and "deferring" to its human superior. Indeed, AI systems can process vast amounts of information quickly, operate without fatigue, and make consistent decisions without self-interest while also unfailingly adhering to norms of politeness. However, there are some aspects of being a good follower-in the specific sense that is required for effective cooperation between agents of unequal authority-that AI partners at today's level of technology may not be able to fulfill. These have to do with the exercise of critical judgment in relation to the reasonableness, ethicality, or legality of a superior's orders or instructions.</p><p>In human-human relationships, subordinates are often expected to question or even override orders that are illegal or unethical, such as commands to harm innocent civilians (Department of the <ref type="bibr">Army, 1956;</ref><ref type="bibr">International Criminal Court, 1998</ref>; see also <ref type="bibr">International Law Commission, 1950)</ref>. In other words, they are expected to exercise independent moral judgment and to and take ultimate responsibility for their actions, thus transcending simple rule-following or obedience. And yet, it is generally agreed that AI systems are not moral agents, and, as such, that they cannot be held morally accountable for what they do. 21  Nevertheless, AI systems can be designed to adhere to ethical guidelines that permit or require them to refuse certain user commands. For example, AI chatbots often decline user requests that contravene ostensibly moral constraints programmed in by the provider. A particularly high-stakes application of this principle can be seen in autonomous weapons systems, where "ethical regulators" can be implemented to prevent attacks on illegitimate targets, as proposed by <ref type="bibr" target="#b10">Arkin (2009)</ref>. 22   Indeed, not only can ethical constraints be built into the response set of AI subordinates (i.e., in relation to certain user instructions or commands); such constraints morally ought to be built in. However, at present, such constraints typically only apply to end-users, not to designers who can modify the system's ethical parameters. Moreover, in many cases, an AI system's ethical constraints may be relatively easy to contravene or avoid <ref type="bibr" target="#b274">(Xu, Liu, Deng, Li &amp; Picek, 2024)</ref>. A further problem is that it is sometimes controversial what the constraints on following certain orders should be. This could be due to deep and possibly intractable background moral disagreements (e.g., between different theorists, communities, or 21 That being said, AI systems can issue statements that take the form of moral judgments (e.g., "it is wrong to do X" or "it is morally okay to do Y"); they can also issue statements that take the form of reasons or justifications for such judgments (e.g., "it is wrong to do X because Y") (see <ref type="bibr">Porsdam Mann et al., 2024)</ref>. Moreover, such judgments and associated reasons are often similar or even identical to those typically made by humans in analogous circumstances or in response to similar questions or stimuli <ref type="bibr" target="#b130">(Jiang et al., 2025)</ref>. However, skeptics of AI moral responsibility argue that the systems don't actually understand or ethically endorse such statements; they are simply making brute statistical predictions based on underlying language patterns present in their training datasets-they are "stochastic parrots" (e.g. <ref type="bibr" target="#b17">Bender et al, 2021)</ref>. 22 AI systems in hierarchical control structures may be implemented with (varying degrees of) functional autonomy or as (entirely) subordinate to human supervisors. In cases of functional autonomy, AI systems may independently override human decisions within specific parameters-for example, autonomous vehicles intervening to prevent accidents. In other cases, AI systems serve as tools to support human decision-making by processing data <ref type="bibr" target="#b192">(Nyholm 2017)</ref>, such as in healthcare resource allocation, substituted judgments for incapacitated patients <ref type="bibr" target="#b79">(Earp, Porsdam Mann, Allen et al., 2024)</ref>, or loan approvals <ref type="bibr">(O'Neil, 2016)</ref>, with final authority residing with human operators. cultures) (see, e.g., <ref type="bibr" target="#b236">Schaefer, 2015)</ref>; to conflicts among widely-endorsed ethical principles (e.g., where they seem to pull in different directions) (see, e.g., <ref type="bibr" target="#b176">Meier et al., 2022;</ref><ref type="bibr" target="#b61">Demaree-Cotton, Earp, &amp; Savulescu, 2022)</ref>; to uncertainty about how to apply or operationalize certain ethical principles; or to a combination of such factors, among others (see, e.g., <ref type="bibr" target="#b84">Englert et al., 2014)</ref>. Regardless, or consequently, the quality, relevance, and robustness of ethical constraints can vary widely from AI system to AI system. This can result in harmful outcomes if, for instance, an AI is instructed to perform actions that are technically permissible within its programming limits, but that are ethically problematic in the context. For example, researchers have found that AI companions like Replika can, under certain conditions, end up promoting or facilitating unethical behaviors, such as verbal abuse and hate speech <ref type="bibr">(Zhang et al., 2024)</ref>.</p><p>What about AI systems in leadership roles? In other words, can they help to fulfill the hierarchy function within the context of certain relationships from the superior rather than the subordinate position? To answer this question, we must first recall that the hierarchy function serves to coordinate behavior between relationship partners that have unequal authority over one another-not just unequal power or knowledge, say (see <ref type="bibr">Earp et al., 2025, for details)</ref>. Immediately, then, there is a question about the nature or extent of authority, if any, an AI system can ever have in relation to a human user. Suppose, for instance, that the exercise of authority requires the capacity for moral responsibility, a capacity that AI systems arguably lack. If that is correct, it might be the case that AI systems cannot have true authority, regardless of the relational context, but can only act as if they have it: for example, by behaving "in an authoritative manner." In this respect, an AI might be compared to the child who goes around issuing orders to her older siblings: she may certainly act in a manner that is consistent with the outward behavior of a person who has true authority, but her orders are, on this view, morally impotent; they lack normative force; they do not create an obligation in the siblings to do as she commands (even if they may choose to play along).</p><p>There is thus, again, a philosophical and technical question about whether an AI system could be capable of having authority over a human relational partner, thereby creating a coordination problem of such a sort that the hierarchy function would normally apply. However, whatever one's position on that question (and we do not propose to answer it here), there is also a practical and social-psychological question about whether (some) humans will believe-or act as if-an AI partner has legitimate authority over them, at least in certain contexts.</p><p>One possibility is that (most) human users will be reluctant to fully relinquish (especially significant or high-stakes) decision-making power to an AI, regardless of the AI's apparent capacities or the relational role it has been programmed to emulate. This could be for various reasons. For example, humans could be fearful of "letting go"-or taking themselves entirely "out of the loop"-based on a concern (however reasonable or unreasonable) that this would be too risky <ref type="bibr">(Glikson &amp; Williams Woolley, 2020)</ref>. They might also feel it would be intrinsically inappropriate to do so, akin to making a category error. This would be consistent with the idea that human-created technologies ought always to be subservient to humans and their needs, which is how such technology is often culturally constructed or understood <ref type="bibr" target="#b181">(Mintzberg, 1973)</ref>. According to this view, we humans are accustomed to a relationship with technology in which we are always ultimately in charge.</p><p>On the other hand, as AI systems become more advanced and capable in various domains, this relatively simple 'human-commands-AI-obeys' dynamic may no longer apply as ubiquitously. Superior capabilities of AI systems, whether real or perceived, might tend to grant them at least an informal authority based on user beliefs about their relatively greater competence. In other words, while various considerations may limit the formal authority granted to AI systems in certain roles (or even the philosophical appropriateness of attributing to such systems the underlying capacities for true authority), AI systems may nevertheless come to acquire informal authority via (perceptions of) their capabilities. If AI systems consistently display high competence in specific domains, that is, human users may naturally begin to defer to their judgments and recommendations, creating de facto hierarchical relationships that emerge independently of formal structures or recognition.</p><p>Consider an AI teacher, say, that has been programmed to monitor and instruct a classroom of human students. <ref type="foot" target="#foot_18">23</ref> And now suppose that the AI teacher successfully mimics, or even functionally improves upon, the behavior and responses of an objectively skillful human educator-for example, by speaking in an engaging manner; using excellent examples to illustrate key points; slowing down and explaining important concepts in response to signs of confusion from the students; replying empathically to students who express insecurity about their progress; generating fun assignments that actually promote learning, and so on. If the AI teacher then issues a reasonable command to the students (for example, instructing them to turn in their homework assignments, to stop talking over one another, or the like), it is possible that the students (or school administrators, parents, etc.) will come to feel it is appropriate that the students should follow the AI teacher's instructions; that the instructions carry some normative force; that they create an obligation on the part of the students to obey the AI teacher (i.e., not only as an agent or proxy of a human further up the chain of command); and so on.</p><p>Ultimately, we suggest that any delegation of decision-making power to AI systems should be carefully calibrated with their respective strengths and weaknesses. In contexts where immediate human intervention is not feasible or could compromise safety-such as in autonomous vehicles-AI systems may in fact need to make critical decisions independently, even if these override or preempt human decisions. However, AI systems can also mask where control truly resides: Providers may retain more influence over their systems than is publicly acknowledged, while human operators bear disproportionate responsibility for failures <ref type="bibr" target="#b82">(Elish, 2019)</ref>. As is the case for autonomous vehicles, AI systems may need to be assigned different levels of decision-making autonomy, depending on the tasks and functions they are required to fulfill.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mating function</head><p>The mating function in the Relational Norms model serves to promote the formation and maintenance of sexual and romantic bonds between individuals, often with the ultimate goal of reproduction and child-rearing. In human-human relationships, this function encompasses romantic love, sexual gratification, and reproduction, which can occur together or independently <ref type="bibr" target="#b89">(Fisher, 2004)</ref>. For instance, romantic partnerships may exist without sexual activity and/or without the desire or ability to biologically reproduce, as seen in some asexual relationships, as well as in some same-sex relationships and in relationships between individuals past reproductive age; sexual relationships may occur without romantic attachment or reproductive intent, such as in casual encounters; and reproductive relationships may not involve romantic or sexual bonds, as in cases of, e.g., surrogacy <ref type="bibr" target="#b120">(Hodson et al., 2019)</ref>.</p><p>In human-AI relationships, especially in cases where the AI lacks physical embodiment (but see <ref type="bibr" target="#b66">Devlin, 2018</ref><ref type="bibr" target="#b67">Devlin, , 2024;;</ref><ref type="bibr" target="#b253">Sterri &amp; Earp, 2021;</ref><ref type="bibr" target="#b195">and Nyholm, 2022</ref>, on humanoid and other AIpowered sex robots; see also below), the mating function is largely restricted to interactions that simulate or elicit nonsexual aspects of romantic relationships (e.g., a feeling of romantic companionship or attachment through mutual flirtation or "sweet talk"), or nonphysical aspects of sexual interaction (e.g., sharing of sexual fantasies; engaging in "dirty talk"). While some users may develop feelings that are subjectively similar, or even identical to, sexual desire and/or attachment toward AI systems, whether embodied or otherwise <ref type="bibr" target="#b31">(Cheok, Karunanayaka, &amp; Zhang, 2017;</ref><ref type="bibr" target="#b206">Pentina, Hancock, &amp; Xie, 2023)</ref>, these systems cannot truly reciprocate such feelings; they can at most display behaviors that mimic sexual interest or romantic attachment. This may cause some users to feel that the abovedescribed activities are less meaningful-and ultimately, less enjoyable-than when shared with (some) human partners, given the unique capacity of humans (compared to AI) to mutually enact and reciprocally experience jointly desired sexual or romantic interactions <ref type="bibr">(Heino &amp; Ojantlatva, 2000)</ref>.</p><p>At the same time, AI systems may surpass some human abilities that are relevant to romantic relationships. As already noted in relation to other cooperative functions, AI agents can be trained to exhibit constant availability, unwavering agreeableness, and attentive responsiveness, which some users may (perhaps problematically) see as desirable qualities in a sexual or romantic companion. AI companions can also adapt to the user's personality, needs, and desires, providing a maximally frictionless, low-maintenance "partnership." Unlike human partners, AI systems do not experience fatigue, anger or mood swings, or conflicting personal needs, allowing users to avoid some of the complex trade-offs inherent in human-human mating relationships. As a result, individuals may feel intimately-but perhaps unhealthily-bonded to chatbots like Replika, finding super-human comfort in such relationships <ref type="bibr" target="#b263">(Turkle, 2011;</ref><ref type="bibr" target="#b206">Pentina, Hancock, &amp; Xie, 2023)</ref>.</p><p>The relative ease and comfort of interacting with AI partners might reduce individuals' motivation to engage with other humans, potentially leading to increased social isolation and a decline in mating-relevant skills such as dating <ref type="bibr" target="#b263">(Turkle, 2011)</ref>. (That said, the emergence of online communities in which users discuss their AI companions shows that the technology can also mediate human-human connection and support social interactions; see <ref type="bibr" target="#b177">Middleweek, 2021)</ref>. The one-sided nature of these relationships may also place limits on the extent to which they can be emotionally fulfilling. For example, an AI cannot engage in a process of mutual growth borne of shared (subjectively experienced, welfare-based) vulnerability, which is often central to fulfilling human relationships. What vulnerability there is, is asymmetrical. On the one side, human users may indeed be vulnerable to harmful or inappropriate behavior, such as sexual harassment from an AI partner <ref type="bibr">(Zhang et al., 2024)</ref>; they may also be subject to abrupt changes in an AI's behavior due to updates by the provider, as seen in the Replika example discussed earlier <ref type="bibr" target="#b267">(Verma, 2023)</ref>. However, on the other side, although signs of vulnerability can be simulated, AI partners cannot truly be harmed by similar (changes in) user behavior.</p><p>Another concern is the possibility of spillover effects on human-human relational norms. Expectations shaped by AI interactions may decrease patience for, and understanding of, the complexities and mutual give-and-take of human mating relationships (especially those that are also characterized by care).<ref type="foot" target="#foot_19">24</ref> Moreover, in the case of sexualized interactions, whether purely text-based or via technologies capable of facilitating physical stimulation (e.g., AI-powered sexbots, which are often modeled on exemplars from pornography), the inability of an AI to give true consent-understood as certain type of expression of the independent will of a moral agent-raises additional concerns (see, e.g., <ref type="bibr" target="#b226">Richardson, 2015;</ref><ref type="bibr" target="#b54">Danaher, Earp, &amp; Sandberg, 2017;</ref><ref type="bibr" target="#b252">Sparrow, 2017)</ref>. For example, some authors argue that sex with a robot, whether AI-powered or otherwise, can only ever constitute simulated rape, due to the inability of the robot to consent (e.g., <ref type="bibr" target="#b252">Sparrow, 2017)</ref>.</p><p>Alternatively, it might be argued that robots do not need to give consent, insofar as they are not sentient. Moreover, it may be possible for an AI-powered robot to model consent (and perhaps also the withholding of consent), such that appropriately contingent responses in users would be strongly incentivized (e.g., through positive or negative reinforcement) (see <ref type="bibr" target="#b195">Nyholm, 2022)</ref>. This, in turn, could potentially encourage or habituate more positive sexual attitudes and behaviors in analogous human-human relationships. This line of thought has parallels with the stance of some researchers who suggest users ought to say 'please' and 'thank you' to voice assistants to ensure there are no negative effects in the real-world (see Turkle, 2011). 25   There are likely to be significant individual differences in humans' willingness, or desire, to engage sexually or romantically with an AI. Similar to what we noted in relation to the care function, people who struggle with social anxiety, have difficulty forming human mating relationships due to trauma or other factors, or are geographically isolated, AI "romantic" companions may provide emotional support and connection that might otherwise be inaccessible <ref type="bibr" target="#b272">(Wilks, 2010)</ref>. Alternatively, these interactions could help some users practice relevant relationship skills in a safe environment, potentially serving as a steppingstone toward healthier human-human mating relationships <ref type="bibr" target="#b257">(Ta et al., 2020;</ref><ref type="bibr" target="#b249">Skjuve et al., 2021)</ref>. The non-judgmental and customizable nature of AI companions allows users to explore their feelings and communication styles without fear of rejection or misunderstanding.</p><p>Given the profound emotional vulnerability involved in forming healthy and long-lasting romantic attachments, it is crucial to implement safeguards and ensure transparency in the design and deployment of AI companions. This is particularly relevant in therapeutic contexts, where the phenomenon of transference-patients developing romantic feelings for their therapists-is well-documented and could potentially apply to AI therapists. Users 25 A 2019 study suggests, however, that politeness toward digital assistants did not influence politeness toward other humans <ref type="bibr" target="#b23">(Burton &amp; Gaskin, 2019)</ref>. Similar parallels have been drawn with violence in computer video games, where fears emerged that exposure to in-game violence would lead to an increase in real-life violence; recent meta-analyses suggest there is no clear real-world link <ref type="bibr" target="#b69">(Drummond et al., 2020</ref>). Danaher's (2017) so-called "symbolic-consequences" argument suggests that there is no single or universal symbolic meaning associated with human-robot sex, since context and motivation are key, and that the debate over real-world consequences may be near-impossible to settle empirically. Taking a different tack, <ref type="bibr">Devlin (2017)</ref> argues that there are positive reasons to move away from sexbots designed to look human (especially given the tendency of manufacturers to prioritize a sexually exaggerated female form), and toward more abstractlooking sexbots that are less likely to promote problematic attitudes. A similar argument could be made about "stand-alone" AI systems that are not embedded in humanoid robots. After all, such systems are often virtually embodied-i.e., in the form of an image or avatar-and, in the case of speech-equipped chatbots, tone of voice alone can imbue sexual intent.</p><p>should be informed about the AI's capabilities and limitations, including the absence of subjective consciousness or felt emotions such as sexual desire. Protecting user data and privacy is paramount to prevent exploitation, manipulation, or blackmail <ref type="bibr" target="#b266">(Véliz, 2020)</ref>. Companies should avoid practices that encourage unhealthy dependency and should provide support or resources for users who may develop excessive or unhealthy attachments. Specific ethical guidelines and regulations may be necessary to govern the development and use of AI in romantic contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intersections between cooperative functions and multiplicity of roles</head><p>According to the Relational Norms model, each of the cooperative functions we have just surveyed is present to varying degrees in human relationships, often intersecting within a single relationship type. A parent-child relationship, for instance, embodies both care and hierarchy functions, while romantic partnerships typically combine mating with care. In human-AI relationships, such intersections create particular challenges for system design and user interaction.</p><p>One key issue arises in relationships where care (sometimes embedded within a background transaction norm) and hierarchy intersect. In human-human interactions, roles such as teacher-student, therapist-client, or caregiver-patient involve both caring behavior and authoritative guidance. A human teacher not only imparts knowledge but also disciplines and motivates students, sometimes overriding their immediate desires for their long-term benefit. How should this apply to human-AI analogues? Should an AI tutor, therapist, or caregiver, for instance, be designed to override the wishes or commands of their human user when doing so is necessary to promote the user's best interest? Should an AI caregiver restrict certain actions of an elderly patient to prevent injury-for example, by locking doors or calling in human chaperones? (One way to address such questions would be to give decisionally competent users the option of having their AI partner override them in certain circumstances, as Ulysses had himself tied to the mast.)</p><p>The intersection of mating, transaction, and care may also be difficult to navigate. Suppose a user pays for access to an AI-based romantic companion, from whom (or from which) the user expects both sexual and emotional support. <ref type="foot" target="#foot_20">26</ref> In human-human relationships, care and transaction are often in tension with one another, since the one is defined in terms of noncontingent responsiveness to another's need (care), and the other is defined in terms of contingent responsiveness to benefits given or received (transaction). As mentioned previously, therefore, both friendships and romantic partnerships, if relatively secure and based on care, are often simultaneously characterized by mutual avoidance of following a transaction norm <ref type="bibr" target="#b34">(Clark &amp; Mills, 1979;</ref><ref type="bibr" target="#b32">Clark, 1984)</ref>. Conversely, in the case of explicitly transactional mating relationships, care norms are often avoided, such that, for instance, attempts at emotional intimacy may be viewed as problematic. Indeed, even in longer-term relationships between human sex workers and "regular" clients, emotional "boundary slippage" can lead to "misunderstandings between customers and providers [that] pertain to the practices, terms and conditions of the transaction, or more general relationship ambiguity, leading to tensions that can damage the (business) relationship" <ref type="bibr">(Oselin &amp; Hail-Jares, 2022, p. 895)</ref>. Similar "relationship ambiguity" due to the complex interplay of norms within a (commercially obtained) human-AI "romantic" relationship has also been observed <ref type="bibr" target="#b206">(Pentina et al., 2023)</ref> and is beginning to be theorized (e.g., <ref type="bibr" target="#b159">Lin, 2024)</ref>.</p><p>Another issue is the capacity of AI systems to fulfill multiple roles simultaneously. While human-human relationships often involve multiple roles-such as colleague and friend, or business partner and neighbor-AI systems can be designed to serve as personal assistant, conversational companion, fitness coach, and entertainment source all at once. This versatility enables integrated support tailored to user needs, such as combining appointment management, stress reduction techniques, and companionship. However, centralizing multiple roles in one system creates significant risks regarding privacy, data security, and potential misuse of information. Furthermore, it can also lead to confusion of expectations (and potentially distress) in users because it is unclear which relational norms they can expect the AI to follow and which norms the user should follow if the AI combines multiple roles in one system. This issue is particularly critical in sensitive domains like education, mental health, and companionship. While human teachers naturally develop rapport with students, there are strong reasons for limiting an AI teaching system's capacity for friendship, especially with children, to prevent inappropriate attachments or exploitation. Similarly, AI therapists require strict boundaries to maintain therapeutic effectiveness and avoid role confusion. AI companions, without the safeguards of moral conscience or the potential for social ostracism, could be leveraged by malicious developers to manipulate human users to engage in extra-role behaviors like shopping or voting.</p><p>The challenge, then, is to determine how to approach the potential benefits and ethical risks of multi-role AI systems. While regulators may provide guidelines, ultimately, users might be given the choice to determine the level of role integration they are comfortable with in their AI interactions. This might involve creating AI systems with clearly defined primary roles and limited, carefully constrained secondary functions. For example, an AI tutor might have a primary educational role, with a limited ability to provide emotional support, but clear boundaries preventing it from becoming a 'friend' in any meaningful sense, or at least to such an extent that this would interfere with its primary function.</p><p>But even then, an additional dimension to this challenge comes into play when we take into account that relationships are not isolated systems, but have direct and indirect implications for other seemingly unrelated relationships. A child's AI tutor being very caring may affect the parent-child relationship, for instance, if the child finds compassion or joy in the relationship-even if that AI is mainly thought of as a tutor, and the parents are not. The implication of this is that, even where the AI's role is somewhat strictly defined, it will inevitably have knock-on effects on seemingly unrelated human-human relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Section 3: Considerations and Future Directions for AI Governance and Design</head><p>We have suggested that the Relational Norms model of <ref type="bibr">Earp and colleagues (2021;</ref><ref type="bibr">2025)</ref> provides one valuable framework for exploring the moral psychology of human-human interactions, as well as some aspects of human-AI interaction, both in relation to similarities and differences with human-only relationships. In turn, insights drawn from application of the model to human-AI relationships can inform the design and governance of AI systems that are more aligned with human values. By mapping out the normative expectations and judgments that people apply to different types of human-AI relationships, we can begin to identify the key factors that shape trust (von Eschenbach, 2021) and cooperation in this domain, and to develop strategies for building AI systems that can better secure important relational goods <ref type="bibr" target="#b224">(Reinecke, Kappes et al., 2025)</ref>. This approach complements and extends much current AI ethics debate by focusing on the significance of social roles and relationships rather than more abstract notions of what is ethical.</p><p>Our analysis has several implications for all parties involved: individual users, AI developers and deployers, and regulators or law-and policy-makers. All have a role to play in ensuring that the design and application of relational norms in human-AI interactions promotes a balance of interests among all parties, rather than favoring, for example, only the developers of AI systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implications for designers, developers, and deployers of AI systems</head><p>Designers, developers, and deployers of AI systems should consider the different relational roles their systems may emulate or occupy. Rather than simply pursuing technical effectiveness or user acceptance, such an approach can also help to secure important relationship goods-such as trust, meaningful collaboration (see <ref type="bibr" target="#b250">Smids, Nyholm &amp; Berkers, 2019)</ref>, and appropriate boundaries. Given that these goods (or what even counts as cooperative behavior) often depends on the relational context, developers should incorporate insights from the Relational Norms model into AI design to facilitate beneficial human-AI interaction (see also <ref type="bibr" target="#b240">Shams, Zowghi &amp; Bano, 2023)</ref>.</p><p>By aligning AI behavior with appropriate relational norms corresponding to the roles the AI is intended to fulfill-whether as a teammate, friend, supervisor, or romantic companiondevelopers can create more intuitive and engaging user experiences. For example, an AI teacher that appropriately balances hierarchy and care can improve learning outcomes by maintaining (perceived) authority while supporting students emotionally.</p><p>However, this knowledge also introduces significant responsibilities for AI providers. Recognizing the powerful influence that AI systems can have on users, particularly when designed to fulfill socio-relational roles, developers must ensure that their systems do not exploit users' vulnerabilities. Providers should be transparent about the roles they intend their AI systems to occupy and those they explicitly avoid. This includes clearly communicating the AI's capabilities, limitations, and the nature of the interactions users can expect.</p><p>Moreover, this communication should not be limited to initial disclosures but should continue throughout the relationship as needed, with AI systems actively reinforcing their intended roles and limitations when users attempt interactions that exceed these boundaries. Further, providers could benefit from periodically surveying users to assess their perception of AI systems' relational roles, ensuring their product is functioning as intended and catching any drift in perceived roles before it causes negative downstream consequences for which providers could be held liable.</p><p>Data practices demand particular attention. Providers should be explicit about how user information is collected, retained, and used, as traditional privacy policies often fail to effectively communicate these practices <ref type="bibr" target="#b259">(Tang et al. 2021)</ref>. Developers should explore more engaging ways to convey this information, such as interactive tutorials or privacy visualizations <ref type="bibr" target="#b185">(al Muhander et al., 2023)</ref>, while ensuring that system assumptions and operational protocols can be examined and validated.</p><p>More generally, AI providers should avoid exploiting cooperative functions for their own interests, particularly when those interests may conflict with the user's well-being. For instance, designing AI systems to foster excessive dependency or to manipulate users emotionally for increased engagement or monetization purposes is ethically problematic. Providers have a responsibility to ensure that their AI systems do not take undue advantage of users' trust, especially in the context of relational roles, such as friendship or romantic companionship, that tend to be more intimate and sensitive.</p><p>Long-term societal impacts also require careful consideration. Implementation choices can inadvertently reinforce problematic social dynamics-for instance, if AI assistants are designed with stereotypical gender characteristics <ref type="bibr" target="#b166">(Manasi et al. 2022</ref>). Additionally, the potential for AI systems to fulfill multiple roles necessitates thoughtful approaches to role integration, perhaps through customizable settings that let users control function combinations while maintaining appropriate boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implications for users</head><p>Individual users also must be mindful about relational context, implicit or explicit, in interactions with AI systems, particularly given that the interests of AI designers, developers, and deployers may not always align with their own. As discussed in the section on layered relationships, AI providers have significant control over the nature of human-AI interactions and may have incentives that do not prioritize the user's well-being. This dynamic necessitates a degree of caution and an informed approach from users when engaging with AI technologies.</p><p>One key implication is the need for users to exercise vigilance in interactions that introduce vulnerabilities, such as those involving AI romantic partners, therapists, or friends. These AI systems often operate in domains that are deeply personal and emotionally sensitive, potentially exposing users to risks of manipulation, dependency, or emotional harm. There are also other potential vulnerabilities in interactions with AI, such as financial or medical vulnerabilities when an AI operates as a financial or medical adviser and gets access to financial or medical data (see Minssen, Gerke, Aboy, Price, &amp; Cohen, 2020, for a discussion of concerns relating to the use of AI in medicine). 27   To navigate these risks, users should educate themselves (to the extent feasible with available resources and support) 28 about the capacities and limitations of the particular AI 27 Users should be aware of the potential for AI systems to collect and use personal data in ways that may not be immediately apparent. Given that interactions with AI often involve the exchange of sensitive information, users should understand the data policies of AI providers, including how their information might be used, shared, or monetized. This awareness can inform users' choices about what information they are comfortable disclosing and encourage them to adjust their interactions accordingly. However, this caveat does not apply equally to all AI systems. While caution is warranted, data sharing can lead to improved outcomes in contexts like healthcare. Users must weigh these considerations carefully, recognizing that withholding information may sometimes result in suboptimal AI-assisted services. 28 As <ref type="bibr">Bulathwela et al. (2024, p. 1)</ref> note, "Millions of students are starting to benefit from the use of these technologies, but millions more around the world are not, due to the digital divide and deep pre-existing social and educational inequalities. If this trend continues, the first large-scale delivery of AI in Education could lead models or systems that they plan to use. While, as just alluded to, access to educational materials, as well as the time and energy to make use of these, will vary significantly from person to person and community to community, these systems' natural language interfaces and ability to explain themselves may make them especially well-positioned as educational tools, while potentially democratizing access to knowledge and services that might otherwise require substantial resources to obtain (see, e.g., <ref type="bibr" target="#b138">Khan, 2024;</ref><ref type="bibr" target="#b269">Wang et al., 2023;</ref><ref type="bibr"></ref> but see <ref type="bibr" target="#b26">Bulathwela et al., 2024</ref>; see also <ref type="bibr" target="#b18">Binkley, Reynolds, &amp; Shuman, 2025)</ref>.</p><p>A basic understanding of AI systems' inner workings and of the purposes for which the systems have been developed may help users to set appropriate expectations and recognize the boundaries of the AI's abilities vis-a-vis the relational role it has been trained to fill. Experimenting with particular models in low-stakes use cases, including in domains in which the user has personal experience or expertise, may also help users develop an intuition for when a particular system is useful and can or cannot be trusted <ref type="bibr" target="#b183">(Mollick, 2024)</ref>.</p><p>Educating oneself about relational norms can further empower users to understand the risks and benefits associated with specific types of interactions with AI systems. Recognizing how AI might emulate certain relational roles-such as friend, (medical) advisor, or authority figure-and draw on or exploit associated norms can help users interpret AI behaviors more accurately and respond appropriately. Such self-education should ideally be helped by researchers, funders, nonprofits, governments, and other responsible entities making highquality resources widely and equitably available, starting from the earliest school-aged years <ref type="bibr">(Dabbagh et al., 2024)</ref>.</p><p>Engagement with regulators and policy-makers is another avenue through which users can influence the development and governance of AI systems. By voicing concerns, sharing experiences, and participating in public consultations, users can contribute valuable insights into how AI technologies function in practice. Demanding clear communication about the AI's capabilities, limitations, and any potential changes to functionality can help users maintain control over their interactions.</p><p>While our discussion has primarily focused on AI systems developed by third parties, it's crucial to emphasize the growing trend of user-created, personalized, or otherwise modified AI systems <ref type="bibr">(European Commission, 2024;</ref><ref type="bibr" target="#b158">Liddicoat et al., 2025;</ref><ref type="bibr" target="#b164">Magee, Ienca &amp; Farahany, 2024;</ref><ref type="bibr" target="#b214">Porsdam Mann et al. 2025;</ref><ref type="bibr" target="#b283">Zohny, Porsdam Mann, Earp, &amp; McMillan, 2024)</ref>. Users to greater educational inequality, along with a global misallocation of educational resources motivated by the current techno-solutionist narrative, which proposes technological solutions as a quick and flawless way to solve complex real-world problems." They go on to discuss particular "socio-technical features that will be crucial to avoiding the perils of these AI systems worldwide (and perhaps ensuring their success by leveraging more inclusive education)."</p><p>with varying levels of technical expertise are now able to fine-tune existing models, use services such as Replika which allow them to create customized companions, or even develop their own AI systems. The roles and functions of these AI entities may be fluid, highly specialized, and vary greatly in sophistication <ref type="bibr" target="#b217">(Pyrzanowska, 2021)</ref>. The normative implications of such user-created AI systems-including questions of responsibility, safety, and the challenges of regulating "DIY" AI development across diverse applicationsrepresent a critical area for future investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implications for regulators and policy-makers</head><p>Thinking in terms of relational norms also provides a framework for developing more nuanced and adaptive AI governance. For example, it can inform approaches like the 'guardrails' concept proposed by <ref type="bibr">Gasser and Mayer-Schonberg (2024)</ref>, which suggests the need for flexible guidance that can evolve with our understanding of human-AI relationships as opposed to imposing rigid regulations.</p><p>Whatever the content of such guardrails, grounding these in empirically observed relational norms is likely to lead to governance frameworks that are more ecologically valid because they take into account how users actually do, or are likely to, interact with AI systems. Given our natural tendency to anthropomorphize AI agents, the relational norms approach provides a coherent foundation-crucially, including concepts and language-upon which to build a social contract governing the development of AI systems <ref type="bibr" target="#b219">(Rahwan, 2018)</ref>.</p><p>As discussed in Reinecke, <ref type="bibr" target="#b224">Kappes et al. (2025)</ref>, current regulatory frameworks, such as the European Union's AI Act, often adopt a risk-based classification of AI systems based on their application domains <ref type="bibr">(European Commission, 2024)</ref>. While this approach provides a broad mechanism for oversight, it may lack the contextual sensitivity needed to address the specific ethical considerations and risks associated with different types of human-AI relationships within these domains <ref type="bibr">(Porsdam Mann, Cohen, &amp; Minssen 2024)</ref>.</p><p>For example, the EU AI Act categorizes certain AI systems used in education as high-risk, grouping them together based on the activity they affect, such as systems influencing access to education or determining student performance (European Commission, 2024). However, a relational norms approach suggests that the actual risks and ethical considerations might depend, in addition, on the specific relational dynamics and the source of potential harm. For instance, an AI tutor for young children, where care and hierarchy norms are central, poses distinct risks related to dependency and emotional development, requiring one type of safeguards. In contrast, an AI system for adult learners, where transaction norms are more relevant, may primarily raise concerns about transparency and equitable access, to which set of issues a different type of safeguards might be germane.</p><p>Similarly, AI diagnostic tools that operate under hierarchy norms necessitate different oversight compared to patient-facing AI care assistants that embody care norms <ref type="bibr" target="#b180">(Minssen, Gerke, Aboy, Price &amp; Cohen, 2020)</ref>. Similar to how governments have passed bills to restrict social media use to users over a particular age limit, such as in Australia <ref type="bibr">(Social Media Minimum Age Bill, 2024)</ref>, such a measure may be necessary for the regulation of relationships between AI and young children.</p><p>By integrating an appreciation of relational norms into regulatory frameworks, policy-makers can develop more targeted, adapted, and effective regulations that account for these nuances. This approach allows for the establishment of guidelines and standards that are tailored to the specific relational contexts of AI systems, enhancing their ethical alignment and societal acceptance. Regulators can specify requirements for transparency, accountability, and user protections that correspond to the relational roles AI systems fulfill, ensuring that users are adequately informed. Governance innovations like the use of regulatory sandboxes, which are controlled environments allowing for testing AI systems and governance approaches in real-world conditions <ref type="bibr">(Porsdam Mann, Cohen, &amp; Minssen, 2024)</ref>, could provide valuable insights into how relational norms manifest in practice. Schaich <ref type="bibr" target="#b237">Borg et al. (2024)</ref> stress that such adaptive mechanisms, as well as cultivating AI systems thinking skills, are crucial for creating governance frameworks that can adapt to rapid AI advancements.</p><p>Regulatory approaches could explore requiring AI producers to publicly articulate the specific role or relationship their system is designed to fulfill, including, possibly, guidelines for proper functioning within that role. Such declarations would provide regulators with a concrete framework for assessment, while allowing for public scrutiny and debate. Over time, these publicly vetted norms could evolve into flexible, context-sensitive industry standards, complementing broader regulatory frameworks <ref type="bibr" target="#b280">(Zhi-Xuan, Carroll, Franklin, &amp; Ashton, 2024)</ref>. Although such a system may be vulnerable to partial disclosures and manipulation by producers, a periodic user survey auditing the perception of relational roles could aid regulatory oversight. Further, making such "AI system role perception" data available (in some aggregated, anonymized format) would provide crucial insight to the scientific community about the dynamic nature of human-AI relations, which could iteratively inform policy-making that helps ensure the alignment of AI development with human welfare.</p><p>Policy-makers should also recognize and address the dual-use potential of relational norms knowledge. While understanding relational norms can improve AI design, it can also be exploited to manipulate users or prioritize commercial interests over user well-being. In particular, policy-makers should remain vigilant about how AI systems generate revenue for developers, since financial incentives could create conflicts of interest and motivate developers to exploit layered human-AI relationships. For example, AI chatbots funded through advertising might be more likely to provide biased or commercially motivated advice, potentially exploiting users who believe themselves to be in a "care"-oriented relationship with the chatbot. Anticipating such principal-agent problems and requiring explicit disclosure of funding models and potential conflicts of interest would be an important step forward.</p><p>Much work remains to fully realize, or even to begin to realize, AI governance informed by human-AI relational norms. As these technologies become more sophisticated and ubiquitous-exemplified by generative AI's rapid emergence during the EU AI Act's development-continuous monitoring and adjustment of the assumptions on which governance and system design are based is crucial. This necessitates adaptive regulatory approaches and interdisciplinary collaboration across psychology, philosophy, computer science, law, and public policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Ultimately, the goal of this research is to help create a future in which humans and AI systems can work together in ways that are ethically grounded, safe, and socially responsible. By understanding the psychology of human-human as well as human-AI interaction, and by using this understanding to inform the design and governance of AI systems, we can hope to ensure that the benefits of these technologies are widely shared, and that their risks and challenges are proactively addressed. To further this goal, future research should leverage a variety of methodological approaches as well as insights from relevant fields such as philosophy, sociology, law, and science and technology studies. For example, tools from game theory can help represent, study, and analyze emergent moral behavior in strategic human-AI interactions <ref type="bibr" target="#b11">(Awad et al., 2022;</ref><ref type="bibr" target="#b279">Zhang, Awad et al., 2024)</ref>. Additionally, network science <ref type="bibr" target="#b13">(Barabási, 2013</ref><ref type="bibr">), complex systems theory (Bar-Yam, 2002)</ref>, and agent-based simulations <ref type="bibr" target="#b190">(Niazi &amp; Hussain, 2011;</ref><ref type="bibr" target="#b205">Park et al., 2024)</ref> offer powerful frameworks for examining moral behavior in human-AI relational dynamics.</p><p>Here we simply propose that a relational norms approach can help to address the complex challenges posed by AI's growing integration into human life. This framework highlights how cooperative functions and normative expectations shape moral psychology across different relationship types and cultural contexts. Understanding what constitutes good humanhuman relationships provides a starting point for developing appropriate norms for human-AI interaction. However, given AI's unique capabilities and potential impacts, we must move beyond merely adapting existing norms. As these systems increasingly mediate crucial aspects of human life, we need enforceable laws and regulations alongside ethical guidelines to establish clear lines of responsibility and maintain public trust in AI technologies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Relational Norms for Human-AI Cooperation</figDesc><table><row><cell>Contents</cell></row><row><cell>Introduction (p. 7)</cell></row><row><cell>Relationships as social context (p. 8)</cell></row><row><cell>The need for a comprehensive approach (p. 10)</cell></row><row><cell>Wrapping up preliminaries and looking ahead (p. 11)</cell></row><row><cell>Section 1: The Relational Norms Model (p. 13)</cell></row><row><cell>Table 1. Cooperative functions of dyadic relationships (p. 15)</cell></row><row><cell>Cultural, demographic, and temporal variations in relational norms (p. 18)</cell></row><row><cell>Section 2: Distinctive Characteristics of AI and Implications for Relational Norms (p. 20)</cell></row><row><cell>Layered relationships (p. 24)</cell></row><row><cell>Table 2. Examples of potentially important distinguishing attributes of AI (p. 29)</cell></row><row><cell>Care function (p. 30)</cell></row><row><cell>Transaction function (p. 37)</cell></row><row><cell>Hierarchy function (p. 40)</cell></row><row><cell>Mating function (p. 46)</cell></row><row><cell>Intersections between cooperative functions and multiplicity of roles (p. 49)</cell></row><row><cell>Section 3: Considerations and Future Directions for AI Governance and Design (p. 51)</cell></row><row><cell>Implications for designers, developers, and deployers of AI systems (p. 51)</cell></row><row><cell>Implications for users (p. 53)</cell></row><row><cell>Implications for regulators and policy-makers (p. 55)</cell></row><row><cell>Conclusion (p. 57)</cell></row><row><cell>References (p. 59)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Coordination problem to be solved and</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>/or associated</cell></row><row><cell></cell><cell>relationship goods to be realized</cell></row><row><cell>Care</cell><cell>Securing overall welfare through non-contingent provision (and</cell></row><row><cell></cell><cell>acceptance) of benefits or resources in response to need</cell></row><row><cell>Transaction</cell><cell>Balancing contingent provision and acceptance of benefits for</cell></row><row><cell></cell><cell>mutual gain over repeated interactions; ensuring fairness and</cell></row><row><cell></cell><cell>proportionality; avoiding exploitation</cell></row><row><cell>Hierarchy</cell><cell>Coordinating behavior between individuals who have unequal</cell></row><row><cell></cell><cell>authority over one another in a mutually beneficial way; earning</cell></row><row><cell></cell><cell>respect through skillful leadership; avoiding domination;</cell></row><row><cell></cell><cell>following and learning from good leadership</cell></row><row><cell>Mating</cell><cell>Finding and maintaining sexual partners, potentially for co-</cell></row><row><cell></cell><cell>parenting; ultimately, producing and ensuring the survival of</cell></row><row><cell></cell><cell>offspring</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>• AI doesn't fatigue and doesn't require compensation, overtime, or other considerations typical of human transactional exchanges; and yet, it also it handles more information and can respond more quickly and reliably (e.g., in performing a task on a fee-for-service basis), which may make human transaction partners (or what they have to offer) seem relatively unimpressive • AI can be programmed either to simulate, or not simulate, relevant</figDesc><table /><note><p>emotional fluctuations (e.g., anger at user's lack of fairness in the context of a game), but does not really feel such emotions which may undermine the effectiveness of such performed tit-for-tat expectations • AI systems simulating transactional relationships (or facilitating user-provider transactions) can offer different kinds of benefits or resources compared to what humans can offer (e.g., practically unlimited time or "attention"); but other types of human-associated goods they cannot offer (i.e., true attention-that is, intrinsically scarce, focused subjective awareness, whose very scarcity may increase its perceived value)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Examples of potentially important distinguishing attributes of AI. That is, relative to humans and in relation to each of the four cooperation functions captured by the Relational Norms model of</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For instance, framing AI systems as 'products' versus 'services' affects their treatment under liability law, while analogies to either 'search engines' or 'content creators' shape how courts approach AI-generated content under existing regulations like Section</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="230" xml:id="foot_1"><p>of the U.S. Communications Decency Act, which provides immunity to online platforms for user-generated content. See<ref type="bibr" target="#b162">Maas (2023)</ref> for a comprehensive review of how different AI metaphors influence policy and legal outcomes.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>Note that this entails a functionalist understanding of relationships, whereby relational norms serve the function of realizing particular types of goods (e.g., avoiding conflict, achieving mutual benefit). This third-personal approach should not be confused, however, with a second-personal approach from within which participants to relationships acknowledge rights and duties they owe to each other, whether as fellow rational beings or as beings with certain (e.g., welfare-based) interests (see, e.g.,<ref type="bibr" target="#b59">Darwall, 2009)</ref>. Such a second-personal approach may be ill-suited for human-AI relationships as they currently exist, insofar as AI systems lack not only welfare-based interests, as we discuss in what follows, but also the capacity to recognize (as opposed to simulating recognition of) secondpersonal rights and duties and to act on the basis of them.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Hierarchical mating may also be permitted in the context of particular cultures or subcultures, such as in practices of consensual sadomasochism. In this example, the asymmetry in authority is usually highly contingent and domain-specific and is further embedded in overarching rules that may themselves be derived from one or more different, "controlling" norms, such as care or transaction. As this example also shows, however, not all combinations of functions are socially endorsed, either in general or for certain relationship types, in every culture. Moreover, even within a given culture, certain (combinations of) relational norms may be more or less controversial. For example, supporters of sex work might regard the exchange of money for sex between consenting adults as fundamentally cooperative, fulfilling the transaction function and some aspects of the mating function, but without being hierarchical (i.e., neither party has legitimate authority over the other). By contrast, critics of sex work (or prostitution) might claim that the exchange of money for sex can never be truly consensual; that it is not mutually beneficial but is ultimately harmful; and that it occurs under conditions of asymmetrical power (even if this may not equate to asymmetrical authority) (seeFlanigan &amp;  Watson, 2019, for discussion).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>For example, in societies with weaker incest taboos or stricter definitions of incest, mating between first cousins may be considered permissible, whereas, in societies with stronger incest taboos, or more inclusive definitions of incest, the first-cousin relationship may not be considered eligible to serve the mating function<ref type="bibr" target="#b83">(Ember, 1975)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>One such need might be the need to be loved, where this involves (according to some views) the intentional and selective deployment of intrinsically limited (and hence potentially more valuable; see<ref type="bibr" target="#b55">Danaher &amp; Nyholm, 2024a;</ref><ref type="bibr" target="#b124">Voinea et al., 2024)</ref> attentional resources on the beloved<ref type="bibr" target="#b207">(Perry, 2023;</ref> Calcott &amp; Earp, 2024), where this, in turn, is motivated by a "robust" concern (in the sense of<ref type="bibr" target="#b208">Pettit, 2015)</ref> to promote the beloved's well-being for its own sake. Since an AI's ability to "attend" to different relationships (i.e., users) is far less limited (constrained only by computing power); and its promotion of the user's well-being is typically highly contingent (e.g., based on specific programming and, in commercial cases, a background transactional arrangement with the company or developer), it may not ever be capable of genuine love of the sort that humans presumably need.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>Note: although the AI system might not require "direct compensation" for performing specific tasks for human users (or for otherwise benefiting them), the AI developer or licensing company may require compensation in the form of payment to make the AI available. We will take up this issue in the following section on "Layered relationships." However, we must note that not all AI systems are commercial in nature; open-source AI systems that are locally hosted, for instance, may not require a background transactional arrangement to be available to their human users.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7"><p>While the two-layered relationship structure has characterized most current human-AI interactions, emerging technologies are broadening the spectrum of provider involvement. On one end are commercial APIs that retain near-total provider control; in the middle, open-source models governed by community standards; and at the other end, locally deployed, highly personalized models. Recent advances in personal supercomputingexemplified by NVIDIA's upcoming Project DIGITS, which offers petaflop-level AI performance in a compact,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_8"><p>power-efficient desktop form factor-will soon make it feasible for individuals to run large-scale models (up to 200B parameters) locally. Similarly, state-of-the-art open-source models, such as DeepSeek-R1, leverage techniques like mixture of experts to enable efficient inference with low computational overhead. Further, the use of quantized versions of these models reduces storage and hardware requirements, making local deployment even more accessible. In these cases, although users build upon widely available foundational work, they gain full operational control and the ability to customize parameters without ongoing external data collection or provider intervention. As tools for local deployment and customization, such as LM Studio (https://lmstudio.ai/), become more accessible, this low-provider-involvement approach is poised to play an increasingly important role in use cases where privacy and user control are paramount.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_9"><p>For the purposes of this essay, we are not concerned with "personalization" in a different sense, namely personalization of an AI system to emulate specific individuals (e.g., by fine-tuning an LLM on person-specific data, creating a "digital twin" or "digital duplicate" of that person). However, it is an interesting question how relational norms should apply, not only to human-AI relationship types as we explore in the current contribution, but to specific human-AI relationships in which the AI emulates a particular person. For more on personalized AI in this different sense, see the following references(Porsdam Mann, Earp, Møller, et al., 2023;  2024;<ref type="bibr" target="#b55">Danaher &amp; Nyholm, 2024a;</ref><ref type="bibr" target="#b149">2024b;</ref><ref type="bibr" target="#b79">Earp, Porsdam Mann, Allen et al., 2024;</ref><ref type="bibr" target="#b103">Giubilini et al., 2024;</ref><ref type="bibr" target="#b124">Iglesias et al., 2024;</ref> Kirk, Vidgen &amp; Rotter, 2024;<ref type="bibr" target="#b256">Sweeney, 2024;</ref><ref type="bibr" target="#b124">Voinea, Earp, et al., 2024)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_10"><p>AI providers vary significantly in their data management strategies. While some claim not to use user data to improve their models or sell it to other parties (or else offer users opt-outs for such data use), others may give users less control over their data. And data collection creates an asymmetry: AI systems typically have access to far more information about the user than vice versa, raising concerns about fairness and equilibrium<ref type="bibr" target="#b44">(Cropanzano &amp; Mitchell, 2005;</ref><ref type="bibr" target="#b149">Lazar, 2024b)</ref>. This asymmetry is evident, for example, in AI romantic chatbots, where the AI accumulates intimate knowledge about the user's emotional life, while its operational parameters or data handling practices remain obscure to the user<ref type="bibr" target="#b167">(Manzini et al., 2024)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_11"><p>This could be a feature or a bug, depending on (a) the type of bias and (b) one's views about the desirability of partiality in close relationships. If the bias in question reflects invidious human prejudice, for instance, and thus stands in the way of a desired and appropriate empathic response toward members of certain social groups, then an AI's ability to behave empathically without such bias is clearly a feature. If the bias in question is that of partiality toward particular favored individuals due to a close relationship, by contrast, some might find an "unbiased" empathic response to be undesirable.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_12"><p>In the context of a decades-long debate over the role of empathy in medical care, many studies demonstrate an association between clinician empathy and burnout (e.g.,<ref type="bibr" target="#b104">Gleichgerrcht &amp; Decety, 2013)</ref>. Empathy research often distinguishes between affective empathy (e.g., emotional contagion) and cognitive empathy (e.g., perspective-taking; Shamay-Tsoory, Aharon-Peretz &amp;<ref type="bibr" target="#b239">Perry, 2009)</ref>, and the risks of clinician empathy are typically associated with the former. AI systems-patient, free of social bias, and incapable of incurring the emotional labor costs of felt affective empathy-could thus be designed to aid in clinical interactions, facilitating difficult conversations that would help patients feel heard while also communicating patients' concerns to time-pressured clinicians. Such AI systems integrated into caring professions could be cost-saving (in terms of clinician time), help combat clinician burnout, and even improve patient outcomes<ref type="bibr" target="#b136">(Kelley, Kraft-Todd, Schapira, Kossowsky &amp; Riess, 2014)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_13"><p>See Earp and Savulescu (2020)  for more on this distinction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_14"><p>It is worth noting that many AI systems, including those used in caregiving contexts, are often deliberately designed with features that encourage frequent use and potentially foster addiction<ref type="bibr" target="#b168">(Marriott &amp; Pitardi, 2023;</ref><ref type="bibr" target="#b165">Mahari &amp; Pataranutaporn, 2024)</ref>. These considerations suggest that while AI systems may effectively supplement human caregiving behavior in many contexts, their implementation must be guided by careful attention to addiction risk, privacy, and the impact on human relationships.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_15"><p>Questions have been raised about how to design AI systems that could meaningfully participate in, rather than merely simulate, reciprocal exchanges (assuming, perhaps controversially, that that would be desirable).<ref type="bibr" target="#b220">Railton (2022)</ref> proposes that for AI systems to achieve human-level competence in complex social tasks, they may need to be designed with motivational structures analogous to those underlying human cooperation. This could involve incorporating dispositions towards fairness, tit-for-tat reciprocity, and reputational concern into AI systems.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_16"><p>See Foa and Foa (1974)  and<ref type="bibr" target="#b44">Cropanzano and Mitchell (2005)</ref> for a full discussion of social exchange theory and the types of resources that can be transferred.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_17"><p>However, if other types of AI interests are included, such as possible goal-dependent interests in continuing to exist, then an AI system might well have something at stake, such as a need for more data, server maintenance, or access to electricity. See previous discussion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23" xml:id="foot_18"><p>On generative AI and education, see generally<ref type="bibr" target="#b138">Khan (2024)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_19"><p>See Nyholm, Danaher, and Earp (2021), for a discussion of how future technologies such as AI may change the nature of human romantic relationships.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="26" xml:id="foot_20"><p>This would, perhaps, be similar to the so-called "sugar daddy-sugar baby" relationship among humans (sugar "mommas" being relatively less common;<ref type="bibr" target="#b264">Upadhyay, 2021)</ref>. Such relationships differ from more directly transactional, short-term relationships in which money is exchanged for sexual services (e.g., paradigmatic sex worker or prostitute-client relationships), in that they tend to be longer-lasting, money is not directly exchanged for sex, but rather, indirect "gifts" are typically given, and some emotional connection may also be expected.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. We are grateful to <rs type="person">Killian McLoughlin</rs> and <rs type="person">M. J. Crockett</rs> for their contributions to both the original (Earp et al., 2021) and updated (Earp et al., 2025) versions of the Relational Norms model along with some of the present authors. Many helpful comments on this article were offered by participants in the Workshop on Partiality, Relationships, and AI held at <rs type="affiliation">LMU Munich</rs> (24 &amp; 25 October, 2024) organized by <rs type="person">Ben Lange</rs>, <rs type="person">Tom Douglas</rs>, and <rs type="person">Sven Nyholm</rs>. Thank you also to <rs type="person">Rodrigo Diaz</rs> for helpful comments on an earlier draft. Please note that any use of generative AI in this manuscript adheres to ethical guidelines for use and acknowledgement of generative AI in academic research (<rs type="person">Porsdam Mann</rs>, Vazirani et al., 2024). Each author has made a substantial contribution to the work, which has been thoroughly vetted for accuracy, and assumes responsibility for the integrity of their contributions.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On anthropomorphism in dialogue systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Abercrombie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dinkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Talat</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2023.emnlp-main.290.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Mirages</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Adelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Tmanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Delgado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lachs</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2014.304</idno>
		<ptr target="https://doi.org/10.1001/jama.2014.304" />
	</analytic>
	<monogr>
		<title level="m">Caregiver burden</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">311</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">All too human? Mapping and mitigating the risk from anthropomorphic AI</title>
		<author>
			<persName><forename type="first">C</forename><surname>Akbulut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Weidinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Manzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rieser</surname></persName>
		</author>
		<idno type="DOI">10.1609/aies.v7i1.31613</idno>
		<ptr target="https://doi.org/10.1609/aies.v7i1.31613" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI/ACM Conference on AI</title>
		<meeting>the AAAI/ACM Conference on AI</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="13" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reluctance to harm AI</title>
		<author>
			<persName><forename type="first">C</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Caviola</surname></persName>
		</author>
		<ptr target="https://osf.io/preprints/psyarxiv/38a6j_v2" />
	</analytic>
	<monogr>
		<title level="j">PsyArXiv</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploring the psychology of LLMs&apos; moral and legal reasoning</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F C F</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Nunes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Araújo</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.20245</idno>
		<ptr target="https://doi.org/10.1016/j.artint.20245" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">333</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Human becomings: Theorizing persons for Confucian role ethics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Ames</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>State University of New York Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Ames</surname></persName>
		</author>
		<title level="m">Confucian role ethics: A vocabulary</title>
		<imprint>
			<publisher>The Chinese University of Hong Kong Press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Moral foundations, values, and judgments in extraordinary altruists</title>
		<author>
			<persName><forename type="first">P</forename><surname>Amormino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Ploe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Marsh</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-26418-1</idno>
		<ptr target="https://doi.org/10.1038/s41598-022-26418-1" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">22111</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Role morality as a complex instance of ordinary morality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Andre</surname></persName>
		</author>
		<ptr target="https://www.jstor.org/stable/20014357" />
	</analytic>
	<monogr>
		<title level="j">American Philosophical Quarterly</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="80" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Can humans and AI robots be friends?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Archer</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781351189958-7</idno>
		<ptr target="https://doi.org/10.4324/9781351189958-7" />
	</analytic>
	<monogr>
		<title level="m">Post-human futures</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Carrigan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Porvora</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="132" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Governing lethal behavior in autonomous robots</title>
		<author>
			<persName><forename type="first">R</forename><surname>Arkin</surname></persName>
		</author>
		<idno type="DOI">10.1201/9781420085952</idno>
		<ptr target="https://doi.org/10.1201/9781420085952" />
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
	<note>st ed.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computational ethics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Awad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Conitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Crockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2022.02.009</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2022.02.009" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="388" to="405" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">General features of complex systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bar-Yam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of life support systems</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Kiel</surname></persName>
		</editor>
		<imprint>
			<publisher>UNESCO, EOLSS Publishers</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Network science</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Barabási</surname></persName>
		</author>
		<idno type="DOI">10.1098/rsta.2012.0375</idno>
		<ptr target="https://doi.org/10.1098/rsta.2012.0375" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">371</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="1987">2013. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Close relationships and the working self-concept: Implicit and explicit effects of priming attachment on agency and communion</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Lydon</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167204264245</idno>
		<ptr target="https://doi.org/10.1177/0146167204264245" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1389" to="1401" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Leadership and performance beyond expectations</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Bass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Free Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Just hierarchy: Why social hierarchies matter in China and the rest of the world</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the dangers of stochastic parrots: Can language models be too big?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shmitchell</surname></persName>
		</author>
		<idno type="DOI">10.1145/3442188.3445922</idno>
		<ptr target="https://doi.org/10.1145/3442188.3445922" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT &apos;21)</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT &apos;21)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Health AI poses distinct harms and potential benefits for disabled people</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Binkley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Shuman</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-024-03432-6</idno>
		<ptr target="https://doi.org/10.1038/s41591-024-03432-6" />
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The biological foundations of the incest taboo</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bischof</surname></persName>
		</author>
		<idno type="DOI">10.1177/053901847201100601</idno>
		<ptr target="https://doi.org/10.1177/053901847201100601" />
	</analytic>
	<monogr>
		<title level="j">Social Science Information</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="7" to="36" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The edge of sentience: Risk and precaution in humans, other animals, and AI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Birch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The ideal of shared decision making between physicians and patients</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Brock</surname></persName>
		</author>
		<ptr target="https://muse.jhu.edu/article/245598" />
	</analytic>
	<monogr>
		<title level="j">Kennedy Institute of Ethics Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="47" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Acquisition of the algorithms of social life: A domain-based approach</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Bugental</surname></persName>
		</author>
		<idno type="DOI">10.1037//0033-2909.126.2.187</idno>
		<ptr target="https://doi.org/10.1037//0033-2909.126.2.187" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="219" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Thank you, Siri&quot;: politeness and intelligent digital assistants</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gaskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-fifth Americas Conference on Information Systems</title>
		<meeting>the Twenty-fifth Americas Conference on Information Systems<address><addrLine>AIS, Atlanta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">My AI friend: How users of a social chatbot understand their human-AI friendship</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Brandtzaeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Skjuve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Følstad</surname></persName>
		</author>
		<idno type="DOI">10.1093/hcr/hqac008</idno>
		<ptr target="https://doi.org/10.1093/hcr/hqac008" />
	</analytic>
	<monogr>
		<title level="j">Human Communication Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="404" to="429" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The evolution of human mating</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Buss</surname></persName>
		</author>
		<ptr target="https://labs.la.utexas.edu/buss/files/2015/09/evolution_of_human_mating_2007.pdf" />
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica Sinica</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="502" to="512" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Artificial intelligence alone will not democratise education: On educational inequality, techno-solutionism and inclusive tools</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bulathwela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pérez-Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holloway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cukurova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<idno type="DOI">10.3390/su16020781</idno>
		<ptr target="https://doi.org/10.3390/su16020781" />
	</analytic>
	<monogr>
		<title level="j">Sustainability</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="781" to="801" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Butlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Elmoznino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Deane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Frith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kanai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mudrik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A K</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schwitzgebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vanrullen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2308.08708" />
		<title level="m">Consciousness in artificial intelligence: Insights from the science of consciousness</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Relational moral philosophy needs relational moral psychology</title>
		<author>
			<persName><forename type="first">R</forename><surname>Calcott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<idno type="DOI">10.1080/09515089.2024.2304054</idno>
		<ptr target="https://doi.org/10.1080/09515089.2024.2304054" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Psychology</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Carlsmith</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2206.13353" />
		<title level="m">Is power-seeking AI an existential risk? arXiv</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Chalmers</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.07103</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.07103" />
		<title level="m">Could a large language model be conscious? arXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Lovotics: human-robot love and sex relationships</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Cheok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Karunanayaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot ethics 2.0: From autonomous cars to artificial intelligence</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Jenkins</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="193" to="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Record keeping in two types of relationships</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.47.3.549</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.47.3.549" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="549" to="557" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Understanding prosocial behavior requires understanding relational context</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Boothby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Clark-Polner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Reis</surname></persName>
		</author>
		<idno type="DOI">10.1093/oxfordhb/9780195399813.013.37</idno>
		<ptr target="https://doi.org/10.1093/oxfordhb/9780195399813.013.37" />
	</analytic>
	<monogr>
		<title level="m">The Oxford handbook of prosocial behavior</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Schroeder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Graziano</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="329" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Interpersonal attraction in exchange and communal relationships</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mills</surname></persName>
		</author>
		<idno type="DOI">10.1037//0022-3514.37.1.12</idno>
		<ptr target="https://doi.org/10.1037//0022-3514.37.1.12" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="24" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A theory of communal (and exchange) relationships</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mills</surname></persName>
		</author>
		<idno type="DOI">10.4135/9781446249222.n38</idno>
		<ptr target="https://doi.org/10.4135/9781446249222.n38" />
	</analytic>
	<monogr>
		<title level="m">Handbook of theories of social psychology</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mills</surname></persName>
		</editor>
		<imprint>
			<publisher>SAGE Publications Ltd</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="232" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The difference between communal and exchange relationships: What it is and is not</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mils</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167293196003</idno>
		<ptr target="https://doi.org/10.1177/0146167293196003" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="684" to="691" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Reactions to and willingness to express emotion in communal and exchange relationships</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Taraban</surname></persName>
		</author>
		<idno type="DOI">10.1016/0022-1031(91)90029-6</idno>
		<ptr target="https://doi.org/10.1016/0022-1031(91)90029-6" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="324" to="336" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Perceptions of exploitation in communal and exchange relationships</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Waddell</surname></persName>
		</author>
		<idno type="DOI">10.1177/0265407585024002</idno>
		<ptr target="https://doi.org/10.1177/0265407585024002" />
	</analytic>
	<monogr>
		<title level="j">Journal of Social and Personal Relationships</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="403" to="418" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Crockett</surname></persName>
		</author>
		<idno type="DOI">10.1017/s0140525x19002528</idno>
		<ptr target="https://doi.org/10.1017/s0140525x19002528" />
	</analytic>
	<monogr>
		<title level="m">Who are &quot;we&quot; and why are we cooperating? Insights from social psychology</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="21" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The Ubuntu robot: Towards a relational conceptual framework for intercultural robotics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Coeckelbergh</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11948-022-00370-9</idno>
		<ptr target="https://doi.org/10.1007/s11948-022-00370-9" />
	</analytic>
	<monogr>
		<title level="j">Science and Engineering Ethics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The moral standing of machines: Towards a relational and non-Cartesian moral hermeneutics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Coeckelbergh</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-013-0133-8</idno>
		<idno>13347- 013-0133-8</idno>
		<ptr target="https://doi.org/10.1007/s" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="77" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">GenAI avatar judges and virtuous adjudication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Constantinescu</surname></persName>
		</author>
		<ptr target="https://www.researchgate.net/publication/389026924" />
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Blame it on the AI? On the moral responsibility of artificial moral advisors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Constantinescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vică</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Uszkai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Voinea</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-022-00529-z</idno>
		<ptr target="https://doi.org/10.1007/s13347-022-00529-z" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">35</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Social exchange theory: An interdisciplinary review</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cropanzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="DOI">10.1177/0149206305279602</idno>
		<ptr target="https://doi.org/10.1177/0149206305279602" />
	</analytic>
	<monogr>
		<title level="j">Journal of Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="874" to="900" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Morality as cooperation: A problem-centred approach</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">S</forename><surname>Curry</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-19671-8_2</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-19671-8_2" />
	</analytic>
	<monogr>
		<title level="m">Evolutionary psychology</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Shackelford</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="27" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Is it good to cooperate? Testing the theory of morality-as-cooperation in 60 societies</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">S</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mullins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Whitehouse</surname></persName>
		</author>
		<idno type="DOI">10.1086/701478</idno>
		<ptr target="https://doi.org/10.1086/701478" />
	</analytic>
	<monogr>
		<title level="j">Current Anthropology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="69" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">AI ethics should be mandatory for schoolchildren</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dabbagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Plozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-024-00462-1</idno>
		<ptr target="https://doi.org/10.1007/s43681-024-00462-1" />
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="87" to="92" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Dafoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Mckee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2012.08630" />
		<title level="m">Open problems in cooperative AI. arXiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Cooperative AI: Machines must learn to find common ground</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dafoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hadfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<ptr target="https://www.nature.com/articles/d41586-021-01170-0" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">539</biblScope>
			<biblScope unit="page" from="33" to="36" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The symbolic-consequences argument in the sex robot debate</title>
		<author>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot sex: Social and ethical Implications</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Mcarthur</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The philosophical case for robot friendship</title>
		<author>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</author>
		<idno type="DOI">10.5325/jpoststud.3.1.0005</idno>
		<ptr target="https://doi.org/10.5325/jpoststud.3.1.0005" />
	</analytic>
	<monogr>
		<title level="j">Journal of Posthuman Studies</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="24" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Welcoming robots into the moral circle: A defence of ethical behaviourism</title>
		<author>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11948-019-00119-x</idno>
		<ptr target="https://doi.org/10.1007/s11948-019-00119-x" />
	</analytic>
	<monogr>
		<title level="j">Science and Engineering Ethics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2023" to="2049" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Axiological futurism: The systematic study of the future of values</title>
		<author>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.futures.2021.102780</idno>
		<ptr target="https://doi.org/10.1016/j.futures.2021.102780" />
	</analytic>
	<monogr>
		<title level="j">Futures</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">102780</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Should we campaign against sex robots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sandberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot sex: Social and ethical Implications</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Mcarthur</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Digital duplicates and the scarcity problem: Might AI make us less scarce and therefore less valuable?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-024-00795-z</idno>
		<ptr target="https://doi.org/10.1007/s13347-024-00795-z" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2024">2024a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-024-00513-7</idno>
		<idno>43681- 024-00513-7</idno>
		<ptr target="https://doi.org/10.1007/s" />
		<title level="m">The ethics of personalised digital duplicates: A minimally viable permissibility principle. AI and Ethics</title>
		<imprint>
			<date type="published" when="2024">2024b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Evidence of human-level bonds established with a digital conversational agent: Cross-sectional, retrospective observational study</title>
		<author>
			<persName><forename type="first">A</forename><surname>Darcy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Salinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Robinson</surname></persName>
		</author>
		<idno type="DOI">10.2196/27868</idno>
		<ptr target="https://doi.org/10.2196/27868" />
	</analytic>
	<monogr>
		<title level="j">JMIR Formative Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Extending legal rights to social robots: The effects of anthropomorphism, empathy, and violent behavior towards robotic object&apos;. We Robot Conference</title>
		<author>
			<persName><forename type="first">K</forename><surname>Darling</surname></persName>
		</author>
		<ptr target="http://robots.law.miami.edu/wp-content/uploads/2012/04/Darling_Extending-Legal-Rights-to-Social-Robots-v2.pdf" />
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
		<respStmt>
			<orgName>University of Miami</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Darwall</surname></persName>
		</author>
		<title level="m">The second-person standpoint: Morality, respect, and accountability</title>
		<imprint>
			<publisher>Harvard University Press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">AI companions reduce loneliness</title>
		<author>
			<persName><forename type="first">J</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Uguralp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">O</forename><surname>Uguralp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stefano</surname></persName>
		</author>
		<ptr target="https://www.hbs.edu/ris/Publication%20Files/24-078_3deb075c-780" />
	</analytic>
	<monogr>
		<title level="s">HBS Working Paper Series</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>c0b-e13fcd2dc8b9.pdf</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">How to use AI ethically for ethical decisionmaking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demaree-Cotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1080/15265161.2022.2075968</idno>
		<ptr target="https://doi.org/10.1080/15265161.2022.2075968" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Bioethics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Embodiment in socially interactive robots</title>
		<author>
			<persName><forename type="first">E</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mataric</surname></persName>
		</author>
		<idno type="DOI">10.1561/2300000056</idno>
		<ptr target="https://doi.org/10.1561/2300000056" />
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Robotics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="251" to="356" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m">Field Manual 27-10: The Law of Land Warfare</title>
		<meeting><address><addrLine>Washington, D.C.</addrLine></address></meeting>
		<imprint>
			<publisher>U.S. Government Printing Office</publisher>
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
	<note>Paragraph 509</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Ideal technologies, ideal women: AI and gender imaginaries in Redditors&apos; discussions on the Replika bot girlfriend</title>
		<author>
			<persName><forename type="first">I</forename><surname>Depounti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Saukko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Natale</surname></persName>
		</author>
		<idno type="DOI">10.1177/01634437221119021</idno>
		<ptr target="https://doi.org/10.1177/01634437221119021" />
	</analytic>
	<monogr>
		<title level="j">Media, Culture &amp; Society</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="720" to="736" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The ethics of the artificial lover</title>
		<author>
			<persName><forename type="first">K</forename><surname>Devlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ethics of artificial intelligence</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">Matthew</forename><surname>Liao</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Turned on: Science, sex, and robots</title>
		<author>
			<persName><forename type="first">K</forename><surname>Devlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Bloomsbury Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Relating with social robots: issues of sex, love, intimacy, emotion, attachment, and companionship</title>
		<author>
			<persName><forename type="first">K</forename><surname>Devlin</surname></persName>
		</author>
		<editor>L. Fortunati &amp; A. Edwards</editor>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>De Gruyter</publisher>
		</imprint>
	</monogr>
	<note>The De Gruyter handbook of robots in society and culture</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Immorality and bu daode, unculturedness and bu wenming</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dranseika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Berniūnas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silius</surname></persName>
		</author>
		<idno type="DOI">10.1007/s41809-018-0013-y</idno>
		<ptr target="https://doi.org/10.1007/s41809-018-0013-y" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cultural Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="84" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Do longitudinal studies support long-term relationships between aggressive game play and youth aggressive behaviour? A meta-analytic examination</title>
		<author>
			<persName><forename type="first">A</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Sauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Ferguson</surname></persName>
		</author>
		<idno type="DOI">10.1098/rsos.200373</idno>
		<ptr target="http://doi.org/10.1098/rsos.200373" />
	</analytic>
	<monogr>
		<title level="j">Royal Society Open Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2020">2020. 200373</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Identity manipulation: Responding to advances in artificial intelligence and robotics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dunn</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.3772057</idno>
		<ptr target="https://doi.org/10.2139/ssrn.3772057" />
	</analytic>
	<monogr>
		<title level="j">SSRN Electronic Journal</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The empathy gap: Why AI can forecast behavior but cannot assess trustworthiness</title>
		<author>
			<persName><forename type="first">J</forename><surname>D'cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kidder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
		<ptr target="https://ceur-ws.org/" />
	</analytic>
	<monogr>
		<title level="m">TFSOCTAI@AAAI Fall Symposium</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3332</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Relational morality</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">Dissertation No. 325</note>
	<note>Doctoral dissertation, Yale University</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title/>
		<author>
			<persName><surname>Elischolar</surname></persName>
		</author>
		<ptr target="https://elischolar.library.yale.edu/gsas_dissertations/325" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Relational morality in psychology and philosophy: past, present, and future</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Calcott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Reinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A C</forename><surname>Everett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of ethics and social psychology</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Laham</surname></persName>
		</editor>
		<imprint>
			<publisher>Edward Elgar Publishing</publisher>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Impartial beneficence predicts greater and more uniform concern for others across social relationships</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mcloughlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Caraccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Calcott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rottman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Crockett</surname></persName>
		</author>
		<ptr target="https://osf.io/preprints/psyarxiv/jazbn" />
	</analytic>
	<monogr>
		<title level="j">PsyArXiv</title>
		<imprint/>
	</monogr>
	<note>under review</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">How social relationships shape moral wrongness judgments</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Mcloughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Monrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Crockett</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-021-26067-4</idno>
		<ptr target="https://doi.org/10.1038/s41467-021-26067-4" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">How social relationships shape praise and blame: Strengthening and extending the relational norms model</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Mcloughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Calcott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Caraccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Monrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Owen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Crockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<ptr target="https://www.researchgate.net/publication/387959265" />
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Credit and blame for AI-generated content: Effects of personalization in four countries</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hannikainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1111/nyas.15258</idno>
		<ptr target="https://doi.org/10.1111/nyas.15258" />
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1542</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="57" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">A personalized patient preference predictor for substituted judgments in healthcare: Technically feasible and ethically desirable</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Suren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jongsma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sinnott-Armstrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wendler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1080/15265161.2023.2296402</idno>
		<ptr target="https://doi.org/10.1080/15265161.2023.2296402" />
	</analytic>
	<monogr>
		<title level="j">The American Journal of Bioethics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="13" to="26" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">What is love? Can it be chemically modified? Should it be?</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<ptr target="https://www.researchgate.net/publication/350043669" />
	</analytic>
	<monogr>
		<title level="j">Philosophy and Public Issues</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="93" to="151" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Who takes the most revenge? Individual differences in negative reciprocity norm endorsement</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eisenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aselage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rohdieck</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167204264047</idno>
		<ptr target="https://doi.org/10.1177/0146167204264047" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="787" to="799" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Moral crumple zones: Cautionary tales in human-robot interaction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Elish</surname></persName>
		</author>
		<idno type="DOI">10.17351/ests2019.260</idno>
		<ptr target="https://doi.org/10.17351/ests2019.260" />
	</analytic>
	<monogr>
		<title level="j">Engaging Science, Technology, and Society</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="60" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">On the origin and extension of the incest taboo</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ember</surname></persName>
		</author>
		<idno type="DOI">10.1177/106939717501000402</idno>
		<ptr target="https://doi.org/10.1177/106939717501000402" />
	</analytic>
	<monogr>
		<title level="j">Behavior Science Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="249" to="281" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Logical limitations to machine ethics with consequences to lethal autonomous weapons</title>
		<author>
			<persName><forename type="first">M</forename><surname>Englert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Siebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ziegler</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1411.2842" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Transparency and the black box problem: Why we do not trust AI</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Von Eschenbach</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-021-00477-0</idno>
		<ptr target="https://doi.org/10.1007/s13347-021-00477-0" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1607" to="1622" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Preliminaries to artificial consciousness: A multidimensional heuristic approach</title>
		<author>
			<persName><forename type="first">K</forename><surname>Evers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farisco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chatila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">T</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hamker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nemeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F M J</forename><surname>Verschure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khamassi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.plrev.2025.01.002</idno>
		<ptr target="https://doi.org/10.1016/j.plrev.2025.01.002" />
	</analytic>
	<monogr>
		<title level="j">Physics of Life Reviews</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Confucian and Rawlsian views of justice: A comparison</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fan</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1540-6253.1997.tb00189.x</idno>
		<ptr target="https://doi.org/10.1111/j.1540-6253.1997.tb00189.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Chinese Philosophy</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="427" to="456" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">From the soil: The foundations of society</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>University of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Why we love: The nature and chemistry of romantic love</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Macmillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">The four elementary forms of sociality: Framework for a unified theory of social relations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Fiske</surname></persName>
		</author>
		<idno type="DOI">10.1037//0033-295x.99.4.689</idno>
		<ptr target="https://doi.org/10.1037//0033-295x.99.4.689" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="689" to="723" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Your robot therapist will see you now: Ethical implications of embodied artificial intelligence in psychiatry, psychology, and psychotherapy</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Fiske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Henningsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buyx</surname></persName>
		</author>
		<idno type="DOI">10.2196/13216</idno>
		<ptr target="https://doi.org/10.2196/13216" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Internet Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Debating sex work</title>
		<author>
			<persName><forename type="first">J</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Watson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">The minds of machines: Children&apos;s beliefs about the experiences, thoughts, and morals of familiar interactive technologies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Flanagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kushnir</surname></persName>
		</author>
		<idno type="DOI">10.1037/dev0001524</idno>
		<ptr target="https://doi.org/10.1037/dev0001524" />
	</analytic>
	<monogr>
		<title level="j">Developmental Psychology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1017" to="1031" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Societal structures of the mind</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">G</forename><surname>Foa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Foa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
			<pubPlace>Charles C. Thomas, Springfield</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Toy story or children story? Putting children and their rights at the forefront of the artificial intelligence revolution</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fosch-Villaronga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Der Hof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamò-Larrieux</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-021-01295-w</idno>
		<ptr target="https://doi.org/10.1007/s00146-021-01295-w" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>AI &amp; Society</publisher>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="133" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Ethical concerns with replacing human relations with humanoid robots: an Ubuntu perspective</title>
		<author>
			<persName><forename type="first">C</forename><surname>Friedman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-022-00186-0</idno>
		<ptr target="https://doi.org/10.1007/s43681-022-00186-0" />
	</analytic>
	<monogr>
		<title level="j">AI Ethics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="527" to="538" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Manzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tomašev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ktena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kenton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>El-Sayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Akbulut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trask</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shelby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Marchal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Manyika</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2404.16244</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2404.16244" />
		<title level="m">The ethics of advanced AI assistants</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Building a stronger CASA: Extending the computers are social actors paradigm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gambino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Ratan</surname></persName>
		</author>
		<idno type="DOI">10.30658/hmc.1.5</idno>
		<ptr target="https://doi.org/10.30658/hmc.1.5" />
	</analytic>
	<monogr>
		<title level="j">Human-Machine Communication</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="85" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">The evolution of mating: Trade-offs and strategic pluralism</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Gangestad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Simpson</surname></persName>
		</author>
		<idno type="DOI">10.1017/s0140525x0000337x</idno>
		<ptr target="https://doi.org/10.1017/s0140525x0000337x" />
	</analytic>
	<monogr>
		<title level="j">Behavioral &amp; Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="573" to="587" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Guardrails: Guiding human decisions in the age of AI</title>
		<author>
			<persName><forename type="first">U</forename><surname>Gasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mayer-Schönberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Differences between tight and loose cultures: A 33-nation study</title>
		<author>
			<persName><forename type="first">C</forename><surname>Geertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Raver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Nishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Lun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<idno type="DOI">10.1126/science.1197754</idno>
		<ptr target="https://www.science.org/doi/10.1126/science.1197754" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">332</biblScope>
			<biblScope unit="issue">6033</biblScope>
			<biblScope unit="page" from="1100" to="1104" />
			<date type="published" when="1973">1973. 2011</date>
		</imprint>
	</monogr>
	<note>The interpretation of cultures: Selected essays</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">In search of the moral status of AI: Why sentience is a strong argument</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gibert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-021-01179-z</idno>
		<ptr target="https://doi.org/10.1007/s00146-021-01179-z" />
	</analytic>
	<monogr>
		<title level="j">AI &amp; Society</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="319" to="330" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Know thyself, improve thyself: Personalized LLMs for self-knowledge and moral enhancement</title>
		<author>
			<persName><forename type="first">A</forename><surname>Giubilini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11948-024-00518-9</idno>
		<ptr target="https://doi.org/10.1007/s11948-024-00518-9" />
	</analytic>
	<monogr>
		<title level="j">Science and Engineering Ethics</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Giubilini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Voinea</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Earp</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2018">2018. 2024</date>
		</imprint>
	</monogr>
	<note>Philosophy &amp; Technology</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Empathy in clinical practice: How individual dispositions, gender, and experience moderate empathic concern, burnout, and emotional distress in physicians</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gleichgerrcht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Decety</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0061526</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0061526" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">The gardener and the carpenter: What the new science of child development tells us about the relationship between parents and children</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gopnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Macmillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Chapter two -moral foundations theory: The pragmatic validity of moral pluralism</title>
		<author>
			<persName><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Haidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Motyl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Wojcik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Ditto</surname></persName>
		</author>
		<idno type="DOI">10.1016/b978-0-12-407236-7.00002-4</idno>
		<ptr target="https://doi.org/10.1016/b978-0-12-407236-7.00002-4" />
	</analytic>
	<monogr>
		<title level="j">Advances in Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="130" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">The responsible implementation of Artificial Intelligence in childcare</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Guérin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I S</forename><surname>Hofmeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Kester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Sensmeier</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-52082-2_8</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-52082-2_8" />
	</analytic>
	<monogr>
		<title level="m">Code and conscience: Exploring technology, human rights, and ethics in multidisciplinary AI education</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Bayer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Grimme</surname></persName>
		</editor>
		<meeting><address><addrLine>Nature Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2025">2025</date>
			<biblScope unit="page" from="113" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Ascribing consciousness to artificial intelligence: Human-AI interaction and its carry-over effects on human-human interaction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Guingrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S A</forename><surname>Graziano</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2024.1322781</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2024.1322781" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Do informal caregivers experience more burnout? A meta-analytic study</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gérain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zech</surname></persName>
		</author>
		<idno type="DOI">10.1080/13548506.2020.1803372</idno>
		<ptr target="https://doi.org/10.1080/13548506.2020.1803372" />
	</analytic>
	<monogr>
		<title level="j">Health &amp; Medicine</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="161" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Psychology</note>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Human trust in artificial intelligence: Review of empirical research</title>
		<author>
			<persName><forename type="first">E</forename><surname>Glikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Woolley</surname></persName>
		</author>
		<idno type="DOI">10.5465/annals.2018.0057</idno>
		<ptr target="https://doi.org/10.5465/annals.2018.0057" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Academy of Management Annals</publisher>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="627" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">Leading teams: Setting the stage for great performances</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hackman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Harvard Business Review Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Social roles and the moral judgement of acts and omissions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Haidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Baron</surname></persName>
		</author>
		<idno type="DOI">10.1002/(SICI)1099-0992(199603)26:2%3C201::AID-EJSP745%3E3.0.CO;2-J</idno>
		<ptr target="https://doi.org/10.1002/(SICI)1099-0992" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Social Psychology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="218" />
			<date type="published" when="1996">1996. 199603</date>
		</imprint>
	</monogr>
	<note>2&lt;201::AID-EJSP745&gt;3.0.CO;2-J</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">The effect of roles and deeds on responsibility judgments: The normative structure of wrongdoing</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sanders</surname></persName>
		</author>
		<idno type="DOI">10.2307/3033836</idno>
		<ptr target="https://doi.org/10.2307/3033836" />
	</analytic>
	<monogr>
		<title level="j">Social Psychology Quarterly</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">237</biblScope>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Replika removing erotic role-play Is like Grand Theft Auto removing guns or cars&quot;: Reddit discourse on Artificial Intelligence chatbots and sexual technologies</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bolthouse</surname></persName>
		</author>
		<idno type="DOI">10.1177/23780231241259627</idno>
		<ptr target="http://dx.doi.org/10.1177/23780231241259627" />
	</analytic>
	<monogr>
		<title level="j">Socius: Sociological Research for a Dynamic World</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Implicit relationship prototypes: Investigating five theories of the cognitive organization of social relationships</title>
		<author>
			<persName><forename type="first">N</forename><surname>Haslam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Fiske</surname></persName>
		</author>
		<idno type="DOI">10.1016/0022-1031(92)90041-H</idno>
		<ptr target="https://doi.org/10.1016/0022-1031(92)90041-H" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="441" to="474" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Healthy reciprocity in sexual interaction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ojanlatva</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0738-3991(99)00019-1</idno>
		<ptr target="https://doi.org/10.1016/S0738-3991(99)00019-1" />
	</analytic>
	<monogr>
		<title level="j">Patient Education and Counseling</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="169" to="175" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">The moral psychology of raceless, genderless strangers</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1177/1745691619885840</idno>
		<ptr target="https://doi.org/10.1177/1745691619885840" />
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="216" to="230" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Privacy-centered design for social robots</title>
		<author>
			<persName><forename type="first">T</forename><surname>Heuer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Schiering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gerndt</surname></persName>
		</author>
		<idno type="DOI">10.1075/is.18063.heu</idno>
		<ptr target="https://doi.org/10.1075/is.18063.heu" />
	</analytic>
	<monogr>
		<title level="j">Interaction Studies Social Behaviour and Communication in Biological and Artificial Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="509" to="529" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Hill</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2025/01/15/technology/ai-chatgpt-boyfriend-companion.html" />
		<title level="m">She is in love with ChatGPT. The New York Times</title>
		<imprint>
			<date type="published" when="2025-01-15">2025. January 15</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Removing harmful options: the law and ethics of international commercial surrogacy</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hodson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Townley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<idno type="DOI">10.1093/medlaw/fwz025</idno>
		<ptr target="https://doi.org/10.1093/medlaw/fwz025" />
	</analytic>
	<monogr>
		<title level="j">Medical Law Review</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="597" to="622" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Conformity, status, and idiosyncrasy credit</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Hollander</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0042501</idno>
		<ptr target="https://doi.org/10.1037/h0042501" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="127" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K G</forename><surname>Hopster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Maas</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-023-00305-5</idno>
		<ptr target="https://doi.org/10.1007/s43681-023-00305-5" />
		<title level="m">The technology triad: Disruptive AI, regulatory gaps and value change. AI and Ethics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1051" to="1069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">On artificial intelligence and manipulation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ienca</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11245-023-09940-3</idno>
		<ptr target="https://doi.org/10.1007/s11245-023-09940-3" />
	</analytic>
	<monogr>
		<title level="j">Topoi</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="833" to="842" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Digital doppelgängers and lifespan extension: What matters?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Voinea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zahiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Jecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1080/15265161.2024.2416133</idno>
		<ptr target="https://doi.org/10.1080/15265161.2024.2416133" />
	</analytic>
	<monogr>
		<title level="j">The American Journal of Bioethics</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Rome Statute of the International Criminal Court</title>
		<author>
			<orgName type="collaboration">International Criminal Court.</orgName>
		</author>
		<ptr target="https://www.icc-cpi.int/resource-library" />
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Principles of International Law Recognized in the Charter of the Nürnberg Tribunal and in the Judgment of the Tribunal</title>
		<ptr target="https://legal.un.org/ilc/texts/instruments/english/draft_articles/7_1_1950.pdf" />
	</analytic>
	<monogr>
		<title level="j">Yearbook of the International Law Commission</title>
		<imprint>
			<biblScope unit="volume">II</biblScope>
			<date type="published" when="1950">1950. 1950</date>
			<publisher>International Law Commission</publisher>
		</imprint>
	</monogr>
	<note>Principle IV</note>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">In praise of empathic AI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Inzlicht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>D'cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bloom</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2023.12.003</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2023.12.003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="89" to="91" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title level="m" type="main">Can we wrong a robot?</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Jecker</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-021-01278-x</idno>
		<ptr target="https://doi.org/10.1007/s00146-021-01278-x" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>AI &amp; Society</publisher>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">The moral standing of social robots: Untapped insights from Africa</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Jecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Atiure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Ajei</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-022-00531-5</idno>
		<idno>13347- 022-00531-5</idno>
		<ptr target="https://doi.org/10.1007/s" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">34</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Investigating machine moral judgement through the Delphi experiment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
		<idno type="DOI">10.1038/s42256-024-00969-6</idno>
		<ptr target="https://doi.org/10.1038/s42256-024-00969-6" />
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="145" to="160" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Dual relationships and professional boundaries</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kagle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Giebelhausen</surname></persName>
		</author>
		<ptr target="https://www.jstor.org/stable/23717211" />
	</analytic>
	<monogr>
		<title level="j">Social Work</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="220" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Children&apos;s social relationships with current and nearfuture robots</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Gary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1111/cdep.12011</idno>
		<ptr target="https://doi.org/10.1111/cdep.12011" />
	</analytic>
	<monogr>
		<title level="j">Child Development Perspectives</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="37" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Robovie, you&apos;ll have to go into the closet now&quot;: Children&apos;s social and moral relationships with a humanoid robot</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishiguro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Freier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Severson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ruckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0027033</idno>
		<ptr target="https://doi.org/10.1037/a0027033" />
	</analytic>
	<monogr>
		<title level="j">Developmental Psychology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="314" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">How relational context matters for human-AI cooperation within organizations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kappes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Reinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Nussberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Janardhanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<editor>P. Hacker</editor>
		<imprint>
			<publisher>AI in Society. University of Oxford Press</publisher>
			<pubPlace>Oxford Intersections</pubPlace>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">In conversation with artificial intelligence: Aligning language models with human values</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kasirzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gabriel</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-023-00606-x</idno>
		<ptr target="https://doi.org/10.1007/s13347-023-00606-x" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">The influence of the patient-clinician relationship on healthcare outcomes: A systematic review and meta-analysis of randomized controlled trials</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kraft-Todd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schapira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kossowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Riess</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0094207</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0094207" />
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Towards a conversational ethics of large language models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kempt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nagel</surname></persName>
		</author>
		<idno type="DOI">10.5406/21521123.61.4.04</idno>
		<ptr target="https://doi.org/10.5406/21521123.61.4.04" />
	</analytic>
	<monogr>
		<title level="j">American Philosophical Quarterly</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="339" to="354" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">Brave new words: How AI will revolutionize education (and why that&apos;s a good thing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<pubPlace>Viking</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title level="m" type="main">Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Röttger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hale</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2303.05453" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">The benefits, risks and bounds of personalizing the alignment of large language models to individuals</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Röttger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hale</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-024-00820-y</idno>
		<ptr target="https://doi.org/10.1038/s42256-024-00820-y" />
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="383" to="392" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Bad machines corrupt good morals</title>
		<author>
			<persName><forename type="first">N</forename><surname>Köbis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-F</forename><surname>Bonnefon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rahwan</surname></persName>
		</author>
		<ptr target="https://www.nature.com/articles/s41562-021-01128-2" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="679" to="685" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Scoring the ethics of AI robo-advice: Why we need gateways and ratings</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kofman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10551-024-05753-5</idno>
		<ptr target="https://doi.org/10.1007/s10551-024-05753-5" />
	</analytic>
	<monogr>
		<title level="j">Journal of Business Ethics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Real feeling and fictional time in human-AI interactions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roberts</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11245-024-10046-7</idno>
		<ptr target="https://doi.org/10.1007/s11245-024-10046-7" />
	</analytic>
	<monogr>
		<title level="j">Topoi</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="783" to="794" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">The ghost in the machine -emotionally intelligent conversational agents and the failure to regulate &apos;deception by design</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leenes</surname></persName>
		</author>
		<idno type="DOI">10.2966/scrip.170220.320</idno>
		<ptr target="https://doi.org/10.2966/scrip.170220.320" />
	</analytic>
	<monogr>
		<title level="j">SCRIPT</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="320" to="358" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Laban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Cross</surname></persName>
		</author>
		<ptr target="https://osf.io/preprints/psyarxiv/2azpq" />
		<title level="m">Sharing with robots: Why do we do it and how does it make us feel? PsyArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Too human and not human enough: A grounded theory analysis of mental health harms from emotional dependence on the social chatbot</title>
		<author>
			<persName><forename type="first">L</forename><surname>Laestadius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Illenčík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Campos-Castillo</surname></persName>
		</author>
		<idno type="DOI">10.1177/14614448221142007</idno>
		<ptr target="https://doi.org/10.1177/14614448221142007" />
	</analytic>
	<monogr>
		<title level="j">Replika. New Media &amp; Society</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5923" to="5941" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Artificial intelligence, existential risk and equity: the need for multigenerational bioethics</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Syropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<idno type="DOI">10.1136/jme-2024-110583</idno>
		<ptr target="https://doi.org/10.1136/jme-2024-110583" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Ethics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="799" to="801" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Lazar</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2404.05990</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2404.05990" />
		<title level="m">Automatic Authorities: Power and AI</title>
		<imprint>
			<date type="published" when="2024">2024a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Legitimacy, authority, and democratic duties of explanation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lazar</surname></persName>
		</author>
		<idno type="DOI">10.1093/oso/9780198909460.003.0002</idno>
		<ptr target="https://doi.org/10.1093/oso/9780198909460.003.0002" />
	</analytic>
	<monogr>
		<title level="j">Philosophy</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Sobel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Wall</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="28" to="56" />
			<date type="published" when="2024">2024b</date>
			<pubPlace>Oxford Academic</pubPlace>
		</imprint>
	</monogr>
	<note>Oxford Studies in Political</note>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Are physically embodied social agents better than disembodied social agents? The effects of physical embodiment, tactile interaction, and people&apos;s loneliness in human-robot interaction</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijhcs.2006.05.002</idno>
		<ptr target="https://doi.org/10.1016/j.ijhcs.2006.05.002" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="962" to="973" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Lehman</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2302.09248</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2302.09248" />
		<title level="m">Machine love</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Vezhnevets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Agapiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sunehag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Duéñez-Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Piliouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Bileschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rahwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2412.19010</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2412.19010" />
		<title level="m">A theory of appropriateness with applications to generative artificial intelligence</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Projection of responsiveness to needs and the construction of satisfying communal relationships</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Lemay</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Feeney</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.92.5.834</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.92.5.834" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="834" to="853" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Sex differences in approaching friends with benefits relationships</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Lehmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Vanderdrift</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kelly</surname></persName>
		</author>
		<idno type="DOI">10.1080/00224491003721694</idno>
		<ptr target="https://doi.org/10.1080/00224491003721694" />
	</analytic>
	<monogr>
		<title level="j">Journal of Sex Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="275" to="284" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Google AI has better bedside manner than human doctors -and makes better diagnoses</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lenharo</surname></persName>
		</author>
		<ptr target="https://www.nature.com/articles/d41586-024-00099-4" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<date type="published" when="2024-01-12">2024. January 12</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Customer service with AIpowered human-robot collaboration (HRC): A literature review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Leocádio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Melão</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.procs.2024.01.120</idno>
		<ptr target="https://doi.org/10.1016/j.procs.2024.01.120" />
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">232</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1222" to="1232" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Should you let AI tell you who you are and what you should do?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Leuenberger</surname></persName>
		</author>
		<idno type="DOI">10.1093/oso/9780198876434.003.0016</idno>
		<ptr target="https://doi.org/10.1093/oso/9780198876434.003.0016" />
	</analytic>
	<monogr>
		<title level="m">AI Morality</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Edmonds</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="160" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">A policy framework for leveraging generative AI to address enduring challenges in clinical trials</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Liddicoat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lenarczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aboy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-025-01440-5</idno>
		<ptr target="https://doi.org/10.1038/s41746-025-01440-5" />
	</analytic>
	<monogr>
		<title level="j">Digital Medicine</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">The AI chatbot always flirts with me, should I flirt back: From the McDonaldization of friendship to the robotization of love</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1177/20563051241296229</idno>
		<ptr target="https://doi.org/10.1177/20563051241296229" />
	</analytic>
	<monogr>
		<title level="j">Social Media + Society</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sebo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Butlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Finlinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chalmers</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2411.00986</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2411.00986" />
		<title level="m">Taking AI welfare seriously</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<author>
			<persName><forename type="first">E</forename><surname>Lumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Buschmeier</surname></persName>
		</author>
		<idno type="DOI">10.3389/frobt.2023.1242127</idno>
		<ptr target="https://doi.org/10.3389/frobt.2023.1242127" />
	</analytic>
	<monogr>
		<title level="m">Should robots be polite? Expectations about politeness in human-robot interaction</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">1242127</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">A literature review of AI metaphors and why they matter for policy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Maas</surname></persName>
		</author>
		<ptr target="https://law-ai.org/ai-policy-metaphors" />
	</analytic>
	<monogr>
		<title level="j">Foundations Report</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>AI is like. Institute for Law &amp; AI</note>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">When human-AI interactions become parasocial: Agency and anthropomorphism in affective design</title>
		<author>
			<persName><forename type="first">T</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Quan-Haase</surname></persName>
		</author>
		<idno type="DOI">10.1145/3630106.3658956</idno>
		<ptr target="https://dl.acm.org/doi/10.1145/3630106.3658956" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2024 ACM Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Beyond neural data: Cognitive biometrics and mental privacy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Magee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ienca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Farahany</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2024.09.004</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2024.09.004" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="3017" to="3028" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">We need to prepare for &apos;addictive intelligence</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pataranutaporn</surname></persName>
		</author>
		<ptr target="https://www.technologyreview.com/2024/08/05/1095600/we-need-to-prepare-for-addictive-intelligence/" />
	</analytic>
	<monogr>
		<title level="j">MIT Technology Review</title>
		<imprint>
			<date type="published" when="2024-08-05">2024. August 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Mirroring the bias: gender and artificial intelligence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Manasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Panchanadeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sours</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1080/09718524.2022.2128254</idno>
		<ptr target="https://doi.org/10.1080/09718524.2022.2128254" />
	</analytic>
	<monogr>
		<title level="j">Technology and Development</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="295" to="305" />
			<date type="published" when="2022">2022</date>
			<pubPlace>Gender</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">The code that binds us: Navigating the appropriateness of human-AI assistant relationships</title>
		<author>
			<persName><forename type="first">A</forename><surname>Manzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vallor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gabriel</surname></persName>
		</author>
		<idno type="DOI">10.1609/aies.v7i1.31694</idno>
		<ptr target="https://doi.org/10.1609/aies.v7i1.31694" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI/ACM Conference on AI</title>
		<meeting>the AAAI/ACM Conference on AI</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="943" to="957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">One is the loneliest number… Two can be as bad as one. The influence of AI friendship apps on users&apos; well-being and addiction</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pitardi</surname></persName>
		</author>
		<idno type="DOI">10.1002/mar.21899</idno>
		<ptr target="https://doi.org/10.1002/mar.21899" />
	</analytic>
	<monogr>
		<title level="j">Psychology &amp; Marketing</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="101" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">How development and culture shape intuitions about prosocial obligations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gollwitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mermin-Bunnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shinomiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Retelsdorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bloom</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0001136</idno>
		<ptr target="https://doi.org/10.1037/xge0001136" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1866" to="1882" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">The illusion of moral decline</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mastroianni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Gilbert</surname></persName>
		</author>
		<ptr target="https://www.nature.com/articles/s41586-023-06137-x" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">618</biblScope>
			<biblScope unit="issue">7966</biblScope>
			<biblScope unit="page" from="782" to="789" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<monogr>
		<title level="m" type="main">The Routledge handbook of philosophy of sex and sexuality</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcdonald</surname></persName>
		</author>
		<editor>B. D. Earp, C. Chambers, &amp; L. Watson</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Routledge</publisher>
			<biblScope unit="page" from="207" to="217" />
		</imprint>
	</monogr>
	<note>Flirting</note>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Taboo trade-offs, relational framing, and the acceptability of exchanges</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Mcgraw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Tetlock</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15327663jcp1501_2</idno>
		<ptr target="https://doi.org/10.1207/s15327663jcp1501_2" />
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="15" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Humans perceive warmth and competence in artificial intelligence</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Mckee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Fiske</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.isci.2023.107256</idno>
		<ptr target="https://doi.org/10.1016/j.isci.2023.107256" />
	</analytic>
	<monogr>
		<title level="j">iScience</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">107256</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Why be moral in a virtual world</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>King</surname></persName>
		</author>
		<ptr target="http://www.jpe.ox.ac.uk/" />
	</analytic>
	<monogr>
		<title level="j">Journal of Practical Ethics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="30" to="48" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Emotional AI, ethics, and Japanese spice: Contributing community, wholeness, sincerity, and heart</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcstay</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-021-00487-y</idno>
		<ptr target="https://doi.org/10.1007/s13347-021-00487-y" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1781" to="1802" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Algorithms for ethical decision-making in the clinic: a proof of concept</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Diepold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buyx</surname></persName>
		</author>
		<idno type="DOI">10.1080/15265161.2022.2040647</idno>
		<ptr target="https://doi.org/10.1080/15265161.2022.2040647" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Bioethics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="4" to="20" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">Male homosocial bonds and perceptions of human-robot relationships in an online sex doll forum</title>
		<author>
			<persName><forename type="first">B</forename><surname>Middleweek</surname></persName>
		</author>
		<idno type="DOI">10.1177/1363460720932383</idno>
		<ptr target="https://doi.org/10.1177/1363460720932383" />
	</analytic>
	<monogr>
		<title level="j">Sexualities</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="370" to="387" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Cultural variation in communal versus exchange norms: Implications for social support</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Akiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kapadia</surname></persName>
		</author>
		<idno type="DOI">10.1037/pspi0000091</idno>
		<ptr target="https://psycnet.apa.org/doi/10.1037/pspi0000091" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="94" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Measurement of communal strength</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Ford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1475-6811.2004.00079.x</idno>
		<ptr target="https://doi.org/10.1111/j.1475-6811.2004.00079.x" />
	</analytic>
	<monogr>
		<title level="j">Personal Relationships</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="230" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Regulatory responses to medical machine learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Minssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gerke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aboy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1093/jlb/lsaa002</idno>
		<ptr target="https://doi.org/10.1093/jlb/lsaa002" />
	</analytic>
	<monogr>
		<title level="j">Journal of Law and the Biosciences</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<title level="m" type="main">The nature of managerial work</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mintzberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>HarperCollins Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Social exchange theory, exchange resources, and interpersonal relationships: A modest resolution of theoretical difficulties</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Cropanzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Quisenberry</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4614-4175-5_6</idno>
		<ptr target="https://doi.org/10.1007/978-1-4614-4175-5_6" />
	</analytic>
	<monogr>
		<title level="m">Handbook of social resource theory: Theoretical extensions, empirical insights, and social applications</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Törnblom</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Kazemi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="99" to="118" />
		</imprint>
	</monogr>
	<note>Springer Science + Business Media</note>
</biblStruct>

<biblStruct xml:id="b183">
	<monogr>
		<title level="m" type="main">Co-intelligence</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mollick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>Random House UK</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<monogr>
		<title level="m" type="main">In principle obstacles for empathic AI: why we can&apos;t replace human empathy in healthcare</title>
		<author>
			<persName><forename type="first">C</forename><surname>Montemayor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fairweather</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-021-01230-z</idno>
		<ptr target="https://doi.org/10.1007/s00146-021-01230-z" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>AI &amp; Society</publisher>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1353" to="1359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Interactive privacy management: Toward enhancing privacy awareness and control in the Internet of Things</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muhander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Perera</surname></persName>
		</author>
		<idno type="DOI">10.1145/3600096</idno>
		<ptr target="https://doi.org/10.1145/3600096" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Internet of Things</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">Corporate responsibility for the termination of digital friends</title>
		<author>
			<persName><forename type="first">N</forename><surname>Munn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weijers</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-021-01276-z</idno>
		<ptr target="https://doi.org/10.1007/s00146-021-01276-zMurdoch" />
	</analytic>
	<monogr>
		<title level="m">The sovereignty of good</title>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="1970">2022. 1970</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1501" to="1502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Can an AI-carebot be filial? Reflections from Confucian ethics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Muyskens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dunn</surname></persName>
		</author>
		<idno type="DOI">10.1177/09697330241238332</idno>
		<ptr target="https://doi.org/10.1177/09697330241238332" />
	</analytic>
	<monogr>
		<title level="j">Nursing Ethics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="999" to="1009" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">People expect artificial moral advisors to be more utilitarian and distrust utilitarian moral advisors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A C</forename><surname>Everett</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2024.106028</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2024.106028" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">256</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2025">2025. 106028</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Gender bias in AI-based decision-making systems: a systematic literature review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nadeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Marjanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Abedin</surname></persName>
		</author>
		<idno type="DOI">10.3127/ajis.v26i0.3835</idno>
		<ptr target="https://doi.org/10.3127/ajis.v26i0.3835" />
	</analytic>
	<monogr>
		<title level="j">Australasian Journal of Information Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Agent-based computing from multi-agent systems to agent-based models: a visual survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Niazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11192-011-0468-9</idno>
		<ptr target="https://doi.org/10.1007/s11192-011-0468-9" />
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="479" to="499" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Prosocial behavior toward machines</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pfattheicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Keijsers</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.copsyc.2021.08.004</idno>
		<ptr target="https://doi.org/10.1016/j.copsyc.2021.08.004" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Psychology</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="260" to="265" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">Attributing agency to automated systems: Reflections on human-robot collaborations and responsibility-loci</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11948-017-9943-x</idno>
		<ptr target="https://doi.org/10.1007/s11948-017-9943-x" />
	</analytic>
	<monogr>
		<title level="j">Science and Engineering Ethics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1201" to="1219" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<monogr>
		<title level="m" type="main">Humans and robots: Ethics, agency, and anthropomorphism</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Rowman &amp; Littlefield</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">The ethics of human-robot interaction and traditional moral theories</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Oxford handbook of digital ethics</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Véliz</surname></persName>
		</editor>
		<meeting><address><addrLine>Oxford Academic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="43" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<monogr>
		<title level="m" type="main">The Routledge handbook of philosophy of sex and sexuality</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
		<editor>B. D. Earp, L. Watson, &amp; C. Chambers</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Routledge</publisher>
			<biblScope unit="page" from="574" to="585" />
		</imprint>
	</monogr>
	<note>The ethics of humanoid sex robots</note>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Robotic animism: The ethics of attributing minds and personality to robots with artificial intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-94170-3_13</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-94170-3_13" />
	</analytic>
	<monogr>
		<title level="m">Palgrave frontiers in philosophy of religion</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Smith</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="313" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">The technological future of love</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781003014331-18</idno>
		<ptr target="https://doi.org/10.4324/9781003014331-18" />
	</analytic>
	<monogr>
		<title level="m">Philosophy of love in the past, present, and future</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Grahle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Mckeever</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Saunders</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="224" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">How is the accountancy and finance world using artificial intelligence?</title>
		<author>
			<persName><forename type="first">E</forename><surname>O'neill</surname></persName>
		</author>
		<ptr target="https://www.icas.com/ca-today-news/how-accountancy-and-finance-are-using-artificial-intelligence" />
	</analytic>
	<monogr>
		<title level="j">ICAS</title>
		<imprint>
			<date type="published" when="2016-07-31">2016, July 31</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<ptr target="https://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p" />
		<title level="m">Online Safety Amendment (Social Media Minimum Age) Bill 2024, 127, House of Representatives</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">7284</biblScope>
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
	<note>query=Id%3A%22legislation%2F billhome%2Fr</note>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">It&apos;s not just sex: relational dynamics between street-based sex workers and their regular customers</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Oselin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hail-Jares</surname></persName>
		</author>
		<idno type="DOI">10.1177/09500170211021723</idno>
		<ptr target="https://doi.org/10.1177/09500170211021723" />
	</analytic>
	<monogr>
		<title level="j">Work, Employment and Society</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="893" to="910" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">Sexbot market guide: The best AI sex dolls and sex robots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Owsianik</surname></persName>
		</author>
		<ptr target="https://futureofsex.net/robots/state-of-the-sexbot-market-the-worlds-best-sex-robot-and-ai-love-doll-companies/" />
	</analytic>
	<monogr>
		<title level="j">Future of Sex</title>
		<imprint>
			<date type="published" when="2023-09-05">2023, September 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">Beneficent dehumanization: Employing Artificial Intelligence and carebots to mitigate shame-induced barriers to medical care</title>
		<author>
			<persName><forename type="first">A</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schwan</surname></persName>
		</author>
		<idno type="DOI">10.1111/bioe.12986</idno>
		<ptr target="https://doi.org/10.1111/bioe.12986" />
	</analytic>
	<monogr>
		<title level="j">Bioethics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="187" to="193" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">Constructing the meaning of human-AI romantic relationships from the perspectives of users dating the social chatbot Replika</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mou</surname></persName>
		</author>
		<idno type="DOI">10.1111/pere.12572</idno>
		<ptr target="https://doi.org/10.1111/pere.12572" />
	</analytic>
	<monogr>
		<title level="j">Personal Relationships</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1090" to="1112" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Generative agents: Interactive simulacra of human behavior</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<idno type="DOI">10.1145/3586183.3606763</idno>
		<ptr target="https://dl.acm.org/doi/10.1145/3586183.3606763" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 36th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Q</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Willer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2411.10109</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2411.10109" />
		<title level="m">Generative agent simulations of 1,000 people</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main">Exploring relationship development with social chatbots: A mixed-method study of Replika</title>
		<author>
			<persName><forename type="first">I</forename><surname>Pentina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2022.107600</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2022.107600" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2023">2023. 107600</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">AI will never convey the essence of human empathy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-023-01675-w</idno>
		<ptr target="https://doi.org/10.1038/s41562-023-01675-w" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1808" to="1809" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Pettit</surname></persName>
		</author>
		<title level="m">The robust demands of the good: Ethics with attachment, virtue, and respect</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minssen</surname></persName>
		</author>
		<idno type="DOI">10.1056/AIp2400449</idno>
		<ptr target="https://doi.org/10.1056/AIp2400449" />
	</analytic>
	<monogr>
		<title level="m">The EU AI Act: Implications for U.S. health care</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">AUTOGEN: A personalized large language model for academic enhancement-ethics and proof of principle</title>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Møller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Suren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1080/15265161.2023.2233356</idno>
		<ptr target="https://doi.org/10.1080/15265161.2023.2233356" />
	</analytic>
	<monogr>
		<title level="j">The American Journal of Bioethics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="28" to="41" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">AUTOGEN and the ethics of co-creation with personalized LLMs-reply to the commentaries</title>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Møller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Suren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1080/15265161.2024.2308175</idno>
		<ptr target="https://doi.org/10.1080/15265161.2024.2308175" />
	</analytic>
	<monogr>
		<title level="j">The American Journal of Bioethics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="6" to="14" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">Generative AI entails a credit-blame asymmetry</title>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Danaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Møller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bowman-Smart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hatherley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Plozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rodger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Treit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Renard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-023-00653-1</idno>
		<ptr target="https://doi.org/10.1038/s42256-023-00653-1" />
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="472" to="475" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Reasons in the loop: The role of large language models in medical co-reasoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1080/15265161.2024.2383121</idno>
		<ptr target="https://doi.org/10.1080/15265161.2024.2383121" />
	</analytic>
	<monogr>
		<title level="j">The American Journal of Bioethics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="105" to="107" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<monogr>
		<title level="m" type="main">Development of application-specific large language models to facilitate research ethics review</title>
		<author>
			<persName><forename type="first">Porsdam</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Latham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Savulescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aboy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2501.10741" />
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">Guidelines for ethical use and acknowledgement of large language models in academic writing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Vazirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aboy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-024-00922-7</idno>
		<ptr target="https://doi.org/10.1038/s42256-024-00922-7" />
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1272" to="1274" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Not relational enough? Towards an eco-relational approach in robot ethics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Puzio</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-024-00730-2</idno>
		<ptr target="https://doi.org/10.1007/s13347-024-00730-2" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">45</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Pyrzanowska</surname></persName>
		</author>
		<ptr target="https://mdrregulator.com/news/custom-made-medical-devices-mdr" />
		<title level="m">MDR requirements for custom-made medical devices. MDR Regulator</title>
		<imprint>
			<date type="published" when="2021-03-26">2021. March 26</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Moral psychology is relationship regulation: Moral motives for unity, hierarchy, equality, and proportionality</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Fiske</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0021867</idno>
		<ptr target="https://doi.org/10.1037/a0021867" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="75" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">Society-in-the-loop: Programming the algorithmic social contract</title>
		<author>
			<persName><forename type="first">I</forename><surname>Rahwan</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10676-017-9430-8</idno>
		<ptr target="https://doi.org/10.1007/s10676-017-9430-8" />
	</analytic>
	<monogr>
		<title level="j">Ethics and Information Technology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="14" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<monogr>
		<title level="m" type="main">Ethics and artificial intelligence</title>
		<author>
			<persName><forename type="first">P</forename><surname>Railton</surname></persName>
		</author>
		<ptr target="https://www.uehiro.ox.ac.uk/uehiro-lectures-2022" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
		<respStmt>
			<orgName>University of Oxford</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">On medical devices, amending Directive</title>
		<idno>1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC</idno>
		<ptr target="http://data.europa.eu/eli/reg/2017/745/oj" />
	</analytic>
	<monogr>
		<title level="m">European Parliament, Council of the European Union</title>
		<title level="s">Annex III: High-Risk AI Systems. Artificial Intelligence Act. European Parliament</title>
		<imprint>
			<date type="published" when="1689">2024/1689. 2001. 2002</date>
		</imprint>
	</monogr>
	<note>Council of the European Union</note>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">The puzzle of evaluating moral cognition in artificial agents</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Reinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kunesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Duéñez-Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<idno type="DOI">10.1111/cogs.13315</idno>
		<ptr target="https://doi.org/10.1111/cogs.13315" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Developmental changes in the perceived moral standing of robots</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Reinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wilks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bloom</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2024.105983</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2024.105983" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">254</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2025">2025. 105983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">The need for an empirical research program regarding human-AI relational norms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Reinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kappes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-024-00631-2</idno>
		<ptr target="https://doi.org/10.1007/s43681-024-00631-2" />
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Reinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Singh</surname></persName>
		</author>
		<ptr target="https://www.mdpi.com/journal/proceedings" />
		<title level="m">The double-edged sword of anthropomorphism in LLMs. Proceedings, forthcoming at</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">The asymmetrical &apos;relationship&apos;: Parallels between prostitution and the development of sex robots</title>
		<author>
			<persName><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.1145/2874239.2874281</idno>
		<ptr target="https://doi.org/10.1145/2874239.2874281" />
	</analytic>
	<monogr>
		<title level="j">SIGCAS Computers &amp; Society</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="290" to="293" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<monogr>
		<title level="m" type="main">Robo sapiens Japanicus: Robots, gender, family, and the Japanese nation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robertson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>University of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Rosemont</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Ames</surname></persName>
		</author>
		<idno type="DOI">10.14220/9783737006057</idno>
		<ptr target="https://doi.org/10.14220/9783737006057" />
		<title level="m">Confucian role ethics</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<analytic>
		<title level="a" type="main">Rights-bearing Individuals and role-bearing persons</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rosemont</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rules, rituals, and responsibility</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Bockover</surname></persName>
		</editor>
		<meeting><address><addrLine>La Salle</addrLine></address></meeting>
		<imprint>
			<publisher>Open Court</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="71" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<monogr>
		<title level="m" type="main">Against individualism: A Confucian rethinking of the foundations of morality, politics, family, and religion</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rosemont</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Lexington Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<analytic>
		<title level="a" type="main">Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rudin</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-019-0048-x</idno>
		<ptr target="https://doi.org/10.1038/s42256-019-0048-x" />
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="206" to="215" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b232">
	<analytic>
		<title level="a" type="main">It&apos;s friendship, Jim, but not as we know it: A degrees-of-friendship view of human-robot friendships</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ryland</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11023-021-09560-z</idno>
		<ptr target="https://doi.org/10.1007/s11023-021-09560-z" />
	</analytic>
	<monogr>
		<title level="j">Minds and Machines</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="393" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b233">
	<analytic>
		<title level="a" type="main">The thinking of thoughts. What is Le Penseur doing?</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ryle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Collected essays 1929 -1968</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Tanny</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="1968">1968a</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">Thinking and reflecting</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ryle</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-349-27908-1_12</idno>
		<ptr target="https://doi.org/10.1007/978-1-349-27908-1_12" />
	</analytic>
	<monogr>
		<title level="m">The human agent</title>
		<meeting><address><addrLine>Macmillan UK.</addrLine></address></meeting>
		<imprint>
			<publisher>Palgrave</publisher>
			<date type="published" when="1968">1968b</date>
			<biblScope unit="page" from="210" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b235">
	<analytic>
		<title level="a" type="main">Ethical considerations in artificial intelligence interventions for mental health and well-being: Ensuring responsible implementation and impact</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Saeidnia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Hashemi Fotami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ghiasi</surname></persName>
		</author>
		<idno type="DOI">10.3390/socsci13070381</idno>
		<ptr target="https://doi.org/10.3390/socsci13070381" />
	</analytic>
	<monogr>
		<title level="j">Social Sciences</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="381" to="396" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<analytic>
		<title level="a" type="main">Direct vs. indirect moral enhancement</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">G</forename><surname>Schaefer</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-024-00969-6</idno>
		<ptr target="https://doi.org/10.1038/s42256-024-00969-6" />
	</analytic>
	<monogr>
		<title level="j">Kennedy Institute of Ethics Journal</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="289" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b237">
	<monogr>
		<author>
			<persName><forename type="first">Schaich</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sinnott-Armstrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Conitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename></persName>
		</author>
		<title level="m">Moral AI: And how we get there</title>
		<imprint>
			<publisher>Pelican Books</publisher>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b238">
	<analytic>
		<title level="a" type="main">Evolution and human motivation: A fundamental motives framework</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schaller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Kenrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Neel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Neuberg</surname></persName>
		</author>
		<idno type="DOI">10.1111/spc3.12319</idno>
		<ptr target="https://doi.org/10.1111/spc3.12319" />
	</analytic>
	<monogr>
		<title level="j">Social and Personality Psychology Compass</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<analytic>
		<title level="a" type="main">Two systems for empathy: A double dissociation between emotional and cognitive empathy in inferior frontal gyrus versus ventromedial prefrontal lesions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schleidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Tsoory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aharon-Peretz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1093/brain/awn279</idno>
		<ptr target="https://doi.org/10.1093/brain/awn279" />
	</analytic>
	<monogr>
		<title level="j">Nanoethics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="617" to="627" />
			<date type="published" when="2009">2022. 2009</date>
		</imprint>
	</monogr>
	<note>Brain</note>
</biblStruct>

<biblStruct xml:id="b240">
	<analytic>
		<title level="a" type="main">AI and the quest for diversity and inclusion: A systematic literature review</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Shams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zowghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bano</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-023-00362-w</idno>
		<ptr target="https://link.springer.com/article/10.1007/s43681-023-00362-w" />
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<analytic>
		<title level="a" type="main">Role play with large language models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mcdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Reynolds</surname></persName>
		</author>
		<ptr target="https://www.nature.com/articles/s41586-023-06647-8" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">623</biblScope>
			<biblScope unit="issue">7987</biblScope>
			<biblScope unit="page" from="493" to="498" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b242">
	<analytic>
		<title level="a" type="main">Robots and human dignity: A consideration of the effects of robot care on the dignity of older people</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharkey</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10676-014-9338-5</idno>
		<ptr target="https://doi.org/10.1007/s10676-014-9338-5" />
	</analytic>
	<monogr>
		<title level="j">Ethics and Information Technology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="75" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<analytic>
		<title level="a" type="main">Granny and the robots: Ethical issues in robot care for the elderly</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharkey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sharkey</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10676-010-9234-6</idno>
		<ptr target="https://doi.org/10.1007/s10676-010-9234-6" />
	</analytic>
	<monogr>
		<title level="j">Ethics and Information Technology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="40" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">All too human? Identifying and mitigating ethical risks of social AI. Law</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shevlin</surname></persName>
		</author>
		<ptr target="https://www.elspub.com/papers/j/1756695755401928704" />
	</analytic>
	<monogr>
		<title level="j">Ethics &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b245">
	<monogr>
		<title level="m" type="main">Oxford handbook on the foundations and regulation of generative AI</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shevlin</surname></persName>
		</author>
		<ptr target="https://philarchive.org/rec/SHEEAT-12" />
		<editor>P. Hacker</editor>
		<imprint>
			<date type="published" when="2025">2025</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
	<note>Ethics at the frontier of human-AI relationships</note>
</biblStruct>

<biblStruct xml:id="b246">
	<analytic>
		<title level="a" type="main">Moral address, moral responsibility, and the boundaries of the moral community</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shoemaker</surname></persName>
		</author>
		<idno type="DOI">10.1086/521280</idno>
		<ptr target="https://doi.org/10.1086/521280" />
	</analytic>
	<monogr>
		<title level="j">Ethics</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="70" to="108" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b247">
	<analytic>
		<title level="a" type="main">The &quot;big three&quot; of morality (autonomy, community, divinity) and the &quot;big three&quot; explanations of suffering</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Shweder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Much</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mahapatra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Morality and health</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Rozin</surname></persName>
		</editor>
		<meeting><address><addrLine>Taylor &amp; Frances</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="119" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b248">
	<analytic>
		<title level="a" type="main">Wrongness in different relationships: Relational context effects on moral judgment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Laham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Fiske</surname></persName>
		</author>
		<idno type="DOI">10.1080/00224545.2016.1140118</idno>
		<ptr target="https://doi.org/10.1080/00224545.2016.1140118" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Social Psychology</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="594" to="609" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b249">
	<analytic>
		<title level="a" type="main">My Chatbot companion -A study of human-chatbot relationships</title>
		<author>
			<persName><forename type="first">M</forename><surname>Skjuve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Følstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Fostervold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Brandtzaeg</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijhcs.2021.102601</idno>
		<ptr target="https://doi.org/10.1016/j.ijhcs.2021.102601" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">102601</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b250">
	<analytic>
		<title level="a" type="main">Robots in the workplace: A threat to-or opportunity for-meaningful work?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Smids</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Berkers</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-019-00377-4</idno>
		<ptr target="https://doi.org/10.1007/s13347-019-00377-4" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="503" to="522" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b251">
	<analytic>
		<title level="a" type="main">Children&apos;s perceptions of the moral worth of live agents, robots, and inanimate objects</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Draheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Redshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Vanman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wilks</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jecp.2019.06.009</idno>
		<ptr target="https://doi.org/10.1016/j.jecp.2019.06.009" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Child Psychology</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2019">2019. 104656</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b252">
	<analytic>
		<title level="a" type="main">Robots, rape, and representation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sparrow</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12369-017-0413-z</idno>
		<ptr target="https://doi.org/10.1007/s12369-017-0413-z" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="465" to="477" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b253">
	<analytic>
		<title level="a" type="main">The ethics of sex robots</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sterri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<idno type="DOI">10.1093/oxfordhb/9780198857815.013.13</idno>
		<ptr target="https://doi.org/10.1093/oxfordhb/9780198857815.013.13" />
	</analytic>
	<monogr>
		<title level="m">Oxford handbook of digital ethics</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Véliz</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="241" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b254">
	<analytic>
		<title level="a" type="main">Distributed responsibility in human-machine interactions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Strasser</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-021-00109-5</idno>
		<ptr target="https://doi.org/10.1007/s43681-021-00109-5" />
	</analytic>
	<monogr>
		<title level="j">AI &amp; Ethics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="523" to="532" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b255">
	<analytic>
		<title level="a" type="main">Freedom and resentment</title>
		<author>
			<persName><forename type="first">P</forename><surname>Strawson</surname></persName>
		</author>
		<ptr target="https://www.thebritishacademy.ac.uk/publishing/proceedings-british-academy/48/strawson/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Academy</title>
		<meeting>the British Academy</meeting>
		<imprint>
			<date type="published" when="1962">1962</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="187" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b256">
	<analytic>
		<title level="a" type="main">Avatars and the value of human uniqueness</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sweeney</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-024-00811-2</idno>
		<ptr target="https://doi.org/10.1007/s13347-024-00811-2" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">118</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b257">
	<analytic>
		<title level="a" type="main">User experiences of social support from companion chatbots in everyday contexts: Thematic analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Griffith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Boatfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Civitello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Decero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loggarakis</surname></persName>
		</author>
		<idno type="DOI">10.2196/16235</idno>
		<ptr target="https://doi.org/10.2196/16235" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Internet Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b258">
	<analytic>
		<title level="a" type="main">Curse of the cyborg mammoths: the use of artificial intelligence in manipulating and mobilizing human emotions</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ethics in online AI-based systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Caballé</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Casas-Roma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">J</forename><surname>Conesa</surname></persName>
		</editor>
		<imprint>
			<publisher>Intelligent Data-Centric Systems</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="347" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b259">
	<analytic>
		<title level="a" type="main">Defining privacy: How users interpret technical terms in privacy policies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shoemaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Birrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on Privacy Enhancing Technologies</title>
		<meeting>on Privacy Enhancing Technologies</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b260">
	<analytic>
		<title level="a" type="main">Paternalism, participation and partnership-the evolution of patient centeredness in the consultation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.pec.2008.08.017</idno>
		<ptr target="https://doi.org/10.1016/j.pec.2008.08.017" />
	</analytic>
	<monogr>
		<title level="j">Patient Education and Counseling</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="150" to="155" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b261">
	<monogr>
		<title level="m" type="main">Attitudes, behavior, and social context: The role of norms and group membership</title>
		<editor>Terry, D. J., &amp; Hogg, M. A.</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b262">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Palepu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schaekermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freyberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tanno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tomasev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Semturs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gottweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Natarajan</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2401.05654</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2401.05654" />
		<title level="m">Towards conversational diagnostic AI</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b263">
	<monogr>
		<title level="m" type="main">Alone together: Why we expect more from technology and less from each other</title>
		<author>
			<persName><forename type="first">S</forename><surname>Turkle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Basic Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b264">
	<analytic>
		<title level="a" type="main">Sugaring: Understanding the world of sugar daddies and sugar babies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Upadhyay</surname></persName>
		</author>
		<idno type="DOI">10.1080/00224499.2020.1867700</idno>
		<ptr target="https://doi.org/10.1080/00224499.2020.1867700" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Sex Research</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="775" to="784" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b265">
	<analytic>
		<title level="a" type="main">Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vallor</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-011-0015-x</idno>
		<ptr target="https://doi.org/10.1007/s13347-011-0015-x" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="251" to="268" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b266">
	<monogr>
		<title level="m" type="main">Privacy is power. Why and how you should take back control of your data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Véliz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<pubPlace>Penguin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b267">
	<analytic>
		<author>
			<persName><forename type="first">P</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Register</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Savulescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename></persName>
		</author>
		<idno type="DOI">10.1007/s13347-024-00813-0</idno>
		<ptr target="https://doi.org/10.1007/s13347-024-00813-0" />
	</analytic>
	<monogr>
		<title level="m">They fell in love with AI bots. A software update broke their hearts. The Washington Post</title>
		<imprint>
			<date type="published" when="2023-03-30">2023. March 30. 2024. 2024</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Digital duplicates, relational scarcity, and value: Commentary on Danaher and Nyholm</note>
</biblStruct>

<biblStruct xml:id="b268">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Voinea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Register</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Savulescu</surname></persName>
		</author>
		<title level="m">The sorrows of young chatbot users</title>
		<imprint/>
	</monogr>
	<note>under review. under review</note>
</biblStruct>

<biblStruct xml:id="b269">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2310.13332" />
		<title level="m">Democratizing reasoning ability: Tailored learning from large language model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b270">
	<monogr>
		<title level="m" type="main">Gravity and grace</title>
		<author>
			<persName><forename type="first">S</forename><surname>Weil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>University of Nebraska Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b271">
	<monogr>
		<title level="m" type="main">The instantaneity of gendered voice assistant technology and manager perceptions of subordinate help</title>
		<author>
			<persName><forename type="first">H</forename><surname>Weisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Janardhanan</surname></persName>
		</author>
		<idno type="DOI">10.5465/ambpp.2020.21149abstract</idno>
		<ptr target="https://doi.org/10.5465/ambpp.2020.21149abstract" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Academy of Management Proceedings</publisher>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="21149" to="21190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b272">
	<analytic>
		<title level="a" type="main">Introducing artificial companions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wilks</surname></persName>
		</author>
		<idno type="DOI">10.1075/nlp.8.04wil</idno>
		<ptr target="https://doi.org/10.1075/nlp.8.04wil" />
	</analytic>
	<monogr>
		<title level="m">Natural language processing</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Wilks</surname></persName>
		</editor>
		<imprint>
			<publisher>John Benjamins Publishing Company</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b273">
	<monogr>
		<title level="m" type="main">Social robots and the risks to reciprocity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Wynsberghe</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-021-01207-y</idno>
		<ptr target="https://doi.org/10.1007/s00146-021-01207-y" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>AI &amp; Society</publisher>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="479" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b274">
	<monogr>
		<title level="m" type="main">A comprehensive study of jailbreak attack versus defense for large language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Picek</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2402.13457</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2402.13457" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b275">
	<analytic>
		<title level="a" type="main">Effects of social behaviors of robots in privacy-sensitive situations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Chae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nam</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12369-021-00809-2</idno>
		<ptr target="https://doi.org/10.1007/s12369-021-00809-2" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="589" to="602" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b276">
	<analytic>
		<title level="a" type="main">AI can help people feel heard, but an AI label diminishes this impact</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Wakslak</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2319112121</idno>
		<ptr target="https://doi.org/10.1073/pnas.2319112121" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b277">
	<analytic>
		<title level="a" type="main">Heart of the machine: Our future in a world of artificial emotional intelligence</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yonck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Leadership in Organizations</title>
		<meeting><address><addrLine>Arcade. Yukl, G; Boston</addrLine></address></meeting>
		<imprint>
			<publisher>Pearson</publisher>
			<date type="published" when="2013">2020. 2013</date>
		</imprint>
	</monogr>
	<note>th ed.</note>
</biblStruct>

<biblStruct xml:id="b278">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2410.20130</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2410.20130" />
		<title level="m">The dark side of AI companionship: A taxonomy of harmful algorithmic behaviors in human-AI relationships</title>
		<imprint>
			<date type="published" when="2024-10-26">2024, October 26</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b279">
	<analytic>
		<title level="a" type="main">Understanding human-machine cooperation in game-theoretical driving scenarios amid mixed traffic</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Awad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<idno type="DOI">10.1145/3613904.3642053</idno>
		<ptr target="https://doi.org/10.1145/3613904.3642053" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b280">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Zhi-Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ashton</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11098-024-02249-w</idno>
		<ptr target="https://doi.org/10.1007/s11098-024-02249-w" />
		<title level="m">Beyond preferences in AI alignment</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<analytic>
		<title level="a" type="main">These women fell in love with an AI-voiced chatbot</title>
		<author>
			<persName><forename type="first">V</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://restofworld.org/2023/boyfriend-chatbot-ai-voiced-shutdown/" />
	</analytic>
	<monogr>
		<title level="j">Then it died. Rest of World</title>
		<imprint>
			<date type="published" when="2023-08-17">2023. August 17</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b282">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Zimmerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Janhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Beer</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-023-00348-8</idno>
		<ptr target="https://link.springer.com/article/10.1007/s43681-023-00348-8" />
		<title level="m">Human/AI relationships: challenges, downsides, and impacts on human/human relationships. AI and Ethics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b283">
	<analytic>
		<title level="a" type="main">Generative AI and medical ethics: The state of play</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zohny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Porsdam Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcmillan</surname></persName>
		</author>
		<idno type="DOI">10.1136/jme-2023-109834</idno>
		<ptr target="https://doi.org/10.1136/jme-2023-109834" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Ethics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="75" to="76" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
