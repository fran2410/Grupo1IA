<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BRAIN. Broad Research in Artificial Intelligence and Neuroscience</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mihai-Lucian</forename><surname>Voncilă</surname></persName>
							<email>mihai_lucian.voncila@stud.acs.upb.ro</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science and Engineering Department</orgName>
								<orgName type="department" key="dep2">Faculty of Automatic Control and Computers</orgName>
								<orgName type="institution">National University of Science and Technology Politehnica Bucharest</orgName>
								<address>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nicolae</forename><surname>Tarbă</surname></persName>
							<email>nicolae.tarba@upb.ro</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Computer Science and Engineering Department</orgName>
								<orgName type="department" key="dep2">Faculty of Automatic Control and Computers</orgName>
								<orgName type="institution">National University of Science and Technology Politehnica Bucharest</orgName>
								<address>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ștefana</forename><surname>Oblesniuc</surname></persName>
							<email>stefana.oblesniuc@stud.acs.upb.ro</email>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Computer Science and Engineering Department</orgName>
								<orgName type="department" key="dep2">Faculty of Automatic Control and Computers</orgName>
								<orgName type="institution">National University of Science and Technology Politehnica Bucharest</orgName>
								<address>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Costin-Anton</forename><surname>Boiangiu</surname></persName>
							<email>costin.boiangiu@cs.pub.ro</email>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Computer Science and Engineering Department</orgName>
								<orgName type="department" key="dep2">Faculty of Automatic Control and Computers</orgName>
								<orgName type="institution">National University of Science and Technology Politehnica Bucharest</orgName>
								<address>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Valer</forename><surname>Nimineț</surname></persName>
							<email>valern@ub.ro</email>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Mathematics and Informatics</orgName>
								<orgName type="department" key="dep2">Faculty of Science</orgName>
								<orgName type="institution">Vasile Alecsandri University of Bacau</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BRAIN. Broad Research in Artificial Intelligence and Neuroscience</title>
					</analytic>
					<monogr>
						<idno type="ISSN">2067-3957</idno>
					</monogr>
					<idno type="MD5">5792B47137CE24AC39BEFCF1310B5079</idno>
					<note type="submission">Submitted: August 27 th , 2024| Accepted for publication: October 5 th , 2024</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2025-05-12T17:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Breast cancer is the second most common type of cancer for women, the first being lung cancer <ref type="bibr">(World Health Organization, 2024)</ref>. According to the World Health Organisation, over 2 million women were diagnosed with breast cancer in 2022 (International Agency for Research on Cancer, n.d.) and over 670 thousand died <ref type="bibr">(Breast Cancer Research Foundation, n.d.)</ref>.</p><p>Diagnosing can be a laborious process, with multiple steps often required to make an accurate assessment. Various medical imaging techniques are often employed during this process, with various degrees of accuracy, depending on the stage of the diagnosis. The most common ones are those based on mammography, echography, thermography, magnetic resonance imaging (MRI), and histopathology <ref type="bibr" target="#b36">(Safdar et al., 2022)</ref>.</p><p>Thermography is a non-invasive imaging technique that records the variation of temperature in the body, based on infrared radiation emitted by the body <ref type="bibr" target="#b40">(Singh &amp; Singh, 2020)</ref>. Thermography can be used during the initial consultation and is considered a good method in the early stages of cancer. However, it has some disadvantages, such as being unable to detect small tumors and being susceptible to interference from various body temperature changes. Specialists have diverse opinions on this type of imaging and use it in conjunction with mammography or other techniques.</p><p>Mammography is considered one of the most efficient methods for breast cancer detection and diagnosis. Through mammography, abnormalities in the soft tissue can be visualized and calcifications can be observed. It's a very insightful and intensely studied technique with standard protocols, but it also has disadvantages, such as exposure to radiation, false positives or false negatives, and lower efficiency in certain women such as younger women or women with thicker tissue.</p><p>MRI offers a 3D anatomical perspective and can indicate a heightened vascular density and changes in vascular permeability. It's recommended to women with a high risk of breast cancer such as those with a family history of breast cancer and those who present certain mutations <ref type="bibr" target="#b39">(Sheikh et al., 2015)</ref>. <ref type="bibr" target="#b20">Karellas and Vedantham (Karellas &amp; Vedantham, 2008)</ref> found that breast cancer detection with MRI has a success rate of over 90% but determining the type of tumor (benign or malign) has a success rate of only 72%. Other disadvantages include high cost, low availability due to the high cost of the required equipment, and the relatively high rate of false positives. It is also not recommended for people with claustrophobia or kidney issues.</p><p>Echography has been used for a long time to differentiate cystic mass from solid mass. It's not recommended as a primary imaging method; it's usually used in conjunction with other methods such as mammography or MRI. <ref type="bibr" target="#b21">(Kolb et al., 2002)</ref> found that a physical consultation followed by a mammography has an accuracy of 74%, and a mammography followed by an echography has an accuracy of 97%. The limited viewing angle results in a reduced perspective of the tissue and the method is susceptible to noise.</p><p>Histopathological images are obtained through a microscope from biopsied tissue. This method offers a detailed but invasive diagnosis of the cellular structure, but it depends on the size and quality of the biopsy sample. It is considered one of the best diagnosis methods but is highly susceptible to human error. <ref type="bibr" target="#b13">(Gurcan et al., 2009)</ref> highlights the need for automatization in the diagnosis process, including determining the type of tumor (benign or malign), which would allow more time for studying malign tumors. The anatomopathologist reports the size, location, and consistency of the tissue and whether or not it is cancerous. When medics disagree on the same sample a new sample is harvested.</p><p>Image analysis can be used to help oncologists, anatomopathologists, and other specialists minimize human error in their diagnoses. Accuracy and ease of use are the primary objectives to strive for. through a Modified  In this paper, we propose a binary classification model trained using supervised learning on a medium-sized dataset with histopathology images that contain a breast cancer type named invasive ductal carcinoma (IDC). The model achieves an accuracy of 95.61%, precision of 96%, recall of 94%, and F1-score of 95% on our dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In terms of detecting and diagnosing breast cancer, various approaches have been developed over the years, ranging from traditional computer-assisted diagnosis (CAD) systems to more advanced deep learning architectures, particularly convolutional neural networks (CNNs).</p><p>Methods related to CAD often involved manually extracting various features from images, mostly related to shapes, followed by classification using techniques like support vector machines (SVMs) <ref type="bibr" target="#b6">(Byrne et al., 2011;</ref><ref type="bibr" target="#b17">Hussain, Wajid, Elzaart, &amp; Berbar, 2011;</ref><ref type="bibr" target="#b35">Rejani &amp; Selvi, 2009;</ref><ref type="bibr" target="#b49">Zhang et al., 2013)</ref>. These systems, while beneficial, often faced challenges in generalizability and required extensive domain knowledge to design effective feature extractors. While these systems work similarly for different inputs, such as mammographies, histopathologies, etc., they each present different limitations and algorithms based on the data to be analyzed.</p><p>Alongside CAD methods, multiple CNNs such as AlexNet, VGG, ResNet, ResNeXt, DenseNet, and ImageNet-based models, have been proposed and adapted for breast cancer detection and diagnosis, each presenting its strengths. Various papers <ref type="bibr" target="#b48">(Yao et al., 2019;</ref><ref type="bibr">Boumaraf, Liu, &amp; Ferkous, 2020;</ref><ref type="bibr" target="#b34">Ragab et al., 2019;</ref><ref type="bibr" target="#b0">Acharya et al., 2012;</ref><ref type="bibr" target="#b12">Francis, Sasikala, &amp; Saranya, 2014;</ref><ref type="bibr" target="#b46">Yan et al., 2018;</ref><ref type="bibr" target="#b33">Punitha, Amuthan, &amp; Joseph, 2018;</ref><ref type="bibr" target="#b26">Lotter et al., 2021;</ref><ref type="bibr" target="#b31">Ng &amp; Kee, 2007)</ref> have used these techniques to train different models on a multitude of datasets with varying degrees of precision.</p><p>In addition to using standalone CNN architectures, hybrid approaches that combine multiple models have also been explored. For example, ensemble methods that aggregate the predictions of different CNNs or combine CNNs with traditional CAD features have shown promise in improving diagnostic acc uracy <ref type="bibr" target="#b9">( Daoud et al., 2020;</ref><ref type="bibr" target="#b47">Yan et al., 2020;</ref><ref type="bibr" target="#b38">Shahidi et al., 2020;</ref><ref type="bibr" target="#b45">Xie et al., 2017;</ref><ref type="bibr" target="#b44">Xie et al., 2019;</ref><ref type="bibr" target="#b19">Jiang et al., 2019;</ref><ref type="bibr" target="#b28">Mushtaq et al., 2021;</ref><ref type="bibr" target="#b11">Deniz et al., 2018;</ref><ref type="bibr" target="#b24">Krizhevsky, Sutskever, &amp; Hinton, 2012;</ref><ref type="bibr" target="#b15">Han et al., 2017;</ref><ref type="bibr" target="#b42">Vesal et al., 2018;</ref><ref type="bibr" target="#b41">Vang, Chen, &amp; Xie, 2018;</ref><ref type="bibr" target="#b25">Kwok, 2018;</ref><ref type="bibr" target="#b22">Koné &amp; Boulmane, 2018;</ref><ref type="bibr">Nawaz, Sewissy, &amp; Soliman, 2018;</ref><ref type="bibr" target="#b15">Han et al., 2017)</ref>. These models benefit from the diverse strengths of different architectures and are more robust to variations in the data.</p><p>The performance of these CNN architectures is often evaluated on various datasets. These datasets can be broadly categorized into public and in-house collections.</p><p>In the case of mammographies, the most widely used public datasets are those of the Digital Database for Screening Mammography (DDSM) (references), which contains a total of 2620 images, INbreast (references) with 410 images, and the wider used Curated Breast Imaging Subset of DDSM (CBIS-DDSM: Breast cancer image dataset, n.d.,) which contains more than 10000 annotated images that can be used to better train deep-learning models.</p><p>For histopathology public datasets such as (BACH ICIAR 2018 grand challenge on breast cancer histology images, n.d.) with 400 images, BioImaging 2015 with 249 images, alongside Extended BioImaging 2015 <ref type="bibr" target="#b1">(Araújo et al., 2017)</ref> with 1319 images, (PatchCamelyon: Breast cancer image dataset, n.d.), (BreakHis: Breast cancer image dataset, n.d.) tend to represent the most used ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>We propose a supervised learning approach based on a slightly modified ResNet-50 <ref type="bibr" target="#b16">(He et al., 2016)</ref> architecture, which can be observed in Figure <ref type="figure" target="#fig_0">1</ref>. We add a sequential part at the end of the ResNet50 architecture which comprises an extra Batch Normalization Layer in front of a Fully Connected layer with 256 elements, using a ReLu activation function. Then the output of these layers is reduced to just one, since we are only interested in classifying if cancer is present or not, for which we use a Sigmoid activation function. Artificial Intelligence and Neuroscience The modified architecture is chosen for the following reasons:</p><p>• The Batch Normalization layer is added to the end of the ResNet-50 model in order to normalize the feature inputs on the color channels across different batches before the inputs are sent to the Fully Connected layer. The layer works with a momentum of 0.99 which is appropriate for the chosen number of 32 images per batch, as it is less likely a certain image in a batch will vary the mean greatly. • The Fully Connected layer follows the Batch Normalization layer having a total of 256 nodes. This number was chosen to address the complexity of differentiating between images that contain cancer and those that don't. Various other values were tested but the best results were obtained for 256 nodes. • Inside the Fully Connected layer, we also use a set of regularizers in order to avoid both underfitting and overfitting, more specifically a kernel regularizer of L2, with a factor of 0.016 to reduce the influence of larger weight coefficients. Similarly, we use two L1 regularizers for biases and outputs in order to further reduce the potential of overfitting, both using a factor of 6e-4. • We use a ReLu activation function because it tends to learn better on these particular sets of images, though other functions were also tested. • Because we are only interested in detecting if a certain image contains or doesn't contain cancer, we end the output of our model with a Fully Connected layer of 1 node which is activated by a sigmoid function to predict the desired binary output.</p><p>We use a threshold of 0.5 for the output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>The dataset used in this paper <ref type="bibr">(Mooney, n.d.)</ref> is composed of 162 images of very high resolution which pertain to a specific type of breast cancer, more specifically that of IDC. These images were further sectioned into a total of approximately 277000 images of 50x50 resolution, out of which 72% were benign and 28% were malignant. Examples of such images can be seen in Figure <ref type="figure" target="#fig_1">2</ref>. Under-Sampling (MLPUS) <ref type="bibr" target="#b2">(Babar &amp; Ade, 2016)</ref>, and to over-sampling such as those based on Synthetic Minority Over-Sampling Technique (SMOTE) <ref type="bibr" target="#b8">(Chawla et al., 2002)</ref>. MLPUS works by selecting a variety of samples from the majority class and clustering them, followed by determining the most important samples using some form of evaluation, and training of the Multilayer Perceptron (MLP) based on said samples. The selected samples are then again clustered by using a k-means algorithm, where k would be equal to the number of samples in the minority class. While this is a useful method for under-sampling in the case of a major disparity between classes, in our case the ratio is just one of about 3:1, thus the usage and the complexity of reducing the samples is not justified.</p><p>Similarly, an over-sampling technique such as SMOTE could be employed. SMOTE works by clustering data in the minority class and then selecting certain samples and their nearest neighbors and interpolating between them in order to generate new samples. Whilst this is a valid method for generating new samples, it suffers from a couple of issues, mainly that of data generalization since samples are interpolated based on nearest neighbors. Other methods based on SMOTE, such as Borderline-SMOTE <ref type="bibr" target="#b14">(Han, Wang, &amp; Mao, 2005)</ref> have been proposed which seek to solve these issues by over-sampling minority samples located next to some decision boundaries. Whilst these methods can generate valid new data, they can suffer from issues such as choosing outliers in the data, thus increasing the overall noisiness of the dataset. Additionally, the technique can increase the complexity and the overall duration of the training. For these reasons, we chose to use a more simplistic approach instead.</p><p>In the case of our paper, we choose a simple approach of randomly subsampling the two classes into equal-sized datasets of 10000 images each, giving us a dataset comprised of 20000 images split in a balanced manner. We choose this approach for a variety of reasons, more specifically the gains compared to the performance costs can be considered marginal, as well as the fact that the class imbalance is not severe enough to justify a more complex approach, due to the ratio being only 3:1. One thing to note is that while picking a smaller subsample of the dataset than the one equal to the minority class can lead to potential data loss, we consider the number of images chosen to still be diverse and representative enough for this not to be an issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Data Augmentation</head><p>Due to reducing the size of our dataset, we decided to further increase the robustness of our model by performing on-the-fly augmentations. This is done in order to avoid potential overfitting as well as increase the potential for generalization, whilst not increasing the dataset size so the training time is kept the same. We choose a variety of different augmentations and approaches that won't modify the data drastically, in order to avoid introducing potential synthetic outliers.</p><p>Since histopathological images are captured using high-resolution microscopes, this process may introduce noise due to certain imaging artifacts, such as uneven lighting or sample preparation issues, which can obscure important tissue structures and hinder the identification of cancerous cells. In order to prevent this we use a Gaussian filter which can smooth the image while maintaining certain fine details such as edges which are essential in differentiating between malignant and benign areas.</p><p>Since tumors tend to have an irregular shape and are very varied in their shapes, in the case of IDC, severe rotations can affect the potential to detect certain structures and evaluate them correctly. Additionally, since the model is pre-trained on ImageNet and images with certain orientations, varying said orientations drastically can also reduce overall performance. For this reason, we choose to only use rotations at small angles, of up to 20 degrees, small image shifts that can preserve the overall structure of up to 20% of the image width/height, as well as flips which can also preserve the overall structure.</p><p>Because the images are in a 50x50 resolution, and ResNet-50 requires inputs in the shape of 224x224 images, we use a variety of methods to achieve this requirement. The simplest one is that of directly upscaling the images to the desired resolution using cubic interpolation. Similarly, we Artificial Intelligence and Neuroscience don't have to directly upscale to the desired resolution and can use padding alongside upscaling to obtain the required input. Both these methods have their detriments, as they tend to introduce additional features or can lead to creating outliers in the dataset, and since this has to be applied to every image in the dataset it can affect the result as a whole. In the future methods of combining images in patches for training could be considered in order to maintain a more organic overall input, or more complex upscaling using CNN or super-resolution techniques could be employed.</p><p>Another set of methods we employed are those related to changing the color values of the image, specifically by changing the color space to grayscale. This tends to reduce the model complexity, with the main downside that the model was trained on RGB images, thus certain variations can lead to issues in Additionally, some features can be lost when changing color spaces, and certain artifacts could also be introduced.</p><p>Contrast adjustment remaps pixel values so that they cover the full range of valid pixel values. Various methods can be used, ranging from quick and simple global methods such as rescaling and histogram equalization to more computationally intensive adaptive techniques. Contrast adjustment makes finer details in the image more pronounced, allowing the classifier to more easily differentiate between healthy and cancerous images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Training and validation</head><p>In order to train our model, we split the dataset into 80% training data and 20% test data. The training data is further split into training and validation using a five-fold cross-validation algorithm. The input of our model has been modified again into gamma tone spectrograms of feature maps and fed into the ResNet-50 architecture. The model is pre-trained on the ImageNet <ref type="bibr" target="#b10">(Deng et al., 2009)</ref> dataset to improve training speed and reduce potential overfitting. We train our models for 50 epochs on the Google Collab platform using an Adam optimizer, with an initial learning rate of 1e-5, and a batch size of 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>In Table <ref type="table" target="#tab_0">1</ref> we can observe results for different combinations of augmentation methods used during training that use only the original ResNet-50 architecture. Table <ref type="table">2</ref> presents the results for methods used in our proposed architecture. Methods 5 and 6 use, alongside the mentioned techniques, those of rotation, flipping, and shifting, as well as padding. The evolution of these methods can be seen in Figures <ref type="figure" target="#fig_2">3 and 4</ref>, which present the evolution of the overall accuracy, as well as that of the loss function, alongside the confusion matrix. Table <ref type="table" target="#tab_1">3</ref> showcases the results obtained by training using five-fold cross-validation and the sixth method since that gave the best overall results. These models were trained on only 20 epochs each. As we can see the third and fourth folds seem to offer the best overall results whilst the first fold offers the worst overall results. Even though the fourth fold has higher metrics during validation it performs worse during training, thus we can assume the fold is likely more biased. For this reason, we consider the third fold to offer the best results. Artificial Intelligence and Neuroscience </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>As we can see from the results our proposed model obtained an accuracy of 95.61%, a precision of 96%, a recall of 94%, and an F1-score of 95%. This outperforms the model proposed in <ref type="bibr" target="#b37">(Sathe et al., 2020)</ref> which only obtains an overall accuracy of around 87.64% on the same dataset. In order to increase the accuracy as well the other metrics we used a variety of data augmentation techniques, as well as five-fold cross-validation, which also allows for a more robust and reliable model.</p><p>For future work, the model could be compared to a variety of other architectures or be tested on different other datasets, such as (BACH ICIAR 2018 grand challenge on breast cancer histology images, n.d.), or PatchCamelyon (PatchCamelyon: Breast cancer image dataset, n.d.) to see how it would perform on them. Another thing that could be tried would be combining unsupervised techniques with those of CNN and see if there are potential other improvements that can be obtained.</p><p>Something else that can be done in the future is qualifying uncertainty in the predictions through the use of different techniques such as Monte Carlo Dropout to fit the model output to a distribution as opposed to a single value. This would allow for the better detection of potential outliers or determine if the model hyperparameters could be better adjusted in obtaining more robust configurations. In addition to this, enabling visualization of the model's feature maps can also be employed to further allow people a better understanding of why certain decisions were made during classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The architecture of our proposed method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Example of dataset images: benign (a), (b); malignant (c), (d)</figDesc><graphic coords="4,104.51,570.37,387.75,109.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Fifth method results</figDesc><graphic coords="7,75.26,86.75,446.25,180.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Third fold results</figDesc><graphic coords="8,101.51,72.95,201.75,156.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="1,257.70,213.05,279.75,390.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table><row><cell>ResNet-50 results</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell># Method</cell><cell>Accuracy (%)</cell><cell>Precision (%)</cell><cell>Recall (%)</cell><cell>F1-Score (%)</cell></row><row><cell>1 rescaling</cell><cell>87.09</cell><cell>51</cell><cell>50</cell><cell>50</cell></row><row><cell>2 rescaling, grayscale conversion</cell><cell>87.44</cell><cell>54</cell><cell>52</cell><cell>52</cell></row><row><cell>3 rescaling, contrast adjustment</cell><cell>79.06</cell><cell>55</cell><cell>57</cell><cell>56</cell></row><row><cell>Table 2. Proposed Method results</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell># Method</cell><cell>Accuracy (%)</cell><cell cols="2">Precision (%) Recall (%)</cell><cell>F1-Score (%)</cell></row><row><cell>4 rescaling</cell><cell>92.44</cell><cell>53</cell><cell>54</cell><cell>54</cell></row><row><cell>5 rescaling, grayscale</cell><cell>93.48</cell><cell>52</cell><cell>54</cell><cell>53</cell></row><row><cell>conversion, adaptive</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>thresholding</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>6 rescaling, color conversion,</cell><cell>93.25</cell><cell>56</cell><cell>58</cell><cell>57</cell></row><row><cell>histogram equalization</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Five-fold cross-validation results</figDesc><table><row><cell>Fold</cell><cell>Accuracy (%)</cell><cell>Precision (%)</cell><cell>Recall (%)</cell><cell>F1-Score (%)</cell><cell>Loss</cell></row><row><cell>1</cell><cell>49.04</cell><cell>49</cell><cell>100</cell><cell>66</cell><cell>12.31</cell></row><row><cell>2</cell><cell>68.22</cell><cell>100</cell><cell>27</cell><cell>43</cell><cell>1.88</cell></row><row><cell>3</cell><cell>95.61</cell><cell>96</cell><cell>94</cell><cell>95</cell><cell>1.86</cell></row><row><cell>4</cell><cell>98.08</cell><cell>97</cell><cell>99</cell><cell>98</cell><cell>7.39</cell></row><row><cell>5</cell><cell>94.5</cell><cell>88</cell><cell>100</cell><cell>94</cell><cell>4.63</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Thermography-based breast cancer detection using texture features and support vector machine</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Sree</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10916-010-9611-z</idno>
		<ptr target="https://doi.org/10.1007/s10916-010-9611-z" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1503" to="1510" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Classification of breast cancer histology images using convolutional neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aresta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rouco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eloy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polónia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Campilho</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0177544</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0177544" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A novel approach for handling imbalanced data in medical diagnosis using undersampling technique</title>
		<author>
			<persName><forename type="first">V</forename><surname>Babar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Applied Electronics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="36" to="42" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A new transfer learning-based approach to magnification dependent and independent classification of breast cancer in histopathological images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ferkous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.bspc.2020.102192</idno>
		<ptr target="https://doi.org/10.1016/j.bspc.2020.102192" />
	</analytic>
	<monogr>
		<title level="m">BACH ICIAR 2018 grand challenge on breast cancer histology images</title>
				<imprint>
			<date type="published" when="2020">June 19, 2024. 2020</date>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page">102192</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Breast cancer image dataset</title>
		<author>
			<persName><surname>Breakhis</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/datasets/ambarish/breakhis" />
		<imprint>
			<date type="published" when="2024-06-01">June 1, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Breast cancer statistics worldwide</title>
		<ptr target="https://www.bcrf.org/breast-cancer-statistics-and-resources/" />
	</analytic>
	<monogr>
		<title level="j">Breast Cancer Research Foundation</title>
		<imprint>
			<date type="published" when="2024-06-22">June 22, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Support vector machine-based ultrawideband breast cancer detection system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>O'halloran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glavin</surname></persName>
		</author>
		<idno type="DOI">10.1163/156939311797454015</idno>
		<ptr target="https://www.tandfonline.com/doi/abs/10.1163/156939311797454015" />
	</analytic>
	<monogr>
		<title level="j">Journal of Electromagnetic Waves and Applications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1807" to="1816" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><surname>Cbis-Ddsm</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/datasets/awsaf49/cbis-ddsm-breast-cancer-image-dataset" />
		<title level="m">Breast cancer image dataset</title>
				<imprint>
			<date type="published" when="2024-06-19">June 19, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SMOTE: Synthetic minority over-sampling technique</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
		<idno type="DOI">10.1613/jair.953</idno>
		<ptr target="https://doi.org/10.1613/jair.953" />
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Breast tumor classification in ultrasound images using combined deep and handcrafted features</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Daoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abdel-Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Bdair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Al-Najar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Al-Hawari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alazrai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page">6832</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2009.5206848</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2009.5206848" />
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Transfer learning-based histopathologic image classification for breast cancer detection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Deniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Şengür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kadiroğlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ü</forename><surname>Budak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health Information Science and Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Detection of breast abnormality from thermograms using curvelet transform-based feature extraction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sasikala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saranya</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10916-014-0023-3</idno>
		<ptr target="https://link.springer.com/article/10.1007/s10916-014-0023-3https://doi.org/10.1007/s10916-014-0023-3" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Systems</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Histopathological image analysis: A review</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Gurcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Boucheron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Can</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Rajpoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yener</surname></persName>
		</author>
		<idno type="DOI">10.1109/RBME.2009.2034865</idno>
		<ptr target="https://doi.org/10.1109/RBME.2009.2034865" />
	</analytic>
	<monogr>
		<title level="j">IEEE Reviews in Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="147" to="171" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Borderline-SMOTE: A new over-sampling method in imbalanced data sets learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Mao</surname></persName>
		</author>
		<idno type="DOI">10.1007/11538059_91</idno>
		<ptr target="https://doi.org/10.1007/11538059_91" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Computing</title>
				<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005-08">2005. August</date>
			<biblScope unit="page" from="878" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Breast cancer multi-classification from histopathological images with structured deep learning model</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-017-04075-z</idno>
		<ptr target="https://doi.org/10.1038/s41598-017-04075-z" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4172</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.90</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2016.90" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A comparison of SVM kernel functions for breast cancer detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Wajid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elzaart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berbar</surname></persName>
		</author>
		<idno type="DOI">10.1109/CGIV.2011.31</idno>
		<ptr target="https://doi.org/10.1109/CGIV.2011.31" />
	</analytic>
	<monogr>
		<title level="m">2011 Eighth International Conference on Computer Graphics, Imaging and Visualization</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="145" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Cancer today -Data visualization tools</title>
		<ptr target="https://gco.iarc.fr/today/en/dataviz/pie?mode=population&amp;group_populations=0&amp;cancers=20&amp;types=0" />
		<imprint>
			<date type="published" when="2024-06-08">June 8, 2024</date>
			<publisher>International Agency for Research on Cancer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Breast cancer histopathological image classification using convolutional neural networks with small SE-ResNet module</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">e0214587</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Breast cancer imaging: A perspective for the next decade</title>
		<author>
			<persName><forename type="first">A</forename><surname>Karellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vedantham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Physics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4878" to="4897" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Comparison of the performance of screening mammography, physical examination, and breast US and evaluation of factors that influence them: An analysis of 27,825 patient evaluations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Kolb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lichy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Newhouse</surname></persName>
		</author>
		<idno type="DOI">10.1148/radiol.2251011667</idno>
		<ptr target="https://doi.org/10.1148/radiol.2251011667" />
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">225</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="165" to="175" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hierarchical ResNeXt models for breast cancer histology image classification</title>
		<author>
			<persName><forename type="first">I</forename><surname>Koné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boulmane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Analysis and Recognition: 15th International Conference, ICIAR 2018, Póvoa de Varzim</title>
				<meeting><address><addrLine>Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-27">2018. June 27-29. 2018</date>
			<biblScope unit="page" from="796" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multiclass classification of breast cancer in whole-slide images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kwok</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-93000-8_106</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-93000-8_106" />
	</analytic>
	<monogr>
		<title level="m">Image Analysis and Recognition: 15th International Conference</title>
				<meeting><address><addrLine>Póvoa de Varzim, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-06-27">2018. 2018. June 27-29. 2018</date>
			<biblScope unit="page" from="931" to="940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Robust breast cancer detection in mammography and digital breast tomosynthesis using an annotation-efficient deep learning approach</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lotter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Haslam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Grisot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Onieva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Boxerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Vijayaraghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Sorensen</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-020-01174-9</idno>
		<ptr target="https://doi.org/10.1038/s41591-020-01174-9" />
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="244" to="249" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Mooney</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images/code" />
		<title level="m">Breast histopathology images</title>
				<imprint>
			<date type="published" when="2024-08-02">August 2, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">BHCNet: Neural network-based brain hemorrhage classification using head CT scan</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Mushtaq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shahroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Aseere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Majeed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shehzad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Samad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="113901" to="113916" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Automated classification of breast cancer histology images using deep learning based convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Nawaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Sewissy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H A</forename><surname>Soliman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Science and Network Security</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="152" to="160" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-class breast cancer classification using deep learning convolutional neural network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nawaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Sewissy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H A</forename><surname>Soliman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Computer Science and Applications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="316" to="332" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Integrative computer-aided diagnostic with breast thermogram</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Kee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mechanics in Medicine and Biology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Breast cancer image dataset</title>
		<author>
			<persName><surname>Patchcamelyon</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/datasets/andrewmvd/metastatic-tissue-classification-patchcamelyon" />
		<imprint>
			<date type="published" when="2024-08-16">August 16. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Benign and malignant breast cancer segmentation using optimized region growing technique</title>
		<author>
			<persName><forename type="first">S</forename><surname>Punitha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Amuthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Joseph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Computing and Informatics Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="348" to="358" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Breast cancer detection using deep convolutional neural networks and support vector machines</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Ragab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj.6201</idno>
		<ptr target="https://doi.org/10.7717/peerj.6201" />
	</analytic>
	<monogr>
		<title level="j">PeerJ</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Early detection of breast cancer using SVM classifier technique</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">I A</forename><surname>Rejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Selvi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0912.2314</idno>
		<ptr target="https://arxiv.org/abs/0912.2314" />
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bio-imaging based machine learning algorithm for breast cancer detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Safdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rizwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Gadekallu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K I</forename><surname>Rahmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jawad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhatia</surname></persName>
		</author>
		<idno type="DOI">10.3390/diagnostics12051134</idno>
		<ptr target="https://doi.org/10.3390/diagnostics12051134" />
	</analytic>
	<monogr>
		<title level="j">Diagnostics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">1134</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cancer detection using machine learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bombay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalathil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Phadtare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Research Journal of Engineering and Technology (IRJET)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">09</biblScope>
			<biblScope unit="page" from="2759" to="2762" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Breast cancer classification using deep learning approaches and histopathology image: A comparison study</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shahidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Daud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Abas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maarop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="187531" to="187552" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The spectrum of genetic mutations in breast cancer</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ghori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Naeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fazil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Giri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sathian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mainali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Al Tamimi</surname></persName>
		</author>
		<idno type="DOI">10.7314/APJCP.2015.16.6.2177</idno>
		<ptr target="https://doi.org/10.7314/APJCP.2015.16.6.2177" />
	</analytic>
	<monogr>
		<title level="j">Asian Pacific Journal of Cancer Prevention</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2177" to="2185" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Role of image thermography in early breast cancer detection: Past, present, and future</title>
		<author>
			<persName><forename type="first">D</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cmpb.2019.105074</idno>
		<ptr target="https://doi.org/10.1016/j.cmpb.2019.105074" />
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page">105074</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep learning framework for multi-class breast cancer histology image classification</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Vang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-93000-8_104</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-93000-8_104" />
	</analytic>
	<monogr>
		<title level="m">Image Analysis and Recognition: 15th International Conference, ICIAR 2018, Póvoa de Varzim</title>
				<meeting><address><addrLine>Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-06-27">2018. June 27-29. 2018</date>
			<biblScope unit="page" from="914" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Classification of breast cancer histology images using transfer learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vesal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maier</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-93000-8_91</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-93000-8_91" />
	</analytic>
	<monogr>
		<title level="m">Image Analysis and Recognition: 15th International Conference, ICIAR 2018, Póvoa de Varzim</title>
				<meeting><address><addrLine>Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-06-27">2018. June 27-29. 2018</date>
			<biblScope unit="page" from="812" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Global cancer burden growing, amidst mounting need for services</title>
		<ptr target="https://www.who.int/news/item/01-02-2024-global-cancer-burden-growing--amidst-mounting-need-for-services" />
	</analytic>
	<monogr>
		<title level="j">World Health Organization</title>
		<imprint>
			<date type="published" when="2024-02-01">2024. February 1. June 22, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep learning based analysis of histopathological images of breast cancer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luttrell</surname></persName>
		</author>
		<author>
			<persName><surname>Iv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.3389/fgene.2019.00080</idno>
		<ptr target="https://doi.org/10.3389/fgene.2019.00080" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Genetics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.634</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2017.634" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A hybrid convolutional and recurrent deep neural network for breast cancer pathological image classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/BIBM.2018.8621429</idno>
		<ptr target="https://doi.org/10.1109/BIBM.2018.8621429" />
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="957" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Breast cancer histopathological image classification using a hybrid deep neural network</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="52" to="60" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Parallel structure deep neural network using CNN and RNN with an attention mechanism for breast cancer histology image classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.3390/cancers11121901</idno>
		<ptr target="https://doi.org/10.3390/cancers11121901" />
	</analytic>
	<monogr>
		<title level="j">Cancers (Basel)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1901">2019. 1901</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Recursive SVM biomarker selection for early detection of breast cancer in peripheral blood</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<idno type="DOI">10.1186/1755-8794-6-S1-S4</idno>
		<ptr target="https://doi.org/10.1186/1755-8794-6-S1-S4" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Genomics</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">S4</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Suppl 1</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Breast cancer multi-classification from histopathological images with structured deep learning model</title>
		<author>
			<persName><forename type="first">Zhongyi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benzheng</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanjie</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yilong</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kejian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4172</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
