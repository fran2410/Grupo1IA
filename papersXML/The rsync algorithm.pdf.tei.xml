<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The rsync algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown">
					<licence/>
				</availability>
				<date type="published" when="1996-06-18">June 18, 1996</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Tridgell</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation">Department o f Computer Science Australian National University Canberra , ACT 0200 , Australia</note>
								<orgName type="department">Department o f Computer Science</orgName>
								<orgName type="institution">Australian National University Canberra</orgName>
								<address>
									<postCode>0200</postCode>
									<region>ACT</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Mackerras</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation">Department o f Computer Science Australian National University Canberra , ACT 0200 , Australia</note>
								<orgName type="department">Department o f Computer Science</orgName>
								<orgName type="institution">Australian National University Canberra</orgName>
								<address>
									<postCode>0200</postCode>
									<region>ACT</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The rsync algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="1996-06-18">June 18, 1996</date>
						</imprint>
					</monogr>
					<idno type="MD5">C897794E87A41177B0FF0E9B9A98B7AA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-06T18:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report presents an algorithm for updating a le on one machine to be identical to a le on another machine. We assume that the two machines are connected by a low-bandwidth high-latency bi-directional communications link. The algorithm identi es parts of the source le which are identical to some part of the destination le, and only sends those parts which cannot be matched in this way. E ectively, the algorithm computes a set of di erences without having both les on the same machine. The algorithm works best when the les are similar, but will also function correctly and reasonably e ciently when the les are quite di erent.</p><p>1 The problem Imagine you have t wo les, A and B, and you wish to update B to be the same as A. The obvious method is to copy A onto B. Now imagine that the two les are on machines connected by a slow communications link, for example a dial up IP link. If A is large, copying A onto B will be slow. To make it faster you could compress A before sending it, but that will usually only gain a factor of 2 to 4. Now assume that A and B are quite similar, perhaps both derived from the same original le. To really speed things up you would need to take advantage of this similarity. A common method is to send just the di erences between A and B down the link and then use this list of di erences to reconstruct the le.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The problem is that the normal methods for creating a set of di erences between two les rely on being able to read both les. Thus they require that both les are available beforehand at one end of the link. If they are not both available on the same machine, these algorithms cannot be used once you had copied the le over, you wouldn't need the di erences. This is the problem that rsync addresses.</p><p>The rsync algorithm e ciently computes which parts of a source le match some part of an existing destination le. These parts need not be sent across the link; all that is needed is a reference to the part of the destination le. Only parts of the source le which are not matched in this way need to be sent verbatim. The receiver can then construct a copy o f the source le using the references to parts of the existing destination le and the verbatim material.</p><p>Trivially, the data sent to the receiver can be compressed using any of a range of common compression algorithms, for further speed improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The rsync algorithm</head><p>Suppose we have two general purpose computers and . Computer has access to a le A and has access to le B, where A and B are similar".</p><p>There is a slow communications link between and .</p><p>The rsync algorithm consists of the following steps:</p><p>1. splits the le B into a series of non-overlapping xed-sized blocks of size S b ytes<ref type="foot" target="#foot_0">foot_0</ref> . The last block m a y be shorter than S bytes.</p><p>2. For each of these blocks calculates two checksums: a weak rolling" 32-bit checksum described below and a strong 128-bit MD4 checksum. 3. sends these checksums to .</p><p>4. searches through A to nd all blocks of length S bytes at any o set, not just multiples of S that have the same weak and strong checksum as one of the blocks of B. This can be done in a single pass very quickly using a special property of the rolling checksum described below.</p><p>5. sends a sequence of instructions for constructing a copy o f A. Each instruction is either a reference to a block of B, or literal data. Literal data is sent only for those sections of A which did not match a n y o f t h e blocks of B. The end result is that gets a copy o f A, but only the pieces of A that are not found in B plus a small amount of data for checksums and block indexes are sent o ver the link. The algorithm also only requires one round trip, which minimises the impact of the link latency.</p><p>The most important details of the algorithm are the rolling checksum and the associated multi-alternate search mechanism which allows the all-o sets checksum search to proceed very quickly. These will be discussed in greater detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Rolling checksum</head><p>The weak rolling checksum used in the rsync algorithm needs to have the property that it is very cheap to calculate the checksum of a bu er X 2 ::X n+1 given the checksum of bu er X 1 ::X n and the values of the bytes X 1 and X n+1 .</p><p>The weak checksum algorithm we used in our implementation was inspired by Mark Adler's adler-32 checksum. Our checksum is de ned by ak</p><formula xml:id="formula_0">;l = l X i=k X i m o d M bk;l = l X i=k l , i + 1 X i m o d M</formula><p>sk;l = ak;l + 2 16 bk;l where sk;l i s t h e rolling checksum of the bytes X k : : : X l . For simplicity and speed, we use M = 2 16 .</p><p>The important property of this checksum is that successive values can be computed very e ciently using the recurrence relations ak + 1 ; l + 1 = ak;l , X k + X l+1 m o d M bk + 1 ; l + 1 = bk;l , l , k + 1 X k + ak + 1 ; l + 1 mod M Thus the checksum can be calculated for blocks of length S at all possible o sets within a le in a rolling" fashion, with very little computation at each point.</p><p>Despite its simplicity, this checksum was found to be quite adequate as a rst level check for a match o f t wo le blocks. We h a ve found in practice that the probability of this checksum matching when the blocks are not equal is quite low. This is important because the much more expensive strong checksum must be calculated for each block where the weak checksum matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Checksum searching</head><p>Once has received the list of checksums of the blocks of B, i t m ust search A for any blocks at any o set that match the checksum of some block o f B. The basic strategy is to compute the 32-bit rolling checksum for a block of length S starting at each b yte of A in turn, and for each c hecksum, search the list for a match. To do this our implementation uses a simple 3 level searching scheme.</p><p>The rst level uses a 16-bit hash of the 32-bit rolling checksum and a 2 16 entry hash table. The list of checksum values i.e., the checksums from the blocks of B is sorted according to the 16-bit hash of the 32-bit rolling checksum. Each entry in the hash table points to the rst element of the list for that hash value, or contains a null value if no element of the list has that hash value.</p><p>At each o set in the le the 32-bit rolling checksum and its 16-bit hash are calculated. If the hash table entry for that hash value is not a null value, the second level check i s i n voked.</p><p>The second level check i n volves scanning the sorted checksum list starting with the entry pointed to by the hash table entry, looking for an entry whose 32-bit rolling checksum matches the current v alue. The scan terminates when it reaches an entry whose 16-bit hash di ers. If this search nds a match, the third level check i s i n voked.</p><p>The third level check i n volves calculating the strong checksum for the current o set in the le and comparing it with the strong checksum value in the current list entry. If the two strong checksums match, we assume that we h a ve found a block o f A which matches a block o f B. In fact the blocks could be di erent, but the probability o f this is microscopic, and in practice this is a reasonable assumption.</p><p>When a match is found, sends the data in A between the current le o set and the end of the previous match, followed by the index of the block i n B that matched. This data is sent immediately a match is found, which allows us to overlap the communication with further computation.</p><p>If no match is found at a given o set in the le, the rolling checksum is updated to the next o set and the search proceeds. If a match is found, the search is restarted at the end of the matched block. This strategy saves a considerable amount o f computation for the common case where the two les are nearly identical. In addition, it would be a simple matter to encode the block indexes as runs, for the common case where a portion of A matches a series of blocks of B in order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Pipelining</head><p>The above sections describe the process for constructing a copy of one le on a remote system. If we h a ve a several les to copy, w e can gain a considerable latency advantage by pipelining the process.</p><p>This involves initiating two independent processes. One of the processes generates and sends the checksums to while the other receives the di erence information from and reconstructs the les.</p><p>If the communications link is bu ered then these two processes can proceed independently and the link should be kept fully utilised in both directions for most of the time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>To test the algorithm, tar les were created of the Linux kernel sources for two versions of the kernel. The two k ernel versions were 1.99.10 and 2.0.0. These tar les are approximately 24MB in size and are separated by 5 released patch levels.</p><p>Out of the 2441 les in the 1.99.10 release, 291 les had changed in the 2.0.0 release, 19 les had been removed and 25 les had been added.</p><p>A di " of the two tar les using the standard GNU di utility produced over 32 thousand lines of output totalling 2.1 MB.</p><p>The following table shows the results for rsync between the two les with a varying block size.</p><p><ref type="foot" target="#foot_1">foot_1</ref> block matches tag false data written read size hits alarms 300 64247 3817434 948 5312200 5629158 1632284 500 46989 620013 64 1091900 1283906 979384 700 33255 571970 22 1307800 1444346 699564 900 25686 525058 24 1469500 1575438 544124 1100 20848 496844 21 1654500 1740838 445204</p><p>In each case, the CPU time taken was less than the time it takes to run di " on the two les. <ref type="bibr">3</ref> The columns in the table are as follows:</p><p>block size The size in bytes of the checksummed blocks. matches The number of times a block o f B was found in A. tag hits The number of times the 16 bit hash of the rolling checksum matched a hash of one of the checksums from B.</p><p>false alarms The number of times the 32 bit rolling checksum matched but the strong checksum didn't.</p><p>data The amount of le data transferred verbatim, in bytes. written The total numb e r o f b ytes written by including protocol overheads. This is almost all le data. read The total numb e r o f b ytes read by including protocol overheads. This is almost all checksum information. The results demonstrate that for block sizes above 300 bytes, only a small fraction around 5 of the le was transferred. The amount transferred was also considerably less than the size of the di le that would have been transferred if the di patch method of updating a remote le was used.</p><p>The checksums themselves took up a considerable amount of space, although much less than the size of the data transferred in each case. Each pair of checksums consumes 20 bytes: 4 bytes for the rolling checksum plus 16 bytes for the 128-bit MD4 checksum.</p><p>The number of false alarms was less than 1=1000 of the number of true matches, indicating that the 32 bit rolling checksum is quite good at screening out false matches.</p><p>The number of tag hits indicates that the second level of the checksum search algorithm was invoked about once every 50 characters. This is quite high because the total number of blocks in the le is a large fraction of the size of the tag hash table. For smaller les we w ould expect the tag hit rate to be much closer to the number of matches. For extremely large les, we should probably increase the size of the hash table.</p><p>The next table shows similar results for a much smaller set of les. In this case the les were not packed into a tar le rst. Rather, rsync was invoked with an option to recursively descend the directory tree. The les used were from two source releases of another software package called Samba. The total source code size is 1.7 MB and the di between the two releases is 4155 lines long totalling 120 kB.</p><p>block matches tag false data written read size hits alarms 300 3727 3899 0 129775 153999 83948 500 2158 2325 0 171574 189330 50908 700 1517 1649 0 195024 210144 36828 900 1156 1281 0 222847 236471 29048 1100 921 1049 0 250073 262725 23988</p><p>7 Availability</p><p>An implementation of rsync which provides a convenient i n terface similar to the common UNIX command rcp has been written and is available for download from ftp: samba.anu.edu.au pub rsync.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We h a ve found that values of S between 500 and 1000 are quite good for most purposes</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>All the tests in this section were carried out using rsync version 0.5</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The wall clock time was approximately 2 minutes per run on a 50 MHz SPARC 10 running SunOS, using rsh over loopback for communication. GNU di took about</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>minutes.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>