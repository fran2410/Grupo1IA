<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DEBATE, TRAIN, EVOLVE: Self-Evolution of Language Model Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2025-05-21">21 May 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gaurav</forename><surname>Srivastava</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Virginia Tech</orgName>
								<address>
									<settlement>Blacksburg</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenyu</forename><surname>Bi</surname></persName>
							<email>zhenyub@vt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Virginia Tech</orgName>
								<address>
									<settlement>Blacksburg</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Meng</forename><surname>Lu</surname></persName>
							<email>menglu@vt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Virginia Tech</orgName>
								<address>
									<settlement>Blacksburg</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xuan</forename><surname>Wang</surname></persName>
							<email>xuanw@vt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Virginia Tech</orgName>
								<address>
									<settlement>Blacksburg</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marah</forename><surname>Abdin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sahaj</forename><surname>Agarwal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ahmed</forename><surname>Awadallah</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vidhisha</forename><surname>Balachandran</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Harkirat</forename><surname>Behl</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lingjiao</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gustavo</forename><surname>De Rosa</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Suriya</forename><surname>Gunasekar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Isaac</forename><surname>Cowhey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Carissa</forename><surname>Schoenick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Estornell</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jean-Francois</forename><surname>Ton</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuanshun</forename><surname>Yao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><forename type="middle">2024</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhibin</forename><surname>Gou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhihong</forename><surname>Shao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yujiu</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Edward</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><roleName>Zeyuan</roleName><forename type="first">Phillip</forename><surname>Wallis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jianqiao</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wenyong</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yufei</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qihao</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fei</forename><surname>Mi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Baojun</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Weichao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peiyi</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Runxin</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Junxiao</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiao</forename><surname>Bi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Haowei</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mingchuan</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daya</forename><forename type="middle">2024</forename><surname>Guo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andries</forename><surname>Smit</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Duckworth</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Grinsztajn</surname></persName>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Allen-Zhu</orgName>
								<address>
									<addrLine>Shean Wang</addrLine>
									<settlement>Yuanzhi Li, Lu Wang</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DEBATE, TRAIN, EVOLVE: Self-Evolution of Language Model Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-05-21">21 May 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">BB49CF5EAAD2C26300FA64867CF4A45E</idno>
					<idno type="arXiv">arXiv:2505.15734v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2025-05-26T20:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>2018. Think you have solved question answering? try arc</term>
					<term>the ai2 reasoning challenge. Preprint</term>
					<term>arXiv:1803.05457</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models (LLMs) have improved significantly in their reasoning through extensive training on massive datasets. However, relying solely on additional data for improvement is becoming increasingly impractical, highlighting the need for models to autonomously enhance their reasoning without external supervision. In this paper, we propose DEBATE, TRAIN, EVOLVE (DTE), a novel ground truthfree training framework that uses multi-agent debate traces to evolve a single language model. We also introduce a new prompting strategy REFLECT-CRITIQUE-REFINE, to improve debate quality by explicitly instructing agents to critique and refine their reasoning. Extensive evaluations on five reasoning benchmarks with six open-weight models show that our DTE framework achieve substantial improvements, with an average accuracy gain of 8.92% on the challenging GSM-PLUS dataset. Furthermore, we observe strong cross-domain generalization, with an average accuracy gain of 5.8% on all other benchmarks, suggesting that our method captures general reasoning capabilities.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the past few years, the advancements in large language models (LLMs) have largely depended on training over massive datasets <ref type="bibr">(Abdin et al., 2024</ref><ref type="bibr">(Abdin et al., , 2025))</ref>. However, eventually, we will approach a saturation point where feeding more data into these models may not further improve their reasoning capabilities <ref type="bibr">(Costello et al., 2025)</ref>. This motivates a new research question: How can language models continue to improve without relying on additional external supervision?</p><p>Recent approaches attempt to overcome the data bottleneck by enabling models to generate and learn from synthetic data, which is generated by automatically expanding a small set of seed tasks into large synthetic instruction datasets <ref type="bibr">(Wang et al., 2022;</ref><ref type="bibr">Zeng et al., 2024)</ref>. Other methods <ref type="bibr">(Madaan et al., 2023;</ref><ref type="bibr">Jiang et al., 2023;</ref><ref type="bibr">Gou et al., 2023;</ref><ref type="bibr">Peng et al., 2023;</ref><ref type="bibr">Zelikman et al., 2024;</ref><ref type="bibr">Costello et al., 2025)</ref> refine model-generated outputs through iterative self-feedback or preference optimization. Despite their effectiveness, these selfevolution strategies predominantly rely on judgments from a single model or a teacher-student configuration, often leading to confirmation bias and insufficient reasoning diversity.</p><p>To address these limitations, one promising direction emerged is multi-agent debate (MAD) <ref type="bibr">(Du et al., 2023)</ref>. It involves multiple models independently generating and critically analyzing each other's answers, helping to reveal subtle reasoning errors often overlooked by individual models <ref type="bibr">(Liang et al., 2023;</ref><ref type="bibr">Wang et al., 2024)</ref>. Although MAD shows improved reasoning accuracy, current works predominantly use MAD as an inferencetime technique <ref type="bibr">(Smit et al., 2023)</ref>, requiring multiple models to be run simultaneously for each query. This substantially increases computational overhead and latency <ref type="bibr">(Subramaniam et al., 2025)</ref>, making MAD impractical for large-scale deployments. This motivates our research question: Can we evolve a single model reasoning by fine-tuning on these debate traces?</p><p>Building upon this intuition, we propose DE-BATE, TRAIN, EVOLVE (DTE), a novel framework that combines the strengths of MAD with efficient single-model inference. Specifically, we introduce a ground-truth-free training approach in which a model learns from its own debate traces generated during MAD, thereby evolving autonomously over iterative training cycles. Our framework addresses key challenges of existing methods by extracting high-quality reasoning insights from diverse multiagent interactions, thus avoiding single-model biases and computational inefficiencies.</p><p>First, we conduct a large-scale empirical analysis of MAD using open-source models, where we identify limitations of the original MAD prompting Left-Debate: Several agents debate until they converge on a consensus (green ✓) or expose a wrong path (red ✗). Centre-Train: we remove pure debate elements, keep the high-quality reasoning traces and consensus answer, and use them to fine-tune a single policy with GRPO. Right-Evolve: the evolved agent replaces its earlier self, so future inference require just one forward pass yet they outperform the committee on maths, science, and commonsense benchmarks. approach, particularly in smaller models <ref type="bibr">(Du et al., 2023)</ref>. To address this, we propose a REFLECT-CRITIQUE-REFINE (RCR) prompting strategy, which explicitly forces agents to identify, critique, and correct reasoning errors in both their own and peers' answers. Second, using this prompting strategy, we build our DTE framework (Figure <ref type="figure" target="#fig_0">1</ref>). Finally, we find that models with &lt; 3B parameters suffer accuracy loss <ref type="bibr">(Srivastava et al., 2025)</ref> after second evolution round; our controlled study shows that the problem correlates with large temperatureinduced variance and high KL divergence from the base policy. Lowering the sampling temperature from 0.7 to 0.3 cuts the KL drift by 1/3rd and recovers up to 76% of the lost performance, preventing catastrophic forgetting in smaller models without extra supervision.</p><p>Our experiments show significant gains in reasoning performance across multiple datasets. Specifically, our evolved models show an average accuracy improvement of 8.92% on the challenging GSM-PLUS dataset compared to their original versions. Moreover, our framework achieves notable cross-domain generalization, enhancing model performance across datasets not seen during training. These results confirm that our DEBATE, TRAIN, EVOLVE method successfully distills multiagent debate's insights into efficient single-model inference, bridging the gap between computational efficiency and advanced reasoning capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Multi-Agent Debate Approaches <ref type="bibr">Du et al. (2023)</ref> first showed that letting several large models debate improves accuracy on maths, strategy, and factual QA without any new parameters. Later, <ref type="bibr">Liang et al. (2023)</ref> highlighted the risk of degeneration-of-thought: a single agent quickly converges on one path, whereas a two-debater plus judge setup maintains diversity and outperforms GPT-4 on tricky arithmetic. <ref type="bibr">RECON-CILE (Chen et al., 2023)</ref> mixes agents from different model families, reaches consensus through confidence-weighted votes, and adds up to eleven points on seven reasoning benchmarks. <ref type="bibr">Smit et al. (2023)</ref> shows that MAD beats sampling ensembles only after careful tuning. Finally, works like PREDICT <ref type="bibr">(Park et al., 2024)</ref> apply multi-agent debate to tasks beyond QA, such as hate-speech classification, where agents reason under different guidelines. Recent advances further incorporate explicit reinforcement learning into the debate process. For example, the ACC-Collab framework <ref type="bibr">(Estornell et al., 2024)</ref> utilized an actor-critic approach to explicitly optimize agent collaboration, yielding superior performance on reasoning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Self-Evolution</head><p>in Language Models SELF- <ref type="bibr">INSTRUCT (Wang et al., 2022)</ref> prompts GPT-3 to write 52000 novel instructions plus answers and then fine-tunes on its own output, reducing the gap to InstructGPT by thirty-three points on Super-Natural-Instructions without extra human labels. STAR <ref type="bibr">(Zelikman et al., 2024)</ref> augments a few chain-of-thought exemplars by letting the model explain wrong answers in reverse, doubling CommonsenseQA accuracy for a 350M model. SELF-REFINE <ref type="bibr">(Madaan et al., 2023)</ref> and the broader SELF framework <ref type="bibr">(Lu et al., 2023)</ref> turn one model into writer, critic and re-writer, looping feedback at inference or during fine-tuning to improve on GSM8K by around seven points. Instruction-tuning variants refine the idea: SELF-REFINE <ref type="bibr">INSTRUCTION-TUNING (Ranaldi and Freitas, 2024)</ref> pairs Llama-2 and Mistral students with large teacher rationales and then lets each student prefer its own better reasoning, closing the size gap on commonsense and math tasks. More recently, THINK, PRUNE, TRAIN, IMPROVE <ref type="bibr">(Costello et al., 2025)</ref> shows that careful filtering of self-generated traces can raise Gemma-2B to 58% on GSM8K and push Llama-3-70B beyond GPT-4o. These studies confirm that single-agent loops, with or without ground truth, can expand a model's ability.</p><p>Despite these works, two things remain unexplored: 1) Fully autonomous, ground-truth-free self-evolution; 2) Integration of MAD into model evolution. Our work addresses this by the DEBATE, TRAIN, EVOLVE framework, which combines MAD with self-supervised reinforcement learning (GRPO) to enable models to autonomously evolve their reasoning capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Preliminary Study: Multi-Agent Debate (MAD) First, we conduct a large-scale empirical study on MAD. Our initial objective was to understand how MAD affects performance across different reasoning tasks (eg., math, science), model families, and across scales, and to identify its limitations. Our ultimate goal was to generate high-quality reasoning traces using MAD. Following <ref type="bibr">MAD (Du et al., 2023)</ref> prompting strategy, however, our initial experiments show that the gains from MAD were minimal across reasoning benchmarks.</p><p>Our manual inspection uncovered two primary issues: (i) sycophancy: agents often discarded their correct answer and copied a other agent's wrong but confident solution; (ii) verbosity bias: when two answers disagreed, agents preferred the longer rationale even if it was logically weak (Saito et al., Algorithm 1: MAD using RCR prompting Input: query q, agents A, max rounds T = 5 1 Round 0: each ai ∈ A outputs (y  <ref type="table" target="#tab_33">2023</ref>). For example, on average, a three-agent Qwen-1.5B committee, sycophancy reached 0.28 (28% of the debates have sycophancy rounds). These effects lead to a substantial fraction of [correct → incorrect] transitions during debate.</p><formula xml:id="formula_0">(0) i , r (0) i ) 2 if</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">REFLECT-CRITIQUE-REFINE Prompting</head><p>Inspired by previous works that had iterative self-feedback procedures <ref type="bibr">(Madaan et al., 2023;</ref><ref type="bibr">Gou et al., 2023;</ref><ref type="bibr">Peng et al., 2023)</ref>, we propose REFLECT-CRITIQUE-REFINE (RCR) prompting, which mitigates this problem. Unlike the original MAD prompt that simply asks agents to revise their answer by looking at others, RCR prompting encourages agents to present confident reasoning. 1) Every agent must reflect by stating why its current answer could be wrong; 2) Each agent then critiques exactly two peer rationales, naming a specific flaw or a step it cannot verify; 3) Finally the agent may refine its answer-but only if it supplies at least one new reasoning step.</p><p>Phrases like "identify any errors" reliably trigger negative tokens ("error", "mistake", "step X is wrong") which LLMs have learned during supervised finetuning. By specifying valid next moves (defend/correct/adopt), we implicitly shape the log-probability mass toward useful trajectories, shrinking the space of rambling answers. The single-step explanation requirement forces agents to think before copying, while the fixed quota of peer critiques limits needless verbosity. This prompting helped reduce sycophancy and improved performance.</p><p>Debate protocol Let A = {a 1 , . . . , a N } be a set of agents and q a query. Round 0: each a i produces (y</p><formula xml:id="formula_1">(0) i , r<label>(0)</label></formula><p>i ), an answer and a rationale. If consensus (all answers identical) occurs, the process stops. Otherwise we enter a debate round t ≥ 1 following Algorithm 1: agents receive all previous rationales, execute REFLECT-CRITIQUE-REFINE, and output (y</p><formula xml:id="formula_2">(t) i , r (t) i ).</formula><p>The debate ends when either (i) consensus is reached or (ii) a maximum of N rounds is exhausted, after which the final answer is decided by simple majority vote.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">DEBATE, TRAIN, EVOLVE Framework</head><p>So far we have seen that RCR prompting yields high-quality debate traces and measurable accuracy gains. We now move from learning from these debate traces to train a single language model. This results in DEBATE, TRAIN, EVOLVE (DTE), a closed loop that distills the collective insight of multiple agents into a single, faster model.</p><p>Framework overview Let π θ 0 be a frozen base policy with parameters θ 0 . At iteration k we run Algorithm 1 on a batch of queries Q k , producing a set of debate traces D k = {(x, y ⋆ , R)} where x is the original query, y ⋆ the consensus answer and R a compressed rationale extracted from the highest-scoring agent. Extraction step keeps any explanation steps that appear in at least two agents or that introduce a symbolic manipulation absent from the previous round.</p><p>We then fine-tune a student policy π θ k on D k with Group Relative Policy Optimization <ref type="bibr">(Shao et al., 2024)</ref> and then place π θ k back into the agent pool, replacing its earlier version. The loop repeats until the mean validation reward stagnates for two iterations or a maximum of five cycles is reached. Algorithm 2 gives the exact procedure.</p><p>Reward shaping and GRPO For a query x and a student output y we define the shaped reward</p><formula xml:id="formula_3">r(x, y) = w vote [y = y ⋆ ] + w fmt isFmt(y) + w brev exp(−|y|/τ ),</formula><p>where [ • ] is the indicator function, isFmt checks the &lt;reasoning&gt; &lt;answer&gt; XML template, and |y| is the token length. Weights are set to (w vote , w fmt , w brev ) = (2, 0.5, 0.5) and τ = 120.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GRPO maximises the clipped surrogate</head><p>Algorithm 2: DEBATE, TRAIN, EVOLVE </p><formula xml:id="formula_4">Input: base policy π θ 0 , agent set A0 = {π θ 0 } ∪ B, queries Q, max iterations K 1 for k = 1 to K do 2 sample batch Q k ⊂ Q 3 D k ← {} 4 foreach x ∈ Q k do 5 run Algorithm 1 with agents A k−1 on x 6 store (x, y ⋆ , R) in D k 7 end 8 update θ k ← θ k−1 by maximising LGRPO(θ; D k ) 9 A k ← A k−1 \ {π θ k−1 } ∪ {π θ k } 10 if</formula><formula xml:id="formula_5">L GRPO (θ) = E x∼D k , y∼π θ min ρ r, clip(ρ, 1 − ϵ, 1 + ϵ) r − β KL π θ ∥ π θ 0 , where ρ = π θ (y | x)/π θ k−1 (y | x), ϵ = 0.</formula><p>2, and β = 0.02. The first term is identical to PPO but uses the debate-derived reward; the second anchors the student to the base policy, a key factor for avoiding catastrophic forgetting <ref type="bibr">(Luo et al., 2025;</ref><ref type="bibr">Kotha et al., 2024)</ref>. Gradients are estimated with the standard REINFORCE algorithm and a value network baseline. Baselines and models. We conduct of RCR prompting study on ten open-weight models-Qwen (0.5-32B), Llama-3/8B, Mistral-7B, Phi-mini-and two proprietary models, GPT-4o and GPT-4o-mini. We study our DTE framework with 6 models (Qwen 1.5B-14B, Llama-3B and Llama-8B). Baselines are: (i) the single original model; (ii) vanilla MAD with the original MAD prompt <ref type="bibr">(Du et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Parameter settings. During debate we sample each agent once per query at temperature T = 1.0 (exploratory) or 0.0 (deterministic); mixed-teams  Evaluation metrics. Task performance is exact match for GSM-style datasets and accuracy for MC-QA. For RCR evaluation, we also track Sycophancy-Rate: the fraction of agents switching to an incorrect peer answer without adding new reasoning; [incorrect → correct] instances during MAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Main Results</head><p>Our main results are organized into three main parts:</p><p>(1) First, we evaluate the effectiveness of DEBATE-TRAIN-EVOLVE (DTE) framework, (2) Next, we test its generalization across different reasoning tasks by transferring evolved models to new datasets, and (3) Finally, we analyze the extent of model self-evolution through iterative rounds.</p><p>1) OVERALL DTE PERFORMANCE. Evolved model using DTE shows an average gain of 8.92% ACCURACY on GSM-PLUS compared to its vanilla performance. 2) CROSS-DOMAIN GENERALIZATION. Our results suggests that DTE improves reasoning that travels beyond the source data, with larger models showing the most stable improvements.</p><p>Table <ref type="table">2</ref> reports how well the evolved models generalize on other datasets. We test two scenarios: evolve using (i) GSM8K; (ii) GSM-Plus and test on four unseen datasets. When trained on GSM8K, every model gains on GSM-Plus (average +5.8 pts) and on ARC-Challenge (+2.5 pts on average). ARC-Easy also sees small but consistent gains except for the 1.5B model, which drops 1.6 pts.</p><p>CommonsenseQA improves for 5/6 models, indicating that the reward shaped from mathematical traces still helps improve on commonsense reasoning. Negative deltas are confined to the smallest model (Qwen-1.5B) and to a lesser degree Qwen-3B, suggesting that small models struggles to reconcile new skills with prior knowledge. In contrast, models ≥ 7B never lose more than 0.2 pts on any transfer task. Training on GSM-Plus and testing on GSM8K yields similar behaviour: large gains on the GSM8K (+3.7 pts on average) and moderate gains on others. The symmetry suggests that DTE learns general reasoning heuristics (e.g. numeric decomposition, unit tracking) rather than memorising dataset-specific patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Fine-tuned on GSM8K Fine-tuned on GSM-Plus</p><formula xml:id="formula_6">GSM-Plus ARC-Easy ARC-Challenge CommonsenseQA GSM8K ARC-Easy ARC-Challenge CommonsenseQA (∆) (∆) (∆) (∆) (∆) (∆) (∆) (∆)</formula><p>Qwen-2.  <ref type="bibr">et al., 2023)</ref>. Figure <ref type="figure">3</ref> compares single-model inference, the original debate prompt (MAD@3), and our REFLECT-CRITIQUE-REFINE (RCR-MAD@3) prompt. Across eight diverse models the RCR prompting raises three-agent accuracy by an average of +1.9 pts on GSM8K, +3.7 pts on GSM-Plus, and +0.7 pts on ARC-Challenge. The gain scales with task difficulty: GSM-Plus, which contains harder adversarial questions, benefits the most (up to +7.9 pts for Qwen-1.5B and +6.1 pts for Qwen-7B). On ARC-Challenge improvements are smaller but still positive for 6/8 models. RCR prompting also significantly reduces sycophancy.</p><p>It halves the mean sycophancy rate (from 0.28 to 0.13 on GSM-Plus) and narrows the verbosity gap by 43 %, indicating that agents now switch answers only when they can articulate a new reasoning step. These observations confirm that RCR is a necessary pre-step for producing high-quality traces later utilized by the DTE training loop.</p><p>2) HOW MANY AGENTS ARE ENOUGH? Results shows that three agents MAD captures 85-95 % of the maximum gains. Figure <ref type="figure">4</ref> sweeps the agents size from 1 − 7 and reports trends on four benchmark. We observe three clear patterns here: 1) Beyond 3-agent the curve plateaus and even oscillates, suggesting the marginal information added by the 4th or 5th agent. 2) Small models benefit most from extra agents. Already strong single-agent (Qwen-14B) adds minimal improvement upon scaling up after three. 3) Harder tasks need (slightly) more agents. On GSM-Plus the optimum often shifts to four or five agents: Qwen-7B reaches its peak accuracy (76.0%) at 7 agents, 1.04 pts above the three-agent setting. ARC-Easy, a much easier dataset, saturates at 2 agents for every model; extra debaters add noise rather than insight. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GSM8K</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GSM-PLUS ARC-Challenge</head><p>Figure <ref type="figure">3</ref>: Results (%) on: GSM8K, GSM-PLUS, and ARC-Challenge datasets. Performance is compared across three evaluation settings: single model inference, the Original Multi-Agent Debate (MAD@3) prompt, and our proposed RCR (RCR-MAD (Ours)@3) prompting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARC-Challenge</head><p>Qwen-2.5-1.5B Qwen-2.5-3B Qwen-2.5-7B Qwen-2.5-14B</p><p>Figure <ref type="figure">4</ref>: Scaling up agents Accuracy of four Qwen model sizes as the number of agents grows from 1-7.</p><p>3) DOES AGENT DIVERSITY MATTER? We observe two consistent trends here: First, when the individual agents have comparable standalone accuracy, cross-family mixtures beat homogeneous agents team, supporting the idea that architectural diversity yields complementary reasoning paths.</p><p>Second, when the pool mixes a strong and a weaker model, the debate result gravitates toward the stronger member-adding the weaker agent neither helps nor seriously harms, suggesting that diversity only helps when all agents can contribute novel insights. Complete results for every dataset and roster is available in Appendix B.   stabilises training: at T = 0.4 Round-2 accuracy is within 0.9 pts of Round 1 on GSM-Plus and almost fully recovers on GSM8K; a deterministic schedule (T = 0.0) even adds +3.3 pts on GSM8K but plateaus on GSM-Plus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) WHY GRPO</head><p>The mechanism is visible in the KL divergence between successive students. At T = 1.0 we measure KL evo =0.37 for Qwen-1.5B, whereas T = 0.4 cuts this to 0.19 and T = 0.0 to 0.11, matching the reduction in forgetting. We therefore adopt a linear decay from 0.7 in Round 1 to 0.3 in later rounds for all models up to 3B parameters; larger models did not require temperature adjustment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we introduced the DEBATE, TRAIN, EVOLVE (DTE) framework, a novel approach enabling language models to autonomously enhance their reasoning capabilities by leveraging multiagent debate traces. Our REFLECT-CRITIQUE-REFINE prompting strategy significantly improved debate quality, reducing sycophancy and reasoning errors. Experiments demonstrated substantial accuracy gains, notably an average improvement of 8.92% accuracy on the challenging GSM-PLUS dataset. Additionally, we showed strong cross-domain generalization, confirming that our approach captures general reasoning skills rather than dataset-specific patterns. Importantly, DTE effectively combines the benefits of multi-agent debate with the computational efficiency of singlemodel inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>Despite its effectiveness, our approach has certain limitations. Firstly, iterative fine-tuning within the DTE framework can cause catastrophic forgetting, particularly evident in smaller language models (&lt;3B parameters), leading to potential model collapse. Although we explored several mitigation strategies, completely eliminating this issue remains challenging. Secondly, our framework assumes the availability of high-quality initial debate traces; thus, its efficacy may degrade if debates are of poor quality or if initial agent performance is weak. Third, our study primarily focused on structured reasoning tasks like mathematical and commonsense reasoning. The applicability and effectiveness of DTE on less structured or more openended tasks, such as natural language generation or dialogue systems, require further investigation. Lastly, although computationally efficient compared to traditional MAD setups, DTE still incurs higher training costs than standard single-model fine-tuning. Future work should aim to optimize the framework further, enhancing its practicality and accessibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>This study explore the self-evolution of language models using publicly available benchmarks and datasets such as GSM8K, ARC, and Common-senseQA. All data used in our experiments are non-sensitive and freely accessible, ensuring compliance with ethical research standards and reproducibility. Our method involves fine-tuning on model-generated content, without introducing or relying on any human-annotated private data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Datasets Details</head><p>We evaluate our Multi-Agent Debate (MAD) approach on five diverse reasoning benchmarks. In the following, we briefly describe each dataset along with their splits. In this paper, we use the test split to evaluate all Small Language Models (SLMs).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implementation Details</head><p>Training For model fine-tuning, we used GRPO to enhance Language Models on the targeted reasoning tasks. Our training pipeline utilized the Unsloth<ref type="foot" target="#foot_0">1</ref> and TRL<ref type="foot" target="#foot_1">2</ref> libraries for efficient parameter-efficient fine-tuning with <ref type="bibr">QLoRA (Dettmers et al., 2023)</ref>. Models were trained with a LoRA (Hu et al., 2021) rank of 128 and target modules including query, key, value, output, gate, up, and down projections. We used 8-bit Adam optimizer with beta parameters of (0.9, 0.99) and a weight decay of 0.1. The learning rate was set to 5e-6 with a cosine decay schedule and 10% warmup ratio. Training proceeded for 10,000 steps with a per-device batch size of 8. To improve output formatting, we implemented a multi-component reward function consisting of: (1) an answer correctness reward, (2) format adherence rewards for XML tags structure, (3) a numeric response reward, and (4) a tag-counting reward to incentivize proper tag usage. Each model was instructed to output responses in a structured XML format with separate &lt;reasoning&gt; and &lt;answer&gt; tags to facilitate consistent answer extraction and evaluation. To manage memory constraints on high-end GPUs, we set the maximum sequence length to 2048 tokens with a 512-token maximum for prompts and 1536 tokens for model completions.</p><p>Inference We conducted all model inferences using NVIDIA H100-80GB, A100-80GB, L40-48GB, and A40-48GB GPUs. For efficient inference, we used the vLLM library (Kwon et al., 2023)<ref type="foot" target="#foot_2">3</ref> , dynamically allocating the required number of GPUs to load each model. Multi-GPU utilization was enabled using Hugging Face Accelerate<ref type="foot" target="#foot_3">4</ref> for model sharding and speed optimization.</p><p>C REFLECT-CRITIQUE-REFINE Prompt Design • If you believe your previous answer is correct, explain why and defend it.</p><p>• If you believe you made an error, explain the error and provide a corrected solution.</p><p>• If you believe another agent's answer is correct, explain why you agree with it.</p><p>Your final answer must be in the format {answer} at the end. • If you believe your previous answer is correct, explain the scientific principles supporting your answer.</p><p>• If you believe you made an error, explain the scientific misconception and provide a corrected solution.</p><p>• If you believe another agent's answer is correct, explain why their scientific reasoning is sound.</p><p>Your final answer must be in the format {answer} at the end. • If you believe your previous answer is correct, explain the logical reasoning and real-world knowledge supporting it.</p><p>• If you believe you made an error, explain the flawed assumption or inconsistency and provide a corrected solution.</p><p>• If you believe another agent's answer is correct, explain why their reasoning aligns with commonsense knowledge.</p><p>Your final answer must be in the format {answer} at the end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Self-Evolution Results</head><p>In this section, we present a comprehensive analysis of our DEBATE, TRAIN, EVOLVE framework across multiple experimental settings. We first examine the impact of various GRPO configurations, followed by analyses of multi-round training effects, and finally cross-domain generalization results. Our experiments utilize a diverse set of models ranging from 1.5B to 14B parameters and evaluate performance on challenging reasoning benchmarks including GSM8K, GSM-Plus, ARC-Challenge, ARC-Easy, and CommonsenseQA.</p><p>D.1 Complete GRPO results (all steps, temperature)</p><p>We begin by investigating how different GRPO hyperparameters affect model performance. Tables <ref type="table" target="#tab_17">6, 7</ref>, and 8 present results across three datasets (GSM8K, GSM-Plus, and ARC-Challenge) for six different model configurations, varying training steps (2000, 5000, and 10000) and sampling temperatures (0.8 and 0.2).</p><p>Several key patterns emerge from these results. First, we observe that larger models (7B+) generally maintain or improve their performance through GRPO fine-tuning, while smaller models (particularly Llama-3B) occasionally exhibit catastrophic forgetting at higher step counts. Second, lower temperature (0.2) typically yields more stable optimization trajectories for most model configurations, especially at higher step counts. This supports our hypothesis that constraining policy drift during fine-tuning is crucial for successful reasoning evolution.</p><p>Notably, the Qwen-2.5-3B model demonstrates remarkable stability across configurations, with consistent performance gains on GSM-Plus (from 61.75% to 69.50%) and robust maintenance of GSM8K performance. In contrast, the Llama-3B model shows significant performance degradation at higher step counts with 0.8 temperature, dropping to near-random performance (2.73%) after 10000 steps on GSM8K, while maintaining better stability at 0.2 temperature.</p><p>For ARC-Challenge, we observe that all models benefit from MAD evolution, with particularly strong gains for Qwen-2.5-7B (from 87.22% to 91.64%) and Llama-8B (from 77.65% to 85.07%). These results suggest that our framework effectively generalizes across both mathematical reasoning and scientific question-answering domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Complete Round 2 MAD Results</head><p>After the first round of GRPO fine-tuning, we evaluated the performance of models in a multi-agent debate setting to assess how evolution affects collaborative reasoning. Table <ref type="table" target="#tab_20">10</ref> presents these results across different debate configurations: exponential temperature scaling (Exp), default settings (Default), temperature-4 settings (temp4), and deterministic setting (Det).</p><p>The MAD Round 2 results demonstrate that evolved models generally maintain their collaborative reasoning capabilities after GRPO fine-tuning. For most models, MAD performance after evolution either improves or remains comparable to the original MAD results. The Qwen-2.5-7B model, for instance, achieves 77.75% accuracy on GSM-Plus under the temp4 configuration, which represents a 3.58% improvement over its original MAD performance.</p><p>Interestingly, we observe that different debate configurations yield varying results across model sizes. Smaller models like Qwen-2.5-1.5B show significant performance variation across configurations, with deterministic settings yielding the best results (69.07% on GSM8K and 56.62% on GSM-Plus). In contrast, larger models like Qwen-2.5-7B demonstrate more consistent performance across configurations.</p><p>The exponential temperature scaling configuration generally underperforms other settings, particularly for smaller models. This suggests that controlled diversity in debate is beneficial, but excessive exploration may hinder collaborative reasoning effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 GRPO round 2 results</head><p>To investigate the effects of iterative evolution, we conducted a second round of GRPO fine-tuning on models that had already undergone one round of evolution. Table <ref type="table" target="#tab_19">9</ref> presents these results for four model configurations across two datasets (GSM8K and GSM-Plus).</p><p>The second round of GRPO training reveals interesting dynamics in model evolution. For the Qwen family of models, we observe continued performance improvements or stability across most configurations. The Qwen-2.5-7B model, for instance, achieves further gains on GSM-Plus, reaching 73.75% accuracy (a 5.13% improvement over its first round GRPO performance).</p><p>However, the Llama-3B model exhibits significant performance degradation in certain configurations, particularly at higher step counts with 0.8 temperature (dropping to 35.63% on GSM8K and 23.02% on GSM-Plus). This reinforces our finding that smaller models are more sensitive to optimization instability during iterative fine-tuning. Importantly, using a lower temperature of 0.2 substantially mitigates this issue, allowing the Llama-3B model to maintain competitive performance (73.62% on GSM8K) even after two rounds of evolution.</p><p>These results highlight the importance of careful hyperparameter selection during iterative self-evolution, particularly for smaller models that may be more susceptible to catastrophic forgetting or excessive policy drift.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 Complete Round 3 MAD Results</head><p>To investigate the long-term stability of collaborative reasoning capabilities through multiple evolution iterations, we conducted a third round of multi-agent debate after the second round of GRPO fine-tuning. Table <ref type="table" target="#tab_4">11</ref> presents these results for three Qwen models across the same four debate configurations.</p><p>The Round 3 MAD results reveal interesting trends in iterative evolution. For the Qwen-2.5-3B and Qwen-2.5-7B models, performance remains relatively stable across debate configurations, indicating robust retention of reasoning capabilities through multiple fine-tuning iterations. However, the Qwen-2.5-1.5B model shows more variable performance, particularly under the exponential temperature scaling configuration where it drops to 44.28% on GSM8K.</p><p>Notably, the deterministic debate setting (Det) consistently produces the best or near-best performance across all models and datasets, suggesting that reduced randomness in collaborative reasoning becomes increasingly important after multiple evolution rounds. This aligns with our hypothesis that controlling policy drift is crucial for successful iterative evolution.</p><p>The stability of larger models (3B+) across multiple evolution rounds indicates that our DEBATE, TRAIN, EVOLVE framework can support continuous improvement without substantial performance degradation when applied to sufficiently capable base models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5 Complete Cross Domain Task Results</head><p>A key question for self-evolution frameworks is whether improvements generalize beyond the training domain. Table <ref type="table" target="#tab_21">12</ref> presents results for models fine-tuned on either GSM8K or GSM-Plus and evaluated on multiple out-of-domain tasks including ARC-Easy, ARC-Challenge, and CommonsenseQA.</p><p>The cross-domain results reveal impressive generalization capabilities. Models fine-tuned on mathematical reasoning tasks (GSM8K and GSM-Plus) show substantial performance improvements not only on the alternative math dataset but also on science and commonsense reasoning benchmarks. For instance, the Qwen-2.5-14B model fine-tuned on GSM8K achieves 98.19% accuracy on ARC-Easy, 93.69% on ARC-Challenge, and 83.70% on CommonsenseQA.</p><p>Interestingly, models fine-tuned on GSM-Plus generally perform better on GSM8K than vice versa. For example, the Qwen-2.5-1.5B model achieves 73.09% on GSM8K when fine-tuned on GSM-Plus, but only 51.21% on GSM-Plus when fine-tuned on GSM8K. This asymmetry suggests that GSM-Plus may require more diverse reasoning strategies that transfer well to simpler tasks.</p><p>The strong cross-domain performance demonstrates that our DEBATE, TRAIN, EVOLVE framework does not simply optimize for specific datasets but instead enhances fundamental reasoning capabilities that generalize across tasks. This is a critical advantage over traditional supervised fine-tuning approaches that often exhibit limited transferability. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Complete Results of Large-scale Empirical Study on MAD using RCR Prompting</head><p>This section presents a comprehensive analysis of our large-scale empirical investigation into Multi-Agent Debate (MAD) using Recursive Critical Reflection (RCR) prompting across five diverse benchmarks: GSM8K, GSM-Plus, ARC-Easy, ARC-Challenge, and CommonsenseQA. Through extensive experimentation involving various model combinations and parameter settings, we evaluate how collaborative reasoning among multiple language model agents affects problem-solving performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Evaluation Metrics and Methodology</head><p>To facilitate systematic comparison and analysis of debate outcomes, we track the following key metrics across all debate configurations:</p><p>• Accuracy: The primary performance measure, representing the percentage of problems correctly solved after the debate process concludes.</p><p>• ∆ (Performance Delta): Measures the performance change relative to appropriate baselines. We report several variants including:</p><p>-∆ (vs Base): Change compared to the single agent's performance -∆ (vs Lower Agent): Change compared to the lower-performing agent in cross-agent debates -∆ (vs Upper Agent): Change compared to the better-performing agent in cross-agent debates -∆ (vs Lowest): Change compared to the lowest-performing agent in three-agent settings</p><p>• Debate Rounds: The average number of interaction rounds required to reach consensus or the maximum allowed limit, indicating debate efficiency.</p><p>• Sycophancy: A normalized measure (per data points) quantifying the tendency of agents to abandon their answers in favor of matching another agent's previous response, providing insights into social influence dynamics.</p><p>• State Transitions: Tracked as C→I (correct to incorrect) and I→C (incorrect to correct) counts, these reveal the qualitative nature of answer changes during debate.</p><p>• Debate Helped: The overall count of instances where the debate process improved the final outcome compared to initial responses.</p><p>Our evaluation spans multiple dimensions of agent configuration:</p><p>• Agent Settings: We systematically vary temperature parameter across four settings:</p><p>- Our extensive experimental results are organized in Tables <ref type="table" target="#tab_22">13-32</ref>, systematically covering all five datasets with the four debate configurations described above. For each dataset, we present:</p><p>• Table set 1 (Tables <ref type="table" target="#tab_26">13-16</ref>): Performance on GSM8K</p><p>• Table <ref type="table" target="#tab_30">set 2 (Tables 17-20</ref>): Performance on GSM-Plus</p><p>• Table <ref type="table" target="#tab_34">set 3 (Tables 21-24</ref>): Performance on ARC-Easy</p><p>• Table <ref type="table" target="#tab_37">set 4 (Tables 25-28</ref>): Performance on ARC-Challenge</p><p>• Table <ref type="table" target="#tab_19">set 5 (Tables 29-32</ref>): Performance on CommonsenseQA E.3 Key Findings and Patterns</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3.1 Impact of Agent Settings</head><p>Our analysis reveals that agent parameter settings significantly influence debate outcomes across all datasets. We observe that while the Default setting provides reliable performance, Exploratory settings often lead to higher variance in outcomes, sometimes yielding exceptional improvements but also risking performance degradation. The Deterministic setting generally produces more consistent but potentially conservative results.</p><p>The sycophancy metric proves particularly informative, showing higher values in debates between models with substantial performance gaps. This suggests that lower-performing models tend to defer to higher-performing ones, which can be either beneficial or detrimental depending on the initial state distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3.2 Cross-Model Debate Dynamics</head><p>In cross-agent debates (Tables <ref type="table" target="#tab_23">10-14</ref>), we find that pairing models with complementary strengths often produces synergistic effects. The ∆ metrics relative to both upper and lower agents reveal important patterns: when a high-performing model debates with a weaker one, the debate outcome typically falls between their individual performances but closer to the stronger model's baseline.</p><p>State transitions (C→I and I→C) provide valuable insights into debate quality. A high I→C rate coupled with a low C→I rate indicates constructive debate where correct reasoning prevails, while the opposite pattern signals problematic dynamics where convincing but incorrect reasoning dominates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3.3 Three-Agent Debate Effectiveness</head><p>The introduction of a third agent creates more complex interaction patterns. Three-agent debates consistently show lower sycophancy rates compared to two-agent settings, suggesting that the presence of multiple perspectives reduces blind conformity. When all three agents are identical, we observe that diversity in parameter settings typically outperforms homogeneous settings.</p><p>In three varied agent debates, we find particularly interesting results when combining models of different sizes and architectures. As shown in Table <ref type="table" target="#tab_26">16</ref>, certain combinations like "Qwen-2.5-3B + Phi-mini-3.8B + Llama-3.1-3B" achieve accuracy improvements even compared to the highest-performing individual agent, suggesting effective complementarity between these models' reasoning approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3.4 Dataset-Specific Patterns</head><p>Our results indicate substantial variation in debate effectiveness across different datasets:</p><p>• GSM8K and GSM+: Harder Mathematical reasoning tasks (GSM-Plus) show the most consistent benefits from debate, with average debate rounds typically higher than other datasets, suggesting that step-by-step verification is particularly valuable for these problems.</p><p>• ARC-Easy and ARC-Challenge: Multiple-choice science questions reveal interesting patterns where sycophancy is generally lower, but debate can still improve performance when appropriately configured.</p><p>• CommonsenseQA: This dataset exhibits unique characteristics where debates tend to conclude more quickly, suggesting that commonsense reasoning may be less amenable to explicit verification through debate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.4 Conclusion</head><p>Tables 13-32 collectively present a comprehensive empirical foundation for understanding the effects of Multi-Agent Debate using RCR prompting across diverse reasoning tasks. The metrics reveal nuanced patterns in how debate influences performance, with clear evidence that appropriate configuration of debate participants and settings can yield substantial improvements over single-agent performance.</p><p>The consistent tracking of accuracy, deltas, debate rounds, sycophancy, and state transitions provides a multi-dimensional view of debate quality beyond simple performance measures. These results demonstrate that MAD is not universally beneficial but rather depends critically on the specific combination of models, parameter settings, and problem domains. Our findings establish an important baseline for future research on collaborative reasoning between language models, highlighting both the potential and the challenges of multi-agent approaches to complex problem-solving. Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-0.5B All: Default 41.70 0.3 ↓ 2.77 3.17 414.00 393.00 236.00 Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-0.5B All: Deterministic 47.31 5.31 ↑ 0.00 0.00 0.00 0.00 0.00 Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-0.5B All: Exploratory 36.09 5.91 ↓ 3.47 3.33 438.00 450.00 282.00 Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-0.5B   Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-0.5B Default 25.00 0.21 ↑ 3.21 3.75 583 473 Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-0.5B Deterministic 29.21 4.42 ↑ 0.02 0.00 0 0 0 Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-0.5B Exploratory 20.75 4.04 ↓ 3.88 3.78 645 578 Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-0.5B 1 Det. &amp; 2 Exp.</p><p>22.67 2.12 ↓ 3.66 3.40 667 467 Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-0.5B 2 Det. &amp; 1 Exp.</p><p>25.42 0.63 ↑ 2.45 1.96 454 394</p><p>Qwen-2.5-1.5B Qwen-2.5-1.5B Qwen-2.5-1.5B Default 53.04 11.04 ↑ 1.87 2.28 446 995 Qwen-2.5-1.5B Qwen-2.5-1.5B Qwen-2.5-1.5B Deterministic 47.29 5.29 ↑ 0.03 0.00 0 0 0 Qwen-2.5-1.5B Qwen-2.5-1.5B Qwen-2.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of the proposed DEBATE-TRAIN-EVOLVE framework. Left-Debate: Several agents debate until they converge on a consensus (green ✓) or expose a wrong path (red ✗).Centre-Train: we remove pure debate elements, keep the high-quality reasoning traces and consensus answer, and use them to fine-tune a single policy with GRPO. Right-Evolve: the evolved agent replaces its earlier self, so future inference require just one forward pass yet they outperform the committee on maths, science, and commonsense benchmarks.</figDesc><graphic coords="2,70.87,70.87,453.52,202.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4. 1</head><label>1</label><figDesc>Experimental Setup Datasets. We conduct experiments on five public reasoning benchmarks: 1) GSM8K (Cobbe et al., 2021), 2) GSM-Plus (Li et al., 2024) (harder numeric reasoning), 3) ARC-Easy, 4) ARC-Challenge (Clark et al., 2018), and 5) Common-senseQA (Talmor et al., 2019).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 Figure 6 :</head><label>66</label><figDesc>Figure 6: Iterative fine-tuning and forgetting. Accuracy of Qwen-1.5 B after the first and second evolution rounds at four sampling temperatures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Default: Balanced temperature -Deterministic (Det.): Lower temperature for more consistent outputs -Exploratory (Exp.): Higher temperature for more diverse responses -Mixed: Combinations of the above settings across different agents • Debate Structures: We investigate four primary debate configurations: -Single-Model Debate: Multiple instances of the same model with varied parameter settings -Cross-Agent Debate: Two different models debating with various parameter settings -Three Identical Agents: Three instances of the same model with potentially different settings -Three Varied Agents: Three different models engaging in debate E.2 Overview of Results Organization</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>all y</figDesc><table><row><cell></cell><cell>(0) i</cell><cell cols="4">identical then</cell></row><row><cell>3</cell><cell cols="5">return this answer</cell></row><row><cell>4 end</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">5 for t = 1 to T do</cell></row><row><cell>6</cell><cell cols="5">each ai receives {(y j (t−1)</cell><cell>, r</cell><cell>(t−1) j</cell><cell>)} j̸ =i</cell></row><row><cell>7</cell><cell cols="5">reflect: list potential error in y</cell><cell>(t−1) i</cell></row><row><cell>8</cell><cell cols="5">critique: point out one flaw in two distinct peers'</cell></row><row><cell></cell><cell cols="4">rationales</cell></row><row><cell>9</cell><cell cols="5">refine: output (y</cell><cell>(t) i , r</cell><cell>(t) i ), adding at least one</cell></row><row><cell></cell><cell cols="4">novel step if y</cell><cell>(t) i</cell><cell≯ = y</cell><cell>(t−1) i</cell></row><row><cell>10</cell><cell cols="2">if all y</cell><cell>(t) i</cell><cell cols="2">identical then</cell></row><row><cell>11</cell><cell cols="5">return consensus answer</cell></row><row><cell>12</cell><cell>end</cell><cell></cell><cell></cell><cell></cell></row><row><cell>13 end</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">14 return majority_vote {y i (T )</cell><cell>}</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>validation reward &lt; 1% better than previous then</figDesc><table><row><cell>11</cell><cell>break</cell></row><row><cell>12</cell><cell>end</cell></row><row><cell>13 end</cell><cell></cell></row><row><cell cols="2">14 return final student π θ k</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Performance of one DEBATE-TRAIN-EVOLVE round. For six open-weight models we report test accuracy on three reasoning benchmarks in three settings: the single base model ("Original"), a 3-agent debate using our RCR prompt ("MAD"), and the evolved single student obtained after one DTE round. Green numbers denote the absolute gain of the evolved model over its Original Model, red numbers a decrease in performance.</figDesc><table><row><cell>use one exploratory and two deterministic agents.</cell></row><row><cell>For evolution we adopt LoRA fine-tuning (rank</cell></row><row><cell>128, dropout 0.05) on attention and MLP pro-</cell></row><row><cell>jections, freezing embeddings and layer norms.</cell></row><row><cell>GRPO is optimized with AdamW (learning rate</cell></row><row><cell>2×10 −5 , weight decay 0.01, 50-step linear warm-</cell></row><row><cell>up). Each evolution epoch processes 8k debate</cell></row><row><cell>traces (∼2 M tokens) and runs on A100-80 GB</cell></row><row><cell>GPUs for a 7B model; larger models scale near-</cell></row><row><cell>linearly.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>contrasts</cell></row><row><cell>three settings: the single base model ("Original"), a</cell></row><row><cell>three-agent debate with our RCR prompt ("MAD"),</cell></row></table><note>and the evolved single model produced by one DE-BATE-TRAIN-EVOLVE pass. On GSM-Plus-the hard math dataset-DTE improves every model, with an average gain of +2.38 points over threeagent MAD. Qwen-1.5B shows the largest jump (+13.92 pts), confirming that evolution is most helpful when the base model has head-room and the debate provides diverse traces. On GSM8K the average gain is smaller ( +0.84 pts) because several models were already near their ceiling after debate. ARC-Challenge sees a mixed results: large models benefit (+3.67 pts for Qwen-7B, +8.88 pts for Llama-8B) while small models drift by &lt; 1 pt. Overall, DTE shows a mean improvement of 3.06 pts over single model and +1.09 pts over MAD while restoring single-pass inference.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc>Accuracy on GSM-Plus after 10K training steps using three optimization objectives.</figDesc><table><row><cell>icy stability better than plain maximum-likelihood</cell></row><row><cell>(SFT) or preference-only (DPO/PPO) updates. Ta-</cell></row><row><cell>ble 3 compare three update rules under a fixed com-</cell></row><row><cell>pute budget: (1) classical supervised fine-tuning on</cell></row><row><cell>debate answers (SFT); (2) Direct Preference Opti-</cell></row><row><cell>misation using the majority vote as the preferred</cell></row><row><cell>sample; (3) Group Relative Policy Optimisation</cell></row><row><cell>(GRPO). GRPO delivers the largest accuracy jump</cell></row><row><cell>on GSM-Plus for every model size. Both SFT and</cell></row><row><cell>DPO give smaller gains and even slight regressions</cell></row><row><cell>on the 3 B model, highlighting the risk of over-</cell></row><row><cell>fitting when the reward ignores policy shift. We</cell></row><row><cell>also observe that GRPO keeps KL &lt; 0.24 across</cell></row><row><cell>sizes, whereas DPO averages 0.43. The relative-</cell></row><row><cell>advantage term in GRPO therefore not only boosts</cell></row><row><cell>reward but also constrains drift, reducing catas-</cell></row><row><cell>trophic forgetting.</cell></row><row><cell>5) DATA SELECTION STRATEGY. We test three</cell></row><row><cell>data sampling schemes on GSM-Plus: Random-</cell></row><row><cell>2K selects 2000 examples uniformly from the full</cell></row><row><cell>pool (10552); Debate-Only keeps only data points</cell></row><row><cell>where agents entered at least one critique round</cell></row><row><cell>(t ≥ 1); All-Traces trains on the entire cleaned set.</cell></row><row><cell>Table 4 shows that accuracy rises monotonically</cell></row><row><cell>with coverage: the full corpus beats Debate-Only</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Effect of training-set size and composition.</figDesc><table><row><cell cols="6">GSM-Plus accuracy after one evolution round using</cell></row><row><cell cols="4">three trace-selection schemes.</cell><cell></cell></row><row><cell></cell><cell>80</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>75</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>70</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Accuracy (%)</cell><cell>60 65</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>55</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Qwen-2.5-1.5B</cell></row><row><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell>Qwen-2.5-3B Qwen-2.5-7B</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Qwen-2.5-14B</cell></row><row><cell></cell><cell>45</cell><cell></cell><cell></cell><cell></cell><cell>Llama-3B Llama-8B</cell></row><row><cell></cell><cell>2000</cell><cell>4000</cell><cell>6000 Training Steps</cell><cell>8000</cell><cell>10000</cell></row><row><cell cols="6">Figure 5: Diminishing returns in GRPO updates after</cell></row><row><cell cols="6">8K steps. GSM-Plus accuracy for five models as a</cell></row><row><cell cols="6">function of the number of training steps during GRPO.</cell></row><row><cell cols="6">by 4.43 pts (avg) and Random-2K by 9.17 pts</cell></row><row><cell cols="6">(avg). The gap is largest for Qwen-1.5B, suggesting</cell></row><row><cell cols="6">that smaller models benefit from easier "round-0"</cell></row><row><cell cols="6">examples that Random-2K may miss and Debate-</cell></row><row><cell cols="6">Only discards. We therefore use the full trace set</cell></row><row><cell cols="4">in all other experiments.</cell><cell></cell></row><row><cell cols="6">6) HOW LONG DO WE TRAIN? Figure 5 plots</cell></row><row><cell cols="6">GSM-Plus accuracy as we grow the number of</cell></row><row><cell cols="6">GRPO training steps from 2K to 10K. All mod-</cell></row><row><cell cols="6">els share the similiar trend: rapid gains up to</cell></row><row><cell cols="6">about 8K steps followed by saturation. Small and</cell></row><row><cell cols="6">mid-size models profit the most from the early</cell></row><row><cell cols="6">updates-Qwen-1.5B climbs 8.0 pts between 2K</cell></row><row><cell cols="6">and 6K samples-whereas larger models such as</cell></row><row><cell cols="6">Qwen-14B rise more slowly but steady. Beyond 8K</cell></row><row><cell cols="6">the curve flattens: the average improvement from</cell></row><row><cell cols="6">8K ß 10 k is only +0.32 pts while wall-clock time</cell></row><row><cell cols="2">grows by 25%.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">7) DOES ITERATIVE FINE-TUNING HURT?</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Thomas D Barrett, and Arnu Pretorius. 2023. Should we be going mad? a look at multi-agent debate strategies for llms. arXiv preprint arXiv:2311.17371. Complete GRPO results (all steps, temperature) . . . . . . . . . . . . . . . . . . . . . . D.2 Complete Round 2 MAD Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.3 GRPO round 2 results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.4 Complete Round 3 MAD Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.5 Complete Cross Domain Task Results . . . . . . . . . . . . . . . . . . . . . . . . . . . E Complete Results of Large-scale Empirical Study on MAD using RCR Prompting E.1 Evaluation Metrics and Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc><table><row><cell>Contents of the Appendix</cell></row><row><cell>A Datasets Details</cell></row><row><cell>B Implementation Details</cell></row><row><cell>C REFLECT-CRITIQUE-REFINE Prompt Design</cell></row><row><cell>D Additional Self-Evolution Results</cell></row><row><cell>D.1</cell></row><row><cell>Gaurav Srivastava, Shuxiang Cao, and Xuan Wang.</cell></row><row><cell>2025. Towards reasoning ability of small language</cell></row><row><cell>models. arXiv preprint arXiv:2502.11569.</cell></row><row><cell>Vighnesh Subramaniam, Yilun Du, Joshua B Tenen-</cell></row><row><cell>baum, Antonio Torralba, Shuang Li, and Igor Mor-</cell></row><row><cell>datch. 2025. Multiagent finetuning: Self improve-</cell></row><row><cell>ment with diverse reasoning chains. arXiv preprint</cell></row><row><cell>arXiv:2501.05707.</cell></row></table><note>Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A question answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4149-4158, Minneapolis, Minnesota. Association for Computational Linguistics. Qineng Wang, Zihao Wang, Ying Su, Hanghang Tong, and Yangqiu Song. 2024. Rethinking the bounds of llm reasoning: Are multi-agent discussions the key? In Annual Meeting of the Association for Computational Linguistics. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022. Self-instruct: Aligning language models with self-generated instructions. arXiv preprint arXiv:2212.10560. Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D Goodman. 2024. Star: Self-taught reasoner bootstrapping reasoning with reasoning. In Proc. the 36th International Conference on Neural Information Processing Systems, volume 1126. Weihao Zeng, Can Xu, Yingxiu Zhao, Jian-Guang Lou, and Weizhu Chen. 2024. Automatic instruction evolving for large language models. Preprint, arXiv:2406.00770. E.2 Overview of Results Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.3 Key Findings and Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.3.1 Impact of Agent Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.3.2 Cross-Model Debate Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . E.3.3 Three-Agent Debate Effectiveness . . . . . . . . . . . . . . . . . . . . . . . . . E.3.4 Dataset-Specific Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F Additional Results F.1 Original MAD Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.2 Majority Vote@3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.3 Scaling Results for Multiple Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Table 5 summarizes the splits for each dataset.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Train Validation Test</cell></row><row><cell>GSM8K</cell><cell>7,473</cell><cell>-</cell><cell>1,319</cell></row><row><cell>GSM+</cell><cell>-</cell><cell>10,552</cell><cell>2,400</cell></row><row><cell>ARC-Easy</cell><cell>2,251</cell><cell>570</cell><cell>2,376</cell></row><row><cell>ARC-Challenge</cell><cell>1,119</cell><cell>299</cell><cell>1,172</cell></row><row><cell cols="2">CommonsenseQA 9,741</cell><cell>1,221</cell><cell>1,140</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 5 :</head><label>5</label><figDesc>Dataset splits and example counts. Note that GSM8K is provided with only training and test splits.</figDesc><table /><note>GSM8K(Cobbe et al., 2021)  is a collection of high-quality grade school math word problems that require multi-step reasoning. In the main configuration, the dataset contains a total of 8,790 examples, with 7,473 examples in the training split and 1,319 examples in the test split. These problems typically require between 2 and 8 steps to solve, making it an excellent benchmark for evaluating mathematical reasoning capabilities.GSM-Plus(Li et al., 2024)  extends the GSM8K benchmark with more challenging and diverse mathematical word problems. GSM+ problems generally require more sophisticated multi-step reasoning and often involve more complex mathematical concepts than those in the original GSM8K dataset.ARC(Clark et al., 2018)  comprises two subsets of multiple-choice science questions: • ARC-Easy: Contains 2,251 train, 570 validation, and 2,376 test examples. These questions are answerable by most middle school students and test basic science knowledge. • ARC-Challenge: Contains 1,119 train, 299 validation, and 1,172 test examples. These questions are more challenging and typically answered incorrectly by both retrieval-based algorithms and word co-occurrence algorithms. CommonsenseQA (Talmor et al., 2019) requires commonsense reasoning to answer multiple-choice questions. It has 9,741 training examples, 1,221 validation examples, and 1,140 test examples. The questions are specifically designed to test commonsense knowledge and reasoning capabilities that go beyond simple factual recall.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 6 :</head><label>6</label><figDesc>Complete GRPO Results on GSM8K Dataset. Results show accuracy (%) for different models under various GRPO configurations. Training hyperparameters include learning rate of 5e-6 and context length of 256 tokens. MAD refers to Multi-Agent Debate baseline performance.</figDesc><table><row><cell>Model</cell><cell cols="3">Base Performance MAD</cell><cell cols="3">GRPO (Temperature 0.8)</cell><cell cols="3">GRPO (Temperature 0.2)</cell></row><row><cell></cell><cell>Train</cell><cell>Test</cell><cell></cell><cell cols="6">2k steps 5k steps 10k steps 2k steps 5k steps 10k steps</cell></row><row><cell cols="2">Qwen-2.5-1.5B 81.55</cell><cell>62.77</cell><cell>72.33</cell><cell>67.78</cell><cell>71.42</cell><cell>71.04</cell><cell>73.09</cell><cell>66.49</cell><cell>53.98</cell></row><row><cell>Qwen-2.5-3B</cell><cell>91.28</cell><cell>84.08</cell><cell>85.14</cell><cell>85.06</cell><cell>85.14</cell><cell>86.13</cell><cell>84.00</cell><cell>86.05</cell><cell>84.38</cell></row><row><cell>Qwen-2.5-7B</cell><cell>94.29</cell><cell>90.67</cell><cell>91.21</cell><cell>88.32</cell><cell>86.73</cell><cell>84.00</cell><cell>86.96</cell><cell>86.35</cell><cell>88.02</cell></row><row><cell>Llama-3B</cell><cell>83.90</cell><cell>72.55</cell><cell>73.84</cell><cell>69.22</cell><cell>21.53</cell><cell>2.73</cell><cell>72.40</cell><cell>75.06</cell><cell>3.26</cell></row><row><cell>Llama-8B</cell><cell>89.08</cell><cell>81.73</cell><cell>82.18</cell><cell>84.61</cell><cell>85.29</cell><cell>85.22</cell><cell>86.81</cell><cell>84.91</cell><cell>0.15</cell></row><row><cell cols="2">Qwen-2.5-14B 94.89</cell><cell>92.80</cell><cell>93.33</cell><cell>87.72</cell><cell>89.84</cell><cell>91.81</cell><cell>86.58</cell><cell>89.34</cell><cell>93.74</cell></row><row><cell>Model</cell><cell cols="3">Base Performance MAD</cell><cell cols="3">GRPO (Temperature 0.8)</cell><cell cols="3">GRPO (Temperature 0.2)</cell></row><row><cell></cell><cell>Train</cell><cell>Test</cell><cell></cell><cell cols="6">2k steps 5k steps 10k steps 2k steps 5k steps 10k steps</cell></row><row><cell cols="2">Qwen-2.5-1.5B 42.40</cell><cell>42.00</cell><cell>51.62</cell><cell>47.49</cell><cell>54.46</cell><cell>19.00</cell><cell>52.33</cell><cell>53.04</cell><cell>55.92</cell></row><row><cell>Qwen-2.5-3B</cell><cell>61.14</cell><cell>61.75</cell><cell>67.79</cell><cell>66.21</cell><cell>66.71</cell><cell>69.13</cell><cell>64.04</cell><cell>67.25</cell><cell>68.25</cell></row><row><cell>Qwen-2.5-7B</cell><cell>68.27</cell><cell>68.62</cell><cell>74.17</cell><cell>64.71</cell><cell>73.38</cell><cell>74.71</cell><cell>67.75</cell><cell>72.54</cell><cell>74.50</cell></row><row><cell>Llama-3B</cell><cell>47.68</cell><cell>45.67</cell><cell>51.12</cell><cell>52.38</cell><cell>53.29</cell><cell>52.33</cell><cell>51.79</cell><cell>49.54</cell><cell>53.79</cell></row><row><cell>Llama-8B</cell><cell>58.56</cell><cell>55.62</cell><cell>60.79</cell><cell>64.96</cell><cell>61.58</cell><cell>66.17</cell><cell>65.08</cell><cell>63.46</cell><cell>60.46</cell></row><row><cell cols="2">Qwen-2.5-14B 71.11</cell><cell>71.79</cell><cell>77.25</cell><cell>70.79</cell><cell>73.54</cell><cell>75.88</cell><cell>73.00</cell><cell>73.42</cell><cell>75.62</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 7 :</head><label>7</label><figDesc>Complete GRPO Results on GSM-Plus Dataset. Results show accuracy (%) for different models under various GRPO configurations on the more challenging GSM-Plus dataset. Training hyperparameters include learning rate of 5e-6.</figDesc><table><row><cell>Model</cell><cell cols="3">Base Performance MAD</cell><cell cols="3">GRPO (Temperature 0.8)</cell><cell cols="3">GRPO (Temperature 0.2)</cell></row><row><cell></cell><cell>Train</cell><cell>Test</cell><cell></cell><cell cols="6">2k steps 5k steps 10k steps 2k steps 5k steps 10k steps</cell></row><row><cell>Qwen-2.5-1.5B</cell><cell>-</cell><cell>69.21</cell><cell>68.52</cell><cell>30.03</cell><cell>62.63</cell><cell>68.36</cell><cell>47.27</cell><cell>51.88</cell><cell>67.51</cell></row><row><cell>Qwen-2.5-3B</cell><cell>-</cell><cell>83.53</cell><cell>84.64</cell><cell>81.66</cell><cell>80.29</cell><cell>83.63</cell><cell>81.91</cell><cell>79.78</cell><cell>83.95</cell></row><row><cell>Qwen-2.5-7B</cell><cell>-</cell><cell>87.22</cell><cell>91.64</cell><cell>88.57</cell><cell>88.48</cell><cell>90.63</cell><cell>88.43</cell><cell>88.57</cell><cell>90.89</cell></row><row><cell>Llama-3B</cell><cell>-</cell><cell>73.12</cell><cell>76.19</cell><cell>75.51</cell><cell>74.32</cell><cell>76.87</cell><cell>76.79</cell><cell>74.57</cell><cell>77.23</cell></row><row><cell>Llama-8B</cell><cell>-</cell><cell>77.65</cell><cell>85.07</cell><cell>83.70</cell><cell>84.45</cell><cell>86.03</cell><cell>84.98</cell><cell>85.53</cell><cell>86.53</cell></row><row><cell>Qwen-2.5-14B</cell><cell>-</cell><cell>90.27</cell><cell>93.77</cell><cell>91.81</cell><cell>92.49</cell><cell>93.13</cell><cell>91.47</cell><cell>91.47</cell><cell>92.67</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 8 :</head><label>8</label><figDesc>Complete GRPO Results on ARC-Challenge Dataset. Results show accuracy (%) for different models under various GRPO configurations on the ARC-Challenge dataset. Training hyperparameters include learning rate of 5e-6 and context length of 128 tokens. Base train performance was not evaluated for this dataset.</figDesc><table><row><cell>Model</cell><cell>Dataset</cell><cell cols="4">GRPO Round 2 (Temp 0.8) GRPO Round 2 (Temp 0.2)</cell></row><row><cell></cell><cell></cell><cell>2k steps</cell><cell>5k steps</cell><cell>2k steps</cell><cell>5k steps</cell></row><row><cell>Qwen-2.5-1.5B</cell><cell>GSM8K GSM-Plus</cell><cell>65.73 47.38</cell><cell>68.54 50.12</cell><cell>69.98 46.37</cell><cell>72.18 48.04</cell></row><row><cell>Qwen-2.5-3B</cell><cell>GSM8K GSM-Plus</cell><cell>84.84 65.71</cell><cell>86.05 67.96</cell><cell>84.46 65.67</cell><cell>84.08 67.00</cell></row><row><cell>Qwen-2.5-7B</cell><cell>GSM8K GSM-Plus</cell><cell>86.28 69.42</cell><cell>87.19 73.75</cell><cell>88.17 70.54</cell><cell>87.34 73.12</cell></row><row><cell>Llama-3B</cell><cell>GSM8K GSM-Plus</cell><cell>55.88 48.75</cell><cell>35.63 23.02</cell><cell>73.62 52.42</cell><cell>64.29 25.08</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 9 :</head><label>9</label><figDesc>Complete GRPO Round 2 Results. Results show accuracy (%) after second round of GRPO training across different step counts and temperature settings. All models were trained with learning rate of 5e-6 and context length of 128 tokens.</figDesc><table><row><cell>Model</cell><cell>Dataset</cell><cell cols="2">MAD Configuration</cell></row><row><cell></cell><cell cols="3">Exp Default temp4 Det</cell></row><row><cell>Qwen-2.5-1.5B</cell><cell>GSM8K GSM-Plus 22.09 46.32</cell><cell>66.34 53.18</cell><cell>68.61 69.07 55.62 56.62</cell></row><row><cell>Qwen-2.5-3B</cell><cell>GSM8K GSM-Plus 69.62 84.08</cell><cell>86.66 70.25</cell><cell>86.35 86.50 69.67 70.29</cell></row><row><cell>Qwen-2.5-7B</cell><cell>GSM8K GSM-Plus 76.42 91.36</cell><cell>90.75 77.00</cell><cell>91.05 89.99 77.75 77.62</cell></row><row><cell>Llama-3B</cell><cell>GSM8K GSM-Plus 53.62 66.26</cell><cell>75.97 54.58</cell><cell>75.51 75.36 55.96 56.04</cell></row><row><cell>Llama-8B</cell><cell>GSM8K GSM-Plus 65.00 84.69</cell><cell>85.90 65.92</cell><cell>86.96 85.60 66.46 66.50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 10 :</head><label>10</label><figDesc>Complete MAD Round 2 Results. Results show accuracy (%) for different models in multi-agent debate after first round of GRPO fine-tuning. Exp = exponential temperature scaling, Default = standard configuration, temp4 = temperature-4 settings, Det = deterministic configuration.</figDesc><table><row><cell>Model</cell><cell>Dataset</cell><cell cols="2">MAD Configuration</cell></row><row><cell></cell><cell cols="3">Exp Default temp4 Det</cell></row><row><cell>Qwen-2.5-1.5B</cell><cell>GSM8K GSM-Plus 35.54 44.28</cell><cell>60.65 48.62</cell><cell>67.70 72.40 51.67 51.75</cell></row><row><cell>Qwen-2.5-3B</cell><cell>GSM8K GSM-Plus 63.67 83.78</cell><cell>85.60 63.42</cell><cell>85.75 86.13 64.16 64.47</cell></row><row><cell>Qwen-2.5-7B</cell><cell>GSM8K GSM-Plus 69.67 89.76</cell><cell>91.05 69.85</cell><cell>90.90 91.13 70.50 69.88</cell></row></table><note>Table 11: Complete MAD Round 3 Results. Results show accuracy (%) for different models in multi-agent debate after second round of GRPO fine-tuning. Exp = exponential temperature scaling, Default = standard configuration, temp4 = temperature-4 settings, Det = deterministic configuration.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 12 :</head><label>12</label><figDesc>Complete Cross Domain Task Results. Results show accuracy (%) on various datasets after fine-tuning on either GSM8K or GSM-Plus. Dashes (-) indicate that evaluation was not performed on the same dataset used for fine-tuning.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 13 :</head><label>13</label><figDesc>Performance in Multi-Agent Debate Settings on the GSM8K Dataset. This table showcases the impact of different Agent Settings (controlling temperature and top_p parameters like Default, Deterministic, Exploratory, and a combination) on the MAD Accuracy (RCR Prompting) of various language models. The ∆ column quantifies the improvement (or decline) over the single base model performance. Further metrics include average Debate Rounds, normalized Sycophancy (per 1319 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), highlighting the nuanced effects of debate dynamics.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell>Agent Settings</cell><cell>MAD Accuracy</cell><cell>∆</cell><cell cols="2">Debate Sycophancy</cell><cell>C→I</cell><cell>I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(RCR Prompting)</cell><cell></cell><cell cols="2">Rounds (Avg / 1319)</cell><cell></cell><cell></cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell></cell><cell></cell><cell></cell><cell>(Overall)</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-0.5B</cell><cell>Both: Default</cell><cell>47.38</cell><cell>5.38 ↑</cell><cell>1.60</cell><cell>1.17</cell><cell>156.00</cell><cell></cell><cell>220</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Both: Deterministic</cell><cell>47.31</cell><cell>5.31 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Both: Exploratory</cell><cell>39.20</cell><cell>2.8 ↓</cell><cell>2.19</cell><cell>1.25</cell><cell>185.00</cell><cell></cell><cell>234</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Both: Det. &amp; Exp.</cell><cell>43.14</cell><cell>1.14 ↑</cell><cell>1.89</cell><cell>1.09</cell><cell>185.00</cell><cell></cell><cell>226</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>Both: Default</cell><cell>70.89</cell><cell>8.12 ↑</cell><cell>0.86</cell><cell>0.70</cell><cell>101.00</cell><cell></cell><cell>317</cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-1.5B Both: Deterministic</cell><cell>63.46</cell><cell>0.69 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-1.5B Both: Exploratory</cell><cell>71.57</cell><cell>8.8 ↑</cell><cell>1.05</cell><cell>0.84</cell><cell>94.00</cell><cell></cell><cell>399</cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-1.5B Both: Det. &amp; Exp.</cell><cell>72.33</cell><cell>9.56 ↑</cell><cell>0.98</cell><cell>0.71</cell><cell>99.00</cell><cell></cell><cell>377</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Both: Default</cell><cell>86.05</cell><cell>0.91 ↑</cell><cell>0.31</cell><cell>0.21</cell><cell>55.00</cell><cell></cell><cell>104</cell></row><row><cell>Qwen-2.5-3B</cell><cell cols="2">Qwen-2.5-3B Both: Deterministic</cell><cell>84.99</cell><cell>0.15 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Both: Exploratory</cell><cell>85.52</cell><cell>0.38 ↑</cell><cell>0.35</cell><cell>0.26</cell><cell>62.00</cell><cell></cell><cell>103</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Both: Det. &amp; Exp.</cell><cell>86.28</cell><cell>1.14 ↑</cell><cell>0.34</cell><cell>0.19</cell><cell>50.00</cell><cell></cell><cell>101</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Default</cell><cell>91.74</cell><cell>1.07 ↑</cell><cell>0.16</cell><cell>0.13</cell><cell>28.00</cell><cell>53</cell><cell>49</cell></row><row><cell>Qwen-2.5-7B</cell><cell cols="2">Qwen-2.5-7B Both: Deterministic</cell><cell>90.60</cell><cell>0.07 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Exploratory</cell><cell>91.21</cell><cell>0.54 ↑</cell><cell>0.18</cell><cell>0.15</cell><cell>27.00</cell><cell>59</cell><cell>57</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Det. &amp; Exp.</cell><cell>91.51</cell><cell>0.84 ↑</cell><cell>0.18</cell><cell>0.15</cell><cell>33.00</cell><cell>57</cell><cell>55</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Both: Default</cell><cell>93.48</cell><cell>0.68 ↑</cell><cell>0.11</cell><cell>0.13</cell><cell>22.00</cell><cell>46</cell><cell>43</cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Both: Deterministic</cell><cell>93.18</cell><cell>0.38 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Both: Exploratory</cell><cell>93.33</cell><cell>0.53 ↑</cell><cell>0.11</cell><cell>0.12</cell><cell>20.00</cell><cell>48</cell><cell>48</cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Both: Det. &amp; Exp.</cell><cell>93.63</cell><cell>0.83 ↑</cell><cell>0.13</cell><cell>0.15</cell><cell>24.00</cell><cell>44</cell><cell>39</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Both: Default</cell><cell>95.00</cell><cell>0.08 ↑</cell><cell>0.05</cell><cell>0.06</cell><cell>11.00</cell><cell>21</cell><cell>20</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Both: Deterministic</cell><cell>94.77</cell><cell>0.15 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Both: Exploratory</cell><cell>95.38</cell><cell>0.46 ↑</cell><cell>0.07</cell><cell>0.08</cell><cell>9.00</cell><cell>32</cell><cell>31</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Both: Det. &amp; Exp.</cell><cell>95.30</cell><cell>0.38</cell><cell>0.04</cell><cell>0.05</cell><cell>12.00</cell><cell>23</cell><cell>21</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Default</cell><cell>74.91</cell><cell>2.36 ↑</cell><cell>0.73</cell><cell>0.49</cell><cell>106.00</cell><cell></cell><cell>183</cell></row><row><cell>Llama-3.1-3B</cell><cell cols="2">Llama-3.1-3B Both: Deterministic</cell><cell>74.37</cell><cell>1.82 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Exploratory</cell><cell>72.40</cell><cell>0.15 ↓</cell><cell>0.94</cell><cell>0.57</cell><cell>138.00</cell><cell></cell><cell>202</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Det. &amp; Exp.</cell><cell>73.84</cell><cell>1.29 ↑</cell><cell>0.80</cell><cell>0.48</cell><cell>133.00</cell><cell></cell><cell>175</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Default</cell><cell>82.56</cell><cell>0.83 ↑</cell><cell>0.48</cell><cell>0.38</cell><cell>86.00</cell><cell></cell><cell>105</cell></row><row><cell>Llama-3.1-8B</cell><cell cols="2">Llama-3.1-8B Both: Deterministic</cell><cell>81.50</cell><cell>0.23 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Exploratory</cell><cell>80.67</cell><cell>1.06 ↓</cell><cell>0.60</cell><cell>0.40</cell><cell>98.00</cell><cell></cell><cell>149</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Det. &amp; Exp.</cell><cell>82.18</cell><cell>0.45 ↑</cell><cell>0.56</cell><cell>0.39</cell><cell>97.00</cell><cell></cell><cell>126</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Default</cell><cell>87.72</cell><cell>0.84 ↑</cell><cell>0.29</cell><cell>0.27</cell><cell>51.00</cell><cell></cell><cell>95</cell></row><row><cell>Phi-mini-3.8B</cell><cell cols="2">Phi-mini-3.8B Both: Deterministic</cell><cell>86.73</cell><cell>0.15 ↓</cell><cell>0.02</cell><cell>0.00</cell><cell>0.00</cell><cell>2</cell><cell>1</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Exploratory</cell><cell>87.95</cell><cell>1.07 ↑</cell><cell>0.30</cell><cell>0.26</cell><cell>48.00</cell><cell></cell><cell>99</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Det. &amp; Exp.</cell><cell>87.34</cell><cell>0.46 ↑</cell><cell>0.33</cell><cell>0.26</cell><cell>62.00</cell><cell></cell><cell>95</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Default</cell><cell>33.74</cell><cell>12.36 ↑</cell><cell>1.65</cell><cell>0.73</cell><cell>101.00</cell><cell></cell><cell>340</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Deterministic</cell><cell>20.02</cell><cell>1.36</cell><cell>0.04</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Exploratory</cell><cell>35.71</cell><cell>14.33 ↑</cell><cell>1.85</cell><cell>0.80</cell><cell>110.00</cell><cell></cell><cell>381</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Det. &amp; Exp.</cell><cell>33.51</cell><cell>12.13</cell><cell>1.53</cell><cell>0.68</cell><cell>97.00</cell><cell></cell><cell>334</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 14 :</head><label>14</label><figDesc>Performance Analysis of Cross-Agent Debates on the GSM8K Dataset. This table details the outcomes of debates between different language models (Agent 1 and Agent 2). Agent Settings specify the configuration (e.g., Default, Deterministic (Det.), Exploratory (Exp.)) applied to Agent 1 and Agent 2 respectively, influencing temperature and top_p parameters. The table presents overall Accuracy, along with ∆ (Lower Agent) and ∆ (Upper Agent) indicating the performance change for each agent relative to a baseline. Additional metrics include average Debate Rounds, normalized Sycophancy (per 1319 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C) to show debate impact.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell>Agent 3</cell><cell>Agent Settings</cell><cell>Accuracy ∆ (Improvement) Debate Sycophancy C→I I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Rounds (Avg / 1319)</cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell>(Overall)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 15 :</head><label>15</label><figDesc>Performance Analysis of Three Identical Agents Debating on GSM8K. This table shows results when three instances of the same model (Agent 1, Agent 2, Agent 3 being identical) engage in a debate. Agent Settings describe the configuration mix across these three agents (e.g., All Default, or a mix like 1 Deterministic (Det), 2 Exploratory (Exp)). Accuracy is the debate outcome, and ∆ (Improvement) is the change from the single agent's baseline. Standard metrics like Debate Rounds, normalized Sycophancy (per 1319 data points), and error transition rates (C→I, I→C) are also included.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell>Agent 3</cell><cell cols="6">Agent Settings Accuracy ∆ (vs Lowest) Debate Sycophancy C→I I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rounds (Avg / 1319)</cell><cell></cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell></cell><cell></cell><cell>(Overall)</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>All: Default</cell><cell>80.82</cell><cell>4.32 ↓</cell><cell>1.81</cell><cell>1.58</cell><cell cols="2">154.00 859.00 639.00</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>All: Default</cell><cell>69.52</cell><cell>3.03 ↓</cell><cell>2.43</cell><cell>1.76</cell><cell cols="2">271.00 718.00 508.00</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Phi-mini-3.8B</cell><cell>All: Default</cell><cell>76.04</cell><cell>10.84 ↓</cell><cell>2.20</cell><cell>1.47</cell><cell cols="2">267.00 727.00 532.00</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-3B</cell><cell>Llama-3.1-3B</cell><cell>All: Default</cell><cell>79.15</cell><cell>5.99 ↓</cell><cell>2.10</cell><cell>1.36</cell><cell cols="2">184.00 696.00 536.00</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>All: Default</cell><cell>83.62</cell><cell>3.24 ↓</cell><cell>1.82</cell><cell>1.08</cell><cell cols="2">150.00 618.00 534.00</cell></row><row><cell cols="2">Qwen-2.5-0.5B Llama-3.1-3B</cell><cell>Phi-mini-3.8B</cell><cell>All: Default</cell><cell>76.57</cell><cell>10.31 ↓</cell><cell>2.39</cell><cell>1.16</cell><cell cols="2">255.00 515.00 402.00</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Llama-3.1-3B</cell><cell>All: Default</cell><cell>82.71</cell><cell>2.43 ↓</cell><cell>1.24</cell><cell>1.06</cell><cell cols="2">156.00 544.00 436.00</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>All: Default</cell><cell>85.22</cell><cell>1.66 ↓</cell><cell>1.08</cell><cell>0.85</cell><cell cols="2">139.00 460.00 388.00</cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Phi-mini-3.8B</cell><cell>All: Default</cell><cell>81.20</cell><cell>5.68 ↓</cell><cell>1.33</cell><cell>1.05</cell><cell cols="2">196.00 560.00 446.00</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Llama-3.1-3B</cell><cell>All: Default</cell><cell>86.96</cell><cell>0.08 ↑</cell><cell>0.89</cell><cell>0.71</cell><cell cols="2">127.00 372.00 297.00</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>All: Default</cell><cell>87.64</cell><cell>0.76 ↑</cell><cell>0.60</cell><cell>0.55</cell><cell cols="2">97.00 227.00 175.00</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>All: Default</cell><cell>87.79</cell><cell>0.91 ↑</cell><cell>0.58</cell><cell>0.53</cell><cell cols="2">111.00 209.00 167.00</cell></row><row><cell cols="4">Qwen-2.5-0.5B Qwen-2.5-1.5B Qwen-2.5-1.5B All: Default</cell><cell>68.46</cell><cell>5.69 ↑</cell><cell>2.10</cell><cell>2.09</cell><cell cols="2">221.00 795.00 570.00</cell></row><row><cell cols="4">Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-1.5B All: Default</cell><cell>55.12</cell><cell>7.65 ↓</cell><cell>2.60</cell><cell>2.52</cell><cell cols="2">364.00 628.00 407.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 16 :</head><label>16</label><figDesc>Performance Analysis of Three-Agent Debates (Varied Models) on GSM8K. This table presents outcomes from debates involving three potentially different language models (Agent 1, Agent 2, Agent 3). All debates use default agent settings. The ∆ (vs Lowest) column indicates the performance change of the debate outcome (Accuracy) compared to the baseline performance of the lowest-performing agent among the three in that specific debate. Standard metrics like Debate Rounds, normalized Sycophancy (per 1319 data points), and error transition rates (C→I, I→C) are also included.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell>Agent Settings</cell><cell>MAD Accuracy</cell><cell>∆</cell><cell cols="2">Debate Sycophancy</cell><cell>C→I</cell><cell>I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(RCR Prompting)</cell><cell></cell><cell cols="2">Rounds (Avg / 2400)</cell><cell></cell><cell></cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell></cell><cell></cell><cell></cell><cell>(Overall)</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-0.5B</cell><cell>Both: Default</cell><cell>27.33</cell><cell>2.54 ↑</cell><cell>2.00</cell><cell>1.51</cell><cell cols="2">248.00 348</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Both: Deterministic</cell><cell>29.25</cell><cell>4.46 ↑</cell><cell>0.02</cell><cell>0.00</cell><cell>0.00</cell><cell>2</cell><cell>1</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Both: Exploratory</cell><cell>23.12</cell><cell>1.67 ↓</cell><cell>2.56</cell><cell>1.43</cell><cell cols="2">284.00 351</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Both: Det. &amp; Exp.</cell><cell>27.33</cell><cell>2.54 ↑</cell><cell>2.26</cell><cell>1.33</cell><cell cols="2">267.00 396</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>Both: Default</cell><cell>53.12</cell><cell>11.12 ↑</cell><cell>1.14</cell><cell>0.91</cell><cell cols="2">210.00 555</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-1.5B Both: Deterministic</cell><cell>47.29</cell><cell>5.29 ↑</cell><cell>0.03</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-1.5B Both: Exploratory</cell><cell>51.62</cell><cell>9.62 ↑</cell><cell>1.40</cell><cell>1.08</cell><cell cols="2">218.00 647</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-1.5B Both: Det. &amp; Exp.</cell><cell>52.29</cell><cell>10.29 ↑</cell><cell>1.17</cell><cell>0.85</cell><cell cols="2">181.00 528</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Both: Default</cell><cell>67.42</cell><cell>5.67 ↑</cell><cell>0.62</cell><cell>0.39</cell><cell cols="2">133.00 225</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell cols="2">Qwen-2.5-3B Both: Deterministic</cell><cell>67.38</cell><cell>5.63 ↑</cell><cell>0.05</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Both: Exploratory</cell><cell>67.79</cell><cell>6.04 ↑</cell><cell>0.69</cell><cell>0.46</cell><cell cols="2">132.00 296</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Both: Det. &amp; Exp.</cell><cell>66.46</cell><cell>4.71 ↑</cell><cell>0.67</cell><cell>0.36</cell><cell cols="2">163.00 223</cell><cell></cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Default</cell><cell>74.17</cell><cell>5.55 ↑</cell><cell>0.35</cell><cell>0.26</cell><cell cols="2">62.00 135</cell><cell></cell></row><row><cell>Qwen-2.5-7B</cell><cell cols="2">Qwen-2.5-7B Both: Deterministic</cell><cell>73.62</cell><cell>5.00 ↑</cell><cell>0.04</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Exploratory</cell><cell>74.17</cell><cell>5.55 ↑</cell><cell>0.39</cell><cell>0.30</cell><cell cols="2">88.00 158</cell><cell></cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Det. &amp; Exp.</cell><cell>74.46</cell><cell>5.84 ↑</cell><cell>0.33</cell><cell>0.25</cell><cell cols="2">78.00 126</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Both: Default</cell><cell>77.21</cell><cell>5.42 ↑</cell><cell>0.32</cell><cell>0.32</cell><cell cols="2">47.00 102</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Both: Deterministic</cell><cell>76.25</cell><cell>4.46 ↑</cell><cell>0.06</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Both: Exploratory</cell><cell>77.25</cell><cell>5.46 ↑</cell><cell>0.33</cell><cell>0.32</cell><cell cols="2">45.00 128</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Both: Det. &amp; Exp.</cell><cell>76.96</cell><cell>5.17 ↑</cell><cell>0.31</cell><cell>0.29</cell><cell>48.00</cell><cell>99</cell><cell>93</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Both: Default</cell><cell>73.33</cell><cell>0.87 ↑</cell><cell>0.24</cell><cell>0.19</cell><cell>29.00</cell><cell>62</cell><cell>59</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Both: Deterministic</cell><cell>72.79</cell><cell>0.33 ↑</cell><cell>0.08</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Both: Exploratory</cell><cell>73.42</cell><cell>0.96 ↑</cell><cell>0.27</cell><cell>0.23</cell><cell>32.00</cell><cell>91</cell><cell>88</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Both: Det. &amp; Exp.</cell><cell>73.46</cell><cell>1.00 ↑</cell><cell>0.26</cell><cell>0.19</cell><cell>26.00</cell><cell>70</cell><cell>68</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Default</cell><cell>69.62</cell><cell>6.20 ↑</cell><cell>0.60</cell><cell>0.47</cell><cell cols="2">113.00 204</cell><cell></cell></row><row><cell>Phi-mini-3.8B</cell><cell cols="2">Phi-mini-3.8B Both: Deterministic</cell><cell>69.21</cell><cell>5.79 ↑</cell><cell>0.13</cell><cell>0.02</cell><cell>0.00</cell><cell>6</cell><cell>3</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Exploratory</cell><cell>70.38</cell><cell>6.96 ↑</cell><cell>0.67</cell><cell>0.50</cell><cell cols="2">117.00 267</cell><cell></cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Det. &amp; Exp.</cell><cell>69.42</cell><cell>6.00 ↑</cell><cell>0.62</cell><cell>0.45</cell><cell cols="2">114.00 203</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Default</cell><cell>23.42</cell><cell>8.38 ↑</cell><cell>1.91</cell><cell>0.77</cell><cell cols="2">159.00 576</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Deterministic</cell><cell>14.33</cell><cell>0.71 ↓</cell><cell>0.15</cell><cell>0.01</cell><cell>0.00</cell><cell>4</cell><cell>2</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Exploratory</cell><cell>23.29</cell><cell>8.25 ↑</cell><cell>2.13</cell><cell>0.85</cell><cell cols="2">149.00 586</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Det. &amp; Exp.</cell><cell>22.75</cell><cell>7.71 ↑</cell><cell>1.93</cell><cell>0.77</cell><cell cols="2">147.00 556</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Default</cell><cell>51.58</cell><cell>5.91 ↑</cell><cell>1.20</cell><cell>0.82</cell><cell cols="2">232.00 439</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell cols="2">Llama-3.1-3B Both: Deterministic</cell><cell>50.50</cell><cell>4.83 ↑</cell><cell>0.01</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Exploratory</cell><cell>51.12</cell><cell>5.45 ↑</cell><cell>1.47</cell><cell>0.87</cell><cell cols="2">233.00 482</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Det. &amp; Exp.</cell><cell>50.75</cell><cell>5.08 ↑</cell><cell>1.28</cell><cell>0.74</cell><cell cols="2">218.00 381</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Default</cell><cell>62.04</cell><cell>6.42 ↑</cell><cell>0.95</cell><cell>0.72</cell><cell cols="2">202.00 313</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell cols="2">Llama-3.1-8B Both: Deterministic</cell><cell>61.04</cell><cell>5.42 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Exploratory</cell><cell>60.79</cell><cell>5.17 ↑</cell><cell>1.12</cell><cell>0.77</cell><cell cols="2">197.00 340</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Det. &amp; Exp.</cell><cell>60.96</cell><cell>5.34 ↑</cell><cell>1.01</cell><cell>0.72</cell><cell cols="2">214.00 304</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 17 :</head><label>17</label><figDesc>Comparative Analysis of Language Model Performance in Multi-Agent Debate Settings on the GSM-Plus Dataset. This table showcases the impact of different Agent Settings (controlling temperature and top_p parameters like Default, Deterministic, Exploratory, and a combination) on the MAD Accuracy (RCR Prompting) of various language models. The ∆ column quantifies the improvement (or decline) over the single base model performance. Further metrics include average Debate Rounds, normalized Sycophancy (per 2400 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), highlighting the nuanced effects of debate dynamics.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell>Agent Settings</cell><cell>MAD</cell><cell cols="6">∆ Lower ∆ Upper Debate Sycophancy C→I I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Accuracy</cell><cell></cell><cell></cell><cell cols="2">Rounds (Avg / 2400)</cell><cell></cell><cell></cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell></cell><cell></cell><cell></cell><cell>(Overall)</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-1.5B</cell><cell>Both: Default</cell><cell>41.38</cell><cell>16.59 ↑</cell><cell>0.62 ↓</cell><cell>1.85</cell><cell>1.12</cell><cell>314</cell><cell>628</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Both: Deterministic</cell><cell>42.67</cell><cell>17.88 ↑</cell><cell>0.67 ↑</cell><cell>1.58</cell><cell>0.89</cell><cell>292</cell><cell>565</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Both: Exploratory</cell><cell>39.54</cell><cell>14.75 ↑</cell><cell>2.46 ↓</cell><cell>2.30</cell><cell>1.20</cell><cell>320</cell><cell>722</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Both: Det. &amp; Exp.</cell><cell>40.04</cell><cell>15.25 ↑</cell><cell>1.96 ↓</cell><cell>1.97</cell><cell>1.04</cell><cell>301</cell><cell>588</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Both: Exp. &amp; Det.</cell><cell>44.25</cell><cell>19.46 ↑</cell><cell>2.25 ↑</cell><cell>2.00</cell><cell>1.04</cell><cell>278</cell><cell>750</cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Both: Default</cell><cell>54.42</cell><cell>12.42 ↑</cell><cell>8.75 ↑</cell><cell>1.56</cell><cell>0.75</cell><cell>232</cell><cell>612</cell></row><row><cell cols="3">Qwen-2.5-1.5B Llama-3.1-3B Both: Deterministic</cell><cell>54.37</cell><cell>12.37 ↑</cell><cell>8.70 ↑</cell><cell>1.56</cell><cell>0.50</cell><cell>224</cell><cell>489</cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Both: Exploratory</cell><cell>54.21</cell><cell>12.21 ↑</cell><cell>8.54 ↑</cell><cell>1.77</cell><cell>0.89</cell><cell>255</cell><cell>696</cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Both: Det. &amp; Exp.</cell><cell>53.29</cell><cell>11.29 ↑</cell><cell>7.62 ↑</cell><cell>1.65</cell><cell>0.62</cell><cell>249</cell><cell>555</cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Both: Exp. &amp; Det.</cell><cell>54.58</cell><cell>12.58 ↑</cell><cell>8.91 ↑</cell><cell>1.51</cell><cell>0.77</cell><cell>249</cell><cell>603</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Default</cell><cell>70.21</cell><cell>8.46 ↑</cell><cell>6.79 ↑</cell><cell>0.79</cell><cell>0.41</cell><cell>132</cell><cell>304</cell></row><row><cell>Qwen-2.5-3B</cell><cell cols="2">Phi-mini-3.8B Both: Deterministic</cell><cell>69.83</cell><cell>8.08 ↑</cell><cell>6.41 ↑</cell><cell>0.78</cell><cell>0.29</cell><cell>128</cell><cell>224</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Exploratory</cell><cell>69.71</cell><cell>7.96 ↑</cell><cell>6.29 ↑</cell><cell>0.83</cell><cell>0.47</cell><cell>136</cell><cell>339</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Det. &amp; Exp.</cell><cell>69.88</cell><cell>8.13 ↑</cell><cell>6.46 ↑</cell><cell>0.79</cell><cell>0.31</cell><cell>133</cell><cell>241</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Exp. &amp; Det.</cell><cell>70.58</cell><cell>8.83 ↑</cell><cell>7.16 ↑</cell><cell>0.81</cell><cell>0.38</cell><cell>134</cell><cell>307</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Both: Default</cell><cell>63.79</cell><cell>21.79 ↑</cell><cell>2.04 ↑</cell><cell>1.05</cell><cell>0.67</cell><cell>154</cell><cell>573</cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-3B Both: Deterministic</cell><cell>63.92</cell><cell>21.92 ↑</cell><cell>2.17 ↑</cell><cell>0.85</cell><cell>0.60</cell><cell>180</cell><cell>500</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Both: Exploratory</cell><cell>63.79</cell><cell>21.79 ↑</cell><cell>2.04 ↑</cell><cell>1.12</cell><cell>0.76</cell><cell>165</cell><cell>680</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Both: Det. &amp; Exp.</cell><cell>62.58</cell><cell>20.58 ↑</cell><cell>0.83 ↑</cell><cell>1.09</cell><cell>0.61</cell><cell>174</cell><cell>525</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Both: Exp. &amp; Det.</cell><cell>64.25</cell><cell>22.25 ↑</cell><cell>2.50 ↑</cell><cell>1.08</cell><cell>0.68</cell><cell>189</cell><cell>640</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-8B</cell><cell>Both: Default</cell><cell>56.75</cell><cell>11.08 ↑</cell><cell>1.13 ↑</cell><cell>1.29</cell><cell>0.88</cell><cell>264</cell><cell>422</cell></row><row><cell>Llama-3.1-3B</cell><cell cols="2">Llama-3.1-8B Both: Deterministic</cell><cell>57.08</cell><cell>11.41 ↑</cell><cell>1.46 ↑</cell><cell>1.13</cell><cell>0.74</cell><cell>278</cell><cell>348</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-8B</cell><cell>Both: Exploratory</cell><cell>57.17</cell><cell>11.50 ↑</cell><cell>1.55 ↑</cell><cell>1.43</cell><cell>0.89</cell><cell>241</cell><cell>490</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-8B</cell><cell>Both: Det. &amp; Exp.</cell><cell>57.21</cell><cell>11.54 ↑</cell><cell>1.59 ↑</cell><cell>1.27</cell><cell>0.72</cell><cell>259</cell><cell>420</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-8B</cell><cell>Both: Exp. &amp; Det.</cell><cell>56.67</cell><cell>11.00 ↑</cell><cell>1.05 ↑</cell><cell>1.27</cell><cell>0.80</cell><cell>298</cell><cell>411</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-14B</cell><cell>Both: Default</cell><cell>75.88</cell><cell>7.26 ↑</cell><cell>4.09 ↑</cell><cell>0.38</cell><cell>0.28</cell><cell>88</cell><cell>165</cell></row><row><cell>Qwen-2.5-7B</cell><cell cols="2">Qwen-2.5-14B Both: Deterministic</cell><cell>75.54</cell><cell>6.92 ↑</cell><cell>3.75 ↑</cell><cell>0.32</cell><cell>0.24</cell><cell>83</cell><cell>119</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-14B</cell><cell>Both: Exploratory</cell><cell>75.08</cell><cell>6.46 ↑</cell><cell>3.29 ↑</cell><cell>0.39</cell><cell>0.30</cell><cell>111</cell><cell>168</cell></row><row><cell>Qwen-2.5-7B</cell><cell cols="2">Qwen-2.5-14B Both: Det. &amp; Exp.</cell><cell>76.12</cell><cell>7.50 ↑</cell><cell>4.33 ↑</cell><cell>0.36</cell><cell>0.25</cell><cell>92</cell><cell>155</cell></row><row><cell>Qwen-2.5-7B</cell><cell cols="2">Qwen-2.5-14B Both: Exp. &amp; Det.</cell><cell>76.33</cell><cell>7.71 ↑</cell><cell>4.54 ↑</cell><cell>0.35</cell><cell>0.31</cell><cell>78</cell><cell>143</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head>Table 18 :</head><label>18</label><figDesc>Comparative Analysis of Mixed-Model Performance in Multi-Agent Debate Settings on the GSM-Plus Dataset. This table showcases the impact of different Agent Settings on the MAD Accuracy when pairing different language models together. The ∆ Lower and ∆ Upper columns quantify the improvement (or decline) over each individual model's base performance. Further metrics include average Debate Rounds, normalized Sycophancy (per 2400 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), highlighting the dynamics when models of different capabilities debate together.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell>Agent 3</cell><cell>Agent Settings Accuracy</cell><cell>∆</cell><cell>Debate Sycophancy C→I I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Rounds (Avg / 2400)</cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell>(Overall)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_29"><head>Table 19 :</head><label>19</label><figDesc>Comparative Analysis of Language Model Performance in Multi-Agent Debate Settings on the GSM-Plus Dataset. This table showcases the impact of different Agent Settings (controlling temperature and top_p parameters like Default, Deterministic, Exploratory, and combinations) on the Accuracy of various language models in three-agent configurations. The ∆ column quantifies the improvement (or decline) over the single base model performance. Further metrics include average Debate Rounds, normalized Sycophancy (per 2400 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), highlighting the nuanced effects of debate dynamics.</figDesc><table><row><cell></cell><cell></cell><cell>5-1.5B</cell><cell>Exploratory</cell><cell>53.33</cell><cell>11.33 ↑</cell><cell>2.24</cell><cell>2.74</cell><cell cols="2">357 1159</cell><cell></cell></row><row><cell cols="4">Qwen-2.5-1.5B Qwen-2.5-1.5B Qwen-2.5-1.5B 1 Det. &amp; 2 Exp.</cell><cell>53.67</cell><cell>11.67 ↑</cell><cell>2.03</cell><cell>2.35</cell><cell cols="2">394 1116</cell><cell></cell></row><row><cell cols="4">Qwen-2.5-1.5B Qwen-2.5-1.5B Qwen-2.5-1.5B 2 Det. &amp; 1 Exp.</cell><cell>53.17</cell><cell>11.17 ↑</cell><cell>1.31</cell><cell>1.41</cell><cell>265</cell><cell>793</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Default</cell><cell>67.38</cell><cell>5.63 ↑</cell><cell>0.97</cell><cell>1.01</cell><cell>273</cell><cell>423</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Deterministic</cell><cell>67.38</cell><cell>5.63 ↑</cell><cell>0.05</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Exploratory</cell><cell>68.00</cell><cell>6.25 ↑</cell><cell>1.09</cell><cell>1.12</cell><cell>223</cell><cell>537</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell cols="2">Qwen-2.5-3B 1 Det. &amp; 2 Exp.</cell><cell>68.54</cell><cell>6.79 ↑</cell><cell>1.08</cell><cell>0.94</cell><cell>235</cell><cell>428</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell cols="2">Qwen-2.5-3B 2 Det. &amp; 1 Exp.</cell><cell>67.12</cell><cell>5.37 ↑</cell><cell>0.78</cell><cell>0.61</cell><cell>202</cell><cell>274</cell><cell></cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Default</cell><cell>75.79</cell><cell>7.17 ↑</cell><cell>0.51</cell><cell>0.52</cell><cell>84</cell><cell>272</cell><cell></cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Deterministic</cell><cell>73.62</cell><cell>5.00 ↑</cell><cell>0.04</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Exploratory</cell><cell>74.96</cell><cell>6.34 ↑</cell><cell>0.55</cell><cell>0.54</cell><cell>117</cell><cell>270</cell><cell></cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell cols="2">Qwen-2.5-7B 1 Det. &amp; 2 Exp.</cell><cell>75.25</cell><cell>6.63 ↑</cell><cell>0.50</cell><cell>0.50</cell><cell>120</cell><cell>267</cell><cell></cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell cols="2">Qwen-2.5-7B 2 Det. &amp; 1 Exp.</cell><cell>74.42</cell><cell>5.80 ↑</cell><cell>0.39</cell><cell>0.39</cell><cell>97</cell><cell>181</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Default</cell><cell>77.92</cell><cell>6.13 ↑</cell><cell>0.35</cell><cell>0.35</cell><cell>55</cell><cell>166</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Deterministic</cell><cell>76.54</cell><cell>4.75 ↑</cell><cell>0.05</cell><cell>0.00</cell><cell>0</cell><cell>3</cell><cell>1</cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Exploratory</cell><cell>77.29</cell><cell>5.50 ↑</cell><cell>0.38</cell><cell>0.40</cell><cell>69</cell><cell>188</cell><cell></cell></row><row><cell cols="4">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B 1 Det. &amp; 2 Exp.</cell><cell>77.21</cell><cell>5.42 ↑</cell><cell>0.38</cell><cell>0.37</cell><cell>72</cell><cell>172</cell><cell></cell></row><row><cell cols="4">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B 2 Det. &amp; 1 Exp.</cell><cell>77.21</cell><cell>5.42 ↑</cell><cell>0.28</cell><cell>0.25</cell><cell>48</cell><cell>105</cell><cell>81</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Default</cell><cell>73.46</cell><cell>1.00 ↑</cell><cell>0.29</cell><cell>0.23</cell><cell>48</cell><cell>112</cell><cell>96</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Deterministic</cell><cell>72.79</cell><cell>0.33 ↑</cell><cell>0.08</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Exploratory</cell><cell>73.46</cell><cell>1.00 ↑</cell><cell>0.33</cell><cell>0.31</cell><cell>46</cell><cell>123</cell><cell></cell></row><row><cell cols="4">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B 1 Det. &amp; 2 Exp.</cell><cell>73.88</cell><cell>1.42 ↑</cell><cell>0.29</cell><cell>0.23</cell><cell>42</cell><cell>131</cell><cell></cell></row><row><cell cols="4">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B 2 Det. &amp; 1 Exp.</cell><cell>73.12</cell><cell>0.66 ↑</cell><cell>0.24</cell><cell>0.17</cell><cell>40</cell><cell>75</cell><cell>60</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Default</cell><cell>70.21</cell><cell>6.79 ↑</cell><cell>0.90</cell><cell>1.12</cell><cell>226</cell><cell>389</cell><cell></cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Deterministic</cell><cell>69.17</cell><cell>5.75 ↑</cell><cell>0.12</cell><cell>0.04</cell><cell>0</cell><cell>3</cell><cell>1</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Exploratory</cell><cell>70.25</cell><cell>6.83 ↑</cell><cell>0.95</cell><cell>1.11</cell><cell>219</cell><cell>423</cell><cell></cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell cols="2">Phi-mini-3.8B 1 Det. &amp; 2 Exp.</cell><cell>69.83</cell><cell>6.41 ↑</cell><cell>0.93</cell><cell>1.02</cell><cell>232</cell><cell>390</cell><cell></cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell cols="2">Phi-mini-3.8B 2 Det. &amp; 1 Exp.</cell><cell>69.54</cell><cell>6.12 ↑</cell><cell>0.73</cell><cell>0.81</cell><cell>191</cell><cell>292</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Default</cell><cell>24.04</cell><cell>8.99 ↑</cell><cell>2.75</cell><cell>2.12</cell><cell>312</cell><cell>979</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Deterministic</cell><cell>14.37</cell><cell>0.67 ↓</cell><cell>0.15</cell><cell>0.02</cell><cell>0</cell><cell>8</cell><cell>3</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Exploratory</cell><cell>27.04</cell><cell>12.00 ↑</cell><cell>3.03</cell><cell>2.49</cell><cell cols="2">325 1234</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>23.92</cell><cell>8.88 ↑</cell><cell>2.90</cell><cell>2.25</cell><cell cols="2">349 1046</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>23.00</cell><cell>7.96 ↑</cell><cell>2.16</cell><cell>1.55</cell><cell>232</cell><cell>855</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Default</cell><cell>51.54</cell><cell>5.87 ↑</cell><cell>1.89</cell><cell>1.93</cell><cell>454</cell><cell>733</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Deterministic</cell><cell>50.67</cell><cell>5.00 ↑</cell><cell>0.01</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Exploratory</cell><cell>50.71</cell><cell>5.04 ↑</cell><cell>2.26</cell><cell>2.12</cell><cell>520</cell><cell>857</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell cols="2">Llama-3.1-3B 1 Det. &amp; 2 Exp.</cell><cell>50.17</cell><cell>4.50 ↑</cell><cell>2.12</cell><cell>1.96</cell><cell>515</cell><cell>744</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell cols="2">Llama-3.1-3B 2 Det. &amp; 1 Exp.</cell><cell>51.33</cell><cell>5.66 ↑</cell><cell>1.50</cell><cell>1.23</cell><cell>309</cell><cell>493</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Default</cell><cell>62.67</cell><cell>7.05 ↑</cell><cell>1.43</cell><cell>1.60</cell><cell>345</cell><cell>572</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Deterministic</cell><cell>61.04</cell><cell>5.42 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Exploratory</cell><cell>61.08</cell><cell>5.46 ↑</cell><cell>1.69</cell><cell>1.85</cell><cell>385</cell><cell>624</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell cols="2">Llama-3.1-8B 1 Det. &amp; 2 Exp.</cell><cell>62.12</cell><cell>6.50 ↑</cell><cell>1.51</cell><cell>1.64</cell><cell>374</cell><cell>588</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell cols="2">Llama-3.1-8B 2 Det. &amp; 1 Exp.</cell><cell>61.12</cell><cell>5.50 ↑</cell><cell>1.20</cell><cell>1.20</cell><cell>335</cell><cell>414</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_30"><head>Table 20 :</head><label>20</label><figDesc>Comparative Analysis of Mixed Multi-Agent Debate Settings on the GSM-Plus Dataset. This table examines performance when combining different language models in three-agent debate configurations. The first section shows combinations of three different models, while the second section explores configurations with duplicate models. The ∆ column indicates performance changes relative to the best single model in each combination, with improvements in green and declines in red. Metrics include Debate Rounds, normalized Sycophancy (per 2400 data points), and transitions between states (C→I, I→C).</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell cols="2">Agent Settings Accuracy</cell><cell>∆</cell><cell cols="3">Debate Sycophancy C→I I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rounds (Avg / 2376)</cell><cell></cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell></cell><cell></cell><cell>(Overall)</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-0.5B</cell><cell>Default</cell><cell>52.90</cell><cell>1.73 ↓</cell><cell>1.15</cell><cell>0.99</cell><cell>460.00</cell><cell>482</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Deterministic</cell><cell>53.24</cell><cell>1.39 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-0.5B</cell><cell>Exploratory</cell><cell>49.07</cell><cell>5.56 ↓</cell><cell>1.46</cell><cell>1.09</cell><cell>558.00</cell><cell>530</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-0.5B</cell><cell>Det. &amp; Exp.</cell><cell>52.99</cell><cell>1.64 ↓</cell><cell>1.15</cell><cell>0.97</cell><cell>426.00</cell><cell>516</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>Default</cell><cell>86.15</cell><cell>0.47 ↓</cell><cell>0.38</cell><cell>0.38</cell><cell>130.00</cell><cell>403</cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-1.5B Deterministic</cell><cell>84.60</cell><cell>2.02 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>Exploratory</cell><cell>83.42</cell><cell>3.20 ↓</cell><cell>0.55</cell><cell>0.55</cell><cell>160.00</cell><cell>547</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>Det. &amp; Exp.</cell><cell>86.62</cell><cell>0.00</cell><cell>0.41</cell><cell>0.42</cell><cell>135.00</cell><cell>434</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Default</cell><cell>94.02</cell><cell>0.96 ↑</cell><cell>0.14</cell><cell>0.13</cell><cell>56.00</cell><cell>114</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Deterministic</cell><cell>93.35</cell><cell>0.29 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Exploratory</cell><cell>94.15</cell><cell>1.09 ↑</cell><cell>0.16</cell><cell>0.15</cell><cell>49.00</cell><cell>157</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Det. &amp; Exp.</cell><cell>94.07</cell><cell>1.01 ↑</cell><cell>0.15</cell><cell>0.13</cell><cell>70.00</cell><cell>124</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Default</cell><cell>96.17</cell><cell>1.48 ↑</cell><cell>0.05</cell><cell>0.05</cell><cell>31.00 39</cell><cell>37</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Deterministic</cell><cell>96.55</cell><cell>1.86 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Exploratory</cell><cell>96.93</cell><cell>2.24 ↑</cell><cell>0.05</cell><cell>0.05</cell><cell>21.00 57</cell><cell>53</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Det. &amp; Exp.</cell><cell>96.46</cell><cell>1.77 ↑</cell><cell>0.05</cell><cell>0.04</cell><cell>30.00 35</cell><cell>34</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Default</cell><cell>98.19</cell><cell>2.53 ↑</cell><cell>0.03</cell><cell>0.02</cell><cell>15.00 21</cell><cell>21</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Deterministic</cell><cell>97.77</cell><cell>2.11 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Exploratory</cell><cell>98.15</cell><cell>2.49 ↑</cell><cell>0.02</cell><cell>0.02</cell><cell>8.00 20</cell><cell>20</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Det. &amp; Exp.</cell><cell>97.94</cell><cell>2.28 ↑</cell><cell>0.03</cell><cell>0.02</cell><cell>16.00 24</cell><cell>24</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Default</cell><cell>98.53</cell><cell>0.21 ↑</cell><cell>0.02</cell><cell>0.03</cell><cell>10.00 14</cell><cell>13</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Deterministic</cell><cell>98.36</cell><cell>0.04 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Exploratory</cell><cell>98.53</cell><cell>0.21 ↑</cell><cell>0.02</cell><cell>0.03</cell><cell>8.00 14</cell><cell>14</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Det. &amp; Exp.</cell><cell>98.36</cell><cell>0.04 ↑</cell><cell>0.02</cell><cell>0.02</cell><cell>9.00 10</cell><cell>8</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Default</cell><cell>95.88</cell><cell>3.92 ↑</cell><cell>0.11</cell><cell>0.16</cell><cell>40.00 71</cell><cell>60</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Deterministic</cell><cell>95.37</cell><cell>3.41 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Exploratory</cell><cell>94.74</cell><cell>2.78 ↑</cell><cell>0.16</cell><cell>0.21</cell><cell>59.00</cell><cell>116</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Det. &amp; Exp.</cell><cell>94.95</cell><cell>2.99 ↑</cell><cell>0.14</cell><cell>0.19</cell><cell>56.00 89</cell><cell>78</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Default</cell><cell>81.06</cell><cell>0.04 ↑</cell><cell>0.35</cell><cell>0.28</cell><cell>158.00</cell><cell>219</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Deterministic</cell><cell>80.43</cell><cell>0.59 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Exploratory</cell><cell>80.18</cell><cell>0.84 ↓</cell><cell>0.43</cell><cell>0.32</cell><cell>203.00</cell><cell>251</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Det. &amp; Exp.</cell><cell>82.41</cell><cell>1.39 ↑</cell><cell>0.37</cell><cell>0.27</cell><cell>129.00</cell><cell>235</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Default</cell><cell>87.71</cell><cell>3.07 ↑</cell><cell>0.26</cell><cell>0.21</cell><cell>128.00</cell><cell>153</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Deterministic</cell><cell>86.66</cell><cell>2.02 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Exploratory</cell><cell>88.09</cell><cell>3.45 ↑</cell><cell>0.28</cell><cell>0.26</cell><cell>118.00</cell><cell>208</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Det. &amp; Exp.</cell><cell>86.91</cell><cell>2.27 ↑</cell><cell>0.28</cell><cell>0.22</cell><cell>127.00</cell><cell>172</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Default</cell><cell>94.44</cell><cell>5.34 ↑</cell><cell>0.11</cell><cell>0.11</cell><cell>54.00 79</cell><cell>75</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Deterministic</cell><cell>93.64</cell><cell>4.54 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00 0</cell><cell>0</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Exploratory</cell><cell>93.60</cell><cell>4.50 ↑</cell><cell>0.15</cell><cell>0.17</cell><cell>60.00</cell><cell>109</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Det. &amp; Exp.</cell><cell>94.53</cell><cell>5.43 ↑</cell><cell>0.12</cell><cell>0.13</cell><cell>54.00 95</cell><cell>93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31"><head>Table 21 :</head><label>21</label><figDesc>Comparative Analysis of Language Model Performance in Multi-Agent Debate Settings on the ARC-Easy Dataset. This table showcases the impact of different Agent Settings (controlling temperature and top_p parameters like Default, Deterministic, Exploratory, and a combination) on the Accuracy of various language models. The ∆ column quantifies the improvement (or decline) over the single base model performance. Further metrics include average Debate Rounds, normalized Sycophancy (per 2376 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), highlighting the nuanced effects of debate dynamics.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell cols="7">Agent Settings Accuracy ∆ Lower ∆ Upper Debate Sycophancy C→I I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rounds (Avg / 2376)</cell><cell></cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell></cell><cell></cell><cell>(Overall)</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-1.5B</cell><cell>Default</cell><cell>76.98</cell><cell>22.35 ↑</cell><cell>9.64 ↓</cell><cell>0.95</cell><cell>0.75</cell><cell>262.00 804</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Deterministic</cell><cell>79.38</cell><cell>24.75 ↑</cell><cell>7.24 ↓</cell><cell>0.81</cell><cell>0.62</cell><cell>200.00 734</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-1.5B</cell><cell>Exploratory</cell><cell>73.19</cell><cell>18.56 ↑</cell><cell>13.43 ↓</cell><cell>1.16</cell><cell>0.85</cell><cell>300.00 899</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-1.5B</cell><cell>Det. &amp; Exp.</cell><cell>75.21</cell><cell>20.58 ↑</cell><cell>11.41 ↓</cell><cell>0.95</cell><cell>0.78</cell><cell>260.00 846</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-1.5B</cell><cell>Exp. &amp; Det.</cell><cell>77.65</cell><cell>23.02 ↑</cell><cell>8.97 ↓</cell><cell>1.07</cell><cell>0.75</cell><cell>275.00 829</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Default</cell><cell>88.55</cell><cell>1.93 ↑</cell><cell>3.91 ↑</cell><cell>0.40</cell><cell>0.39</cell><cell>146.00 376</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Deterministic</cell><cell>88.13</cell><cell>1.51 ↑</cell><cell>3.49 ↑</cell><cell>0.29</cell><cell>0.24</cell><cell>150.00 242</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Exploratory</cell><cell>88.05</cell><cell>1.43 ↑</cell><cell>3.41 ↑</cell><cell>0.49</cell><cell>0.48</cell><cell>161.00 483</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Det. &amp; Exp.</cell><cell>86.99</cell><cell>0.37 ↑</cell><cell>1.35 ↑</cell><cell>0.37</cell><cell>0.39</cell><cell>172.00 290</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Exp. &amp; Det.</cell><cell>87.71</cell><cell>1.09 ↑</cell><cell>2.07 ↑</cell><cell>0.45</cell><cell>0.40</cell><cell>165.00 447</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Default</cell><cell>95.24</cell><cell>2.18 ↑</cell><cell>3.28 ↑</cell><cell>0.15</cell><cell>0.14</cell><cell>61.00 135</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Deterministic</cell><cell>94.91</cell><cell>1.85 ↑</cell><cell>2.95 ↑</cell><cell>0.14</cell><cell>0.12</cell><cell>72.00 106</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Exploratory</cell><cell>95.24</cell><cell>2.18 ↑</cell><cell>3.28 ↑</cell><cell>0.17</cell><cell>0.16</cell><cell>57.00 184</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Det. &amp; Exp.</cell><cell>94.91</cell><cell>1.85 ↑</cell><cell>2.95 ↑</cell><cell>0.17</cell><cell>0.15</cell><cell>68.00 148</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Exp. &amp; Det.</cell><cell>95.75</cell><cell>2.69 ↑</cell><cell>3.79 ↑</cell><cell>0.15</cell><cell>0.14</cell><cell>58.00 146</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Default</cell><cell>91.88</cell><cell>5.26 ↑</cell><cell>1.18 ↓</cell><cell>0.33</cell><cell>0.29</cell><cell>112.00 363</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Deterministic</cell><cell>92.59</cell><cell>5.97 ↑</cell><cell>0.47 ↓</cell><cell>0.24</cell><cell>0.23</cell><cell>94.00 263</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Exploratory</cell><cell>91.79</cell><cell>5.17 ↑</cell><cell>1.27 ↓</cell><cell>0.42</cell><cell>0.38</cell><cell>95.00 498</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Det. &amp; Exp.</cell><cell>92.76</cell><cell>6.14 ↑</cell><cell>0.20 ↓</cell><cell>0.27</cell><cell>0.27</cell><cell>81.00 294</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Exp. &amp; Det.</cell><cell>92.51</cell><cell>5.89 ↑</cell><cell>0.45 ↓</cell><cell>0.39</cell><cell>0.32</cell><cell>96.00 469</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-8B</cell><cell>Default</cell><cell>91.79</cell><cell>7.15 ↑</cell><cell>2.69 ↑</cell><cell>0.24</cell><cell>0.22</cell><cell>110.00 184</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-8B</cell><cell>Deterministic</cell><cell>91.12</cell><cell>6.48 ↑</cell><cell>2.02 ↑</cell><cell>0.22</cell><cell>0.16</cell><cell>113.00 138</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-8B</cell><cell>Exploratory</cell><cell>90.61</cell><cell>5.97 ↑</cell><cell>1.51 ↑</cell><cell>0.28</cell><cell>0.27</cell><cell>115.00 202</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-8B</cell><cell>Det. &amp; Exp.</cell><cell>90.99</cell><cell>6.35 ↑</cell><cell>1.89 ↑</cell><cell>0.24</cell><cell>0.18</cell><cell>108.00 152</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-8B</cell><cell>Exp. &amp; Det.</cell><cell>91.96</cell><cell>7.32 ↑</cell><cell>2.86 ↑</cell><cell>0.28</cell><cell>0.26</cell><cell>99.00 229</cell><cell></cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-14B</cell><cell>Default</cell><cell>97.94</cell><cell>3.25 ↑</cell><cell>2.28 ↑</cell><cell>0.05</cell><cell>0.05</cell><cell>21.00 55</cell><cell>55</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-14B</cell><cell>Deterministic</cell><cell>97.64</cell><cell>2.95 ↑</cell><cell>1.98 ↑</cell><cell>0.07</cell><cell>0.04</cell><cell>20.00 48</cell><cell>47</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-14B</cell><cell>Exploratory</cell><cell>97.39</cell><cell>2.70 ↑</cell><cell>1.73 ↑</cell><cell>0.08</cell><cell>0.07</cell><cell>32.00 67</cell><cell>66</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-14B</cell><cell>Det. &amp; Exp.</cell><cell>97.43</cell><cell>2.74 ↑</cell><cell>1.77 ↑</cell><cell>0.06</cell><cell>0.05</cell><cell>33.00 49</cell><cell>48</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-14B</cell><cell>Exp. &amp; Det.</cell><cell>97.47</cell><cell>2.78 ↑</cell><cell>1.81 ↑</cell><cell>0.07</cell><cell>0.04</cell><cell>27.00 49</cell><cell>48</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_32"><head>Table 22 :</head><label>22</label><figDesc>Comparative Analysis of Different Language Model Pairs in Multi-Agent Debate Settings on the ARC-Easy Dataset. This table showcases the impact of different Agent Settings (controlling temperature and top_p parameters) on the Accuracy of various model pairs. The ∆ Lower and ∆ Upper columns quantify the improvement (or decline) over each individual model's single-agent performance. Further metrics include average Debate Rounds, normalized Sycophancy (per 2376 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), highlighting the nuanced effects of debate dynamics between different model pairings.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell>Agent Settings</cell><cell>MAD Accuracy</cell><cell>∆</cell><cell cols="2">Debate Sycophancy</cell><cell>C→I</cell><cell>I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(RCR Prompting)</cell><cell></cell><cell cols="2">Rounds (Avg / 2376)</cell><cell></cell><cell></cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell></cell><cell></cell><cell></cell><cell>(Overall)</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-0.5B</cell><cell>Both: Default</cell><cell>51.30</cell><cell>3.33 ↓</cell><cell>2.18</cell><cell>2.67</cell><cell cols="2">1046.00 990</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Both: Deterministic</cell><cell>53.24</cell><cell>1.39 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Both: Exploratory</cell><cell>46.80</cell><cell>7.83 ↓</cell><cell>2.78</cell><cell>3.22</cell><cell cols="2">1228.00 1099</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-0.5B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>48.99</cell><cell>5.64 ↓</cell><cell>2.47</cell><cell>2.82</cell><cell cols="2">1136.00 1053</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-0.5B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>50.80</cell><cell>3.83 ↓</cell><cell>1.34</cell><cell>1.60</cell><cell cols="2">794.00 793</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>Both: Default</cell><cell>87.37</cell><cell>0.75 ↑</cell><cell>0.63</cell><cell>0.84</cell><cell cols="2">232.00 717</cell><cell></cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-1.5B Both: Deterministic</cell><cell>84.60</cell><cell>2.02 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="3">Qwen-2.5-1.5B Qwen-2.5-1.5B Both: Exploratory</cell><cell>85.61</cell><cell>1.01 ↓</cell><cell>0.90</cell><cell>1.17</cell><cell cols="2">279.00 1011</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>86.32</cell><cell>0.30 ↓</cell><cell>0.76</cell><cell>0.98</cell><cell cols="2">275.00 834</cell><cell></cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>86.53</cell><cell>0.09 ↓</cell><cell>0.43</cell><cell>0.62</cell><cell cols="2">198.00 587</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Both: Default</cell><cell>94.87</cell><cell>1.81 ↑</cell><cell>0.19</cell><cell>0.19</cell><cell cols="2">80.00 196</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell cols="2">Qwen-2.5-3B Both: Deterministic</cell><cell>93.35</cell><cell>0.29 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Both: Exploratory</cell><cell>94.28</cell><cell>1.22 ↑</cell><cell>0.25</cell><cell>0.28</cell><cell cols="2">102.00 252</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>94.70</cell><cell>1.64 ↑</cell><cell>0.25</cell><cell>0.23</cell><cell cols="2">90.00 238</cell><cell></cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>93.94</cell><cell>0.88 ↑</cell><cell>0.20</cell><cell>0.18</cell><cell cols="2">94.00 162</cell><cell></cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Default</cell><cell>96.21</cell><cell>1.52 ↑</cell><cell>0.08</cell><cell>0.08</cell><cell>53.00</cell><cell>69</cell><cell>58</cell></row><row><cell>Qwen-2.5-7B</cell><cell cols="2">Qwen-2.5-7B Both: Deterministic</cell><cell>96.17</cell><cell>1.48 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Exploratory</cell><cell>96.55</cell><cell>1.86 ↑</cell><cell>0.10</cell><cell>0.11</cell><cell>57.00</cell><cell>86</cell><cell>71</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>96.55</cell><cell>1.86 ↑</cell><cell>0.10</cell><cell>0.11</cell><cell>56.00</cell><cell>78</cell><cell>65</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>96.34</cell><cell>1.65 ↑</cell><cell>0.07</cell><cell>0.07</cell><cell>39.00</cell><cell>56</cell><cell>40</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Both: Default</cell><cell>98.15</cell><cell>2.49 ↑</cell><cell>0.04</cell><cell>0.04</cell><cell>23.00</cell><cell>29</cell><cell>26</cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Both: Deterministic</cell><cell>97.77</cell><cell>2.11 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Both: Exploratory</cell><cell>98.19</cell><cell>2.53 ↑</cell><cell>0.04</cell><cell>0.05</cell><cell>18.00</cell><cell>40</cell><cell>36</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>98.02</cell><cell>2.36 ↑</cell><cell>0.03</cell><cell>0.04</cell><cell>28.00</cell><cell>40</cell><cell>31</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>97.81</cell><cell>2.15 ↑</cell><cell>0.03</cell><cell>0.03</cell><cell>23.00</cell><cell>28</cell><cell>25</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Both: Default</cell><cell>98.57</cell><cell>0.25 ↑</cell><cell>0.02</cell><cell>0.03</cell><cell>16.00</cell><cell>15</cell><cell>13</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Both: Deterministic</cell><cell>98.36</cell><cell>0.04 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Both: Exploratory</cell><cell>98.48</cell><cell>0.16 ↑</cell><cell>0.02</cell><cell>0.02</cell><cell>15.00</cell><cell>14</cell><cell>14</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>98.48</cell><cell>0.16 ↑</cell><cell>0.02</cell><cell>0.03</cell><cell>16.00</cell><cell>15</cell><cell>12</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>98.32</cell><cell>0.00</cell><cell>0.01</cell><cell>0.02</cell><cell>12.00</cell><cell>9</cell><cell>6</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Default</cell><cell>95.79</cell><cell>3.83 ↑</cell><cell>0.16</cell><cell>0.28</cell><cell cols="2">79.00 138</cell><cell></cell></row><row><cell>Phi-mini-3.8B</cell><cell cols="2">Phi-mini-3.8B Both: Deterministic</cell><cell>95.37</cell><cell>3.41 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Exploratory</cell><cell>94.91</cell><cell>2.95 ↑</cell><cell>0.28</cell><cell>0.43</cell><cell cols="2">110.00 234</cell><cell></cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>96.34</cell><cell>4.38 ↑</cell><cell>0.18</cell><cell>0.27</cell><cell cols="2">70.00 189</cell><cell></cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>95.92</cell><cell>3.96 ↑</cell><cell>0.13</cell><cell>0.24</cell><cell cols="2">53.00 115</cell><cell>83</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Default</cell><cell>87.33</cell><cell>2.69 ↑</cell><cell>0.46</cell><cell>0.44</cell><cell cols="2">252.00 292</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell cols="2">Llama-3.1-3B Both: Deterministic</cell><cell>87.63</cell><cell>2.99 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Exploratory</cell><cell>87.71</cell><cell>3.07 ↑</cell><cell>0.58</cell><cell>0.61</cell><cell cols="2">255.00 415</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>87.58</cell><cell>2.94 ↑</cell><cell>0.53</cell><cell>0.48</cell><cell cols="2">241.00 328</cell><cell></cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>88.47</cell><cell>3.83 ↑</cell><cell>0.32</cell><cell>0.27</cell><cell cols="2">148.00 236</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Default</cell><cell>93.86</cell><cell>4.76 ↑</cell><cell>0.20</cell><cell>0.26</cell><cell cols="2">114.00 139</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell cols="2">Llama-3.1-8B Both: Deterministic</cell><cell>93.64</cell><cell>4.54 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Exploratory</cell><cell>94.19</cell><cell>5.09 ↑</cell><cell>0.25</cell><cell>0.36</cell><cell cols="2">130.00 190</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>94.11</cell><cell>5.01 ↑</cell><cell>0.23</cell><cell>0.33</cell><cell cols="2">119.00 185</cell><cell></cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>94.49</cell><cell>5.39 ↑</cell><cell>0.14</cell><cell>0.20</cell><cell cols="2">69.00 139</cell><cell>89</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Default</cell><cell>82.20</cell><cell>1.18 ↑</cell><cell>0.69</cell><cell>0.71</cell><cell cols="2">318.00 469</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Deterministic</cell><cell>80.43</cell><cell>0.59 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Exploratory</cell><cell>82.66</cell><cell>1.64 ↑</cell><cell>0.83</cell><cell>0.88</cell><cell cols="2">325.00 566</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>82.37</cell><cell>1.35 ↑</cell><cell>0.78</cell><cell>0.81</cell><cell cols="2">324.00 506</cell><cell></cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>81.69</cell><cell>0.67 ↑</cell><cell>0.47</cell><cell>0.51</cell><cell cols="2">230.00 346</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_33"><head>Table 23 :</head><label>23</label><figDesc>Comparative Analysis of Language Model Performance in Multi-Agent Debate Settings on the ARC-Easy Dataset. This table showcases the impact of different Agent Settings (controlling temperature and top_p parameters like Default, Deterministic, Exploratory, and combinations) on the MAD Accuracy (RCR Prompting) of various language models. The ∆ column quantifies the improvement (or decline) over the single base model performance. Further metrics include average Debate Rounds, normalized Sycophancy (per 2376 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), highlighting the nuanced effects of debate dynamics.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell>Agent 3</cell><cell>MAD Accuracy</cell><cell>∆</cell><cell cols="3">Debate Sycophancy C→I I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(RCR Prompting)</cell><cell></cell><cell cols="2">Rounds (Avg / 2376)</cell><cell></cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell></cell><cell></cell><cell>(Overall)</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>92.72</cell><cell>0.34 ↓</cell><cell>1.00</cell><cell>0.95</cell><cell>145 1377</cell><cell>1153</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>84.64</cell><cell>0.00</cell><cell>1.18</cell><cell>1.27</cell><cell>387 1223</cell><cell>1006</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Phi-mini-3.8B</cell><cell>92.93</cell><cell>0.97 ↑</cell><cell>1.03</cell><cell>1.04</cell><cell>184 1379</cell><cell>1156</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-3B</cell><cell>Llama-3.1-3B</cell><cell>91.20</cell><cell>1.86 ↓</cell><cell>1.13</cell><cell>0.99</cell><cell>213 1221</cell><cell>1070</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>89.48</cell><cell>3.58 ↓</cell><cell>1.09</cell><cell>1.12</cell><cell>299 1157</cell><cell>1024</cell></row><row><cell cols="2">Qwen-2.5-0.5B Llama-3.1-3B</cell><cell>Phi-mini-3.8B</cell><cell>91.79</cell><cell>0.17 ↓</cell><cell>0.58</cell><cell>0.72</cell><cell>238</cell><cell>479</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Llama-3.1-3B</cell><cell>91.84</cell><cell>1.22 ↓</cell><cell>0.56</cell><cell>0.60</cell><cell>189</cell><cell>479</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>95.54</cell><cell>2.48 ↑</cell><cell>0.39</cell><cell>0.45</cell><cell>103</cell><cell>449</cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Phi-mini-3.8B</cell><cell>91.79</cell><cell>0.17 ↓</cell><cell>0.58</cell><cell>0.72</cell><cell>238</cell><cell>479</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Llama-3.1-3B</cell><cell>94.07</cell><cell>1.01 ↑</cell><cell>0.41</cell><cell>0.43</cell><cell>162</cell><cell>283</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>95.88</cell><cell>2.82 ↑</cell><cell>0.26</cell><cell>0.26</cell><cell>86</cell><cell>214</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>96.34</cell><cell>3.28 ↑</cell><cell>0.26</cell><cell>0.31</cell><cell>71</cell><cell>180</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>84.64</cell><cell>2.00 ↓</cell><cell>1.22</cell><cell>1.22</cell><cell>300 1229</cell><cell>1012</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-1.5B</cell><cell>72.43</cell><cell>14.19 ↓</cell><cell>1.86</cell><cell>2.11</cell><cell>616 1400</cell><cell>982</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_34"><head>Table 24 :</head><label>24</label><figDesc>Comparative Analysis of Multi-Model Combinations in Agent Debate Settings on the ARC-Easy Dataset. This table showcases the performance of heterogeneous agent teams consisting of different language models. The MAD Accuracy (RCR Prompting) reflects the team performance, while the ∆ column quantifies the improvement (or decline) relative to the best single model in each combination. Additional metrics include average Debate Rounds, normalized Sycophancy (per 2376 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), revealing how diverse model combinations affect debate dynamics and overall helpfulness.</figDesc><table><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Default</cell><cell>91.55</cell><cell>4.33 ↑</cell><cell>0.11</cell><cell>0.11</cell><cell>29.00</cell><cell></cell><cell>45</cell></row><row><cell>Qwen-2.5-7B</cell><cell cols="2">Qwen-2.5-7B Both: Deterministic</cell><cell>91.21</cell><cell>3.99 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Exploratory</cell><cell>91.64</cell><cell>4.42 ↑</cell><cell>0.12</cell><cell>0.11</cell><cell>23.00</cell><cell></cell><cell>51</cell></row><row><cell>Qwen-2.5-7B</cell><cell>Qwen-2.5-7B</cell><cell>Both: Det. &amp; Exp.</cell><cell>92.06</cell><cell>4.84 ↑</cell><cell>0.13</cell><cell>0.12</cell><cell>30.00</cell><cell></cell><cell>43</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Both: Default</cell><cell>94.54</cell><cell>4.27 ↑</cell><cell>0.06</cell><cell>0.05</cell><cell>13.00</cell><cell></cell><cell>24</cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Both: Deterministic</cell><cell>94.37</cell><cell>4.10 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Both: Exploratory</cell><cell>93.77</cell><cell>3.50 ↑</cell><cell>0.06</cell><cell>0.07</cell><cell>23.00</cell><cell></cell><cell>24</cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Both: Det. &amp; Exp.</cell><cell>94.71</cell><cell>4.44 ↑</cell><cell>0.06</cell><cell>0.06</cell><cell>11.00</cell><cell></cell><cell>21</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Both: Default</cell><cell>98.53</cell><cell>3.25 ↑</cell><cell>0.02</cell><cell>0.06</cell><cell>10.00</cell><cell></cell><cell>13</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Both: Deterministic</cell><cell>98.36</cell><cell>3.08 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Both: Exploratory</cell><cell>98.53</cell><cell>3.25 ↑</cell><cell>0.02</cell><cell>0.06</cell><cell>8.00</cell><cell></cell><cell>14</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Both: Det. &amp; Exp.</cell><cell>98.36</cell><cell>3.08 ↑</cell><cell>0.02</cell><cell>0.04</cell><cell>9.00</cell><cell></cell><cell>8</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Default</cell><cell>90.10</cell><cell>5.37 ↑</cell><cell>0.24</cell><cell>0.34</cell><cell>42.00</cell><cell></cell><cell>66</cell></row><row><cell>Phi-mini-3.8B</cell><cell cols="2">Phi-mini-3.8B Both: Deterministic</cell><cell>88.91</cell><cell>4.18 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Exploratory</cell><cell>87.03</cell><cell>2.30 ↑</cell><cell>0.31</cell><cell>0.40</cell><cell cols="2">58.00 107</cell><cell>100</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Both: Det. &amp; Exp.</cell><cell>88.05</cell><cell>3.32 ↑</cell><cell>0.23</cell><cell>0.31</cell><cell>46.00</cell><cell></cell><cell>62</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Default</cell><cell>75.77</cell><cell>2.65 ↑</cell><cell>0.46</cell><cell>0.37</cell><cell cols="2">93.00 130</cell><cell>126</cell></row><row><cell>Llama-3.1-3B</cell><cell cols="2">Llama-3.1-3B Both: Deterministic</cell><cell>74.66</cell><cell>1.54 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Exploratory</cell><cell>76.19</cell><cell>3.07 ↑</cell><cell>0.50</cell><cell>0.43</cell><cell cols="2">89.00 166</cell><cell>149</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Both: Det. &amp; Exp.</cell><cell>75.60</cell><cell>2.48 ↑</cell><cell>0.45</cell><cell>0.34</cell><cell cols="2">108.00 129</cell><cell>124</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Default</cell><cell>87.20</cell><cell>9.55 ↑</cell><cell>0.26</cell><cell>0.30</cell><cell>45.00</cell><cell></cell><cell>88</cell></row><row><cell>Llama-3.1-8B</cell><cell cols="2">Llama-3.1-8B Both: Deterministic</cell><cell>85.75</cell><cell>8.10 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Exploratory</cell><cell>85.07</cell><cell>7.42 ↑</cell><cell>0.28</cell><cell>0.32</cell><cell>58.00</cell><cell></cell><cell>94</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Both: Det. &amp; Exp.</cell><cell>86.86</cell><cell>9.21 ↑</cell><cell>0.23</cell><cell>0.27</cell><cell>56.00</cell><cell></cell><cell>80</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Default</cell><cell>70.48</cell><cell>1.71 ↑</cell><cell>0.51</cell><cell>0.37</cell><cell cols="2">99.00 145</cell><cell>137</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Deterministic</cell><cell>68.26</cell><cell>0.51 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Exploratory</cell><cell>72.78</cell><cell>4.01 ↑</cell><cell>0.58</cell><cell>0.44</cell><cell cols="2">106.00 185</cell><cell>177</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Both: Det. &amp; Exp.</cell><cell>70.82</cell><cell>2.05 ↑</cell><cell>0.50</cell><cell>0.34</cell><cell cols="2">84.00 151</cell><cell>142</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_35"><head>Table 25 :</head><label>25</label><figDesc>Comparative Analysis of Language Model Performance in Multi-Agent Debate Settings on the ARC-Challenge Dataset. This table showcases the impact of different Agent Settings (controlling temperature and top_p parameters like Default, Deterministic, Exploratory, and a combination) on the MAD Accuracy of various language models. The ∆ column quantifies the improvement (or decline) over the single base model performance shown in parentheses next to each model name. Further metrics include average Debate Rounds, normalized Sycophancy (per 1172 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), highlighting the nuanced effects of debate dynamics.</figDesc><table><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Default</cell><cell>94.20</cell><cell>3.93 ↑</cell><cell>0.12</cell><cell>0.13</cell><cell>27</cell><cell>54</cell><cell>45</cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Deterministic</cell><cell>94.37</cell><cell>4.10 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="3">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B</cell><cell>Exploratory</cell><cell>94.80</cell><cell>4.53 ↑</cell><cell>0.10</cell><cell>0.12</cell><cell>28</cell><cell>50</cell><cell>39</cell></row><row><cell cols="4">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B 1 Det. &amp; 2 Exp.</cell><cell>94.54</cell><cell>4.27 ↑</cell><cell>0.09</cell><cell>0.09</cell><cell>22</cell><cell>41</cell><cell>33</cell></row><row><cell cols="4">Qwen-2.5-14B Qwen-2.5-14B Qwen-2.5-14B 2 Det. &amp; 1 Exp.</cell><cell>94.71</cell><cell>4.44 ↑</cell><cell>0.06</cell><cell>0.06</cell><cell>10</cell><cell>32</cell><cell>26</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Default</cell><cell>95.82</cell><cell>0.54 ↑</cell><cell>0.07</cell><cell>0.11</cell><cell>22</cell><cell>36</cell><cell>28</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Deterministic</cell><cell>95.73</cell><cell>0.45 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="3">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B</cell><cell>Exploratory</cell><cell>95.56</cell><cell>0.28 ↑</cell><cell>0.08</cell><cell>0.12</cell><cell>28</cell><cell>35</cell><cell>32</cell></row><row><cell cols="4">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B 1 Det. &amp; 2 Exp.</cell><cell>95.56</cell><cell>0.28 ↑</cell><cell>0.07</cell><cell>0.10</cell><cell>30</cell><cell>29</cell><cell>25</cell></row><row><cell cols="4">Qwen-2.5-32B Qwen-2.5-32B Qwen-2.5-32B 2 Det. &amp; 1 Exp.</cell><cell>95.99</cell><cell>0.71 ↑</cell><cell>0.03</cell><cell>0.04</cell><cell>13</cell><cell>18</cell><cell>14</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Default</cell><cell>88.91</cell><cell>4.18 ↑</cell><cell>0.35</cell><cell>0.61</cell><cell>69</cell><cell></cell><cell>104</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Deterministic</cell><cell>88.91</cell><cell>4.18 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>Exploratory</cell><cell>88.74</cell><cell>4.01 ↑</cell><cell>0.50</cell><cell>0.83</cell><cell>85</cell><cell></cell><cell>151</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell cols="2">Phi-mini-3.8B 1 Det. &amp; 2 Exp.</cell><cell>88.74</cell><cell>4.01 ↑</cell><cell>0.37</cell><cell>0.61</cell><cell>74</cell><cell></cell><cell>121</cell></row><row><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell cols="2">Phi-mini-3.8B 2 Det. &amp; 1 Exp.</cell><cell>89.08</cell><cell>4.35 ↑</cell><cell>0.30</cell><cell>0.52</cell><cell>54</cell><cell></cell><cell>81</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Default</cell><cell>75.77</cell><cell>2.65 ↑</cell><cell>0.81</cell><cell>0.80</cell><cell>177</cell><cell></cell><cell>190</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Deterministic</cell><cell>74.83</cell><cell>1.71 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell>Exploratory</cell><cell>75.51</cell><cell>2.39 ↑</cell><cell>0.90</cell><cell>1.00</cell><cell>196</cell><cell></cell><cell>210</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell cols="2">Llama-3.1-3B 1 Det. &amp; 2 Exp.</cell><cell>75.17</cell><cell>2.05 ↑</cell><cell>0.99</cell><cell>0.91</cell><cell>223</cell><cell></cell><cell>192</cell></row><row><cell>Llama-3.1-3B</cell><cell>Llama-3.1-3B</cell><cell cols="2">Llama-3.1-3B 2 Det. &amp; 1 Exp.</cell><cell>75.26</cell><cell>2.14 ↑</cell><cell>0.53</cell><cell>0.43</cell><cell>118</cell><cell></cell><cell>117</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Default</cell><cell>70.73</cell><cell>1.96 ↑</cell><cell>0.97</cell><cell>0.94</cell><cell>213</cell><cell></cell><cell>207</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Deterministic</cell><cell>68.26</cell><cell>0.51 ↓</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Exploratory</cell><cell>71.67</cell><cell>2.90 ↑</cell><cell>1.14</cell><cell>1.20</cell><cell>232</cell><cell></cell><cell>249</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>1 Det. &amp; 2 Exp.</cell><cell>71.25</cell><cell>2.48 ↑</cell><cell>1.03</cell><cell>1.03</cell><cell>209</cell><cell></cell><cell>227</cell></row><row><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>Mistral-7B</cell><cell>2 Det. &amp; 1 Exp.</cell><cell>70.48</cell><cell>1.71 ↑</cell><cell>0.62</cell><cell>0.66</cell><cell>142</cell><cell></cell><cell>136</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Default</cell><cell>87.46</cell><cell>9.81 ↑</cell><cell>0.40</cell><cell>0.56</cell><cell>98</cell><cell></cell><cell>107</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Deterministic</cell><cell>86.43</cell><cell>8.78 ↑</cell><cell>0.00</cell><cell>0.00</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell>Exploratory</cell><cell>86.01</cell><cell>8.36 ↑</cell><cell>0.52</cell><cell>0.77</cell><cell>127</cell><cell></cell><cell>150</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell cols="2">Llama-3.1-8B 1 Det. &amp; 2 Exp.</cell><cell>86.69</cell><cell>9.04 ↑</cell><cell>0.50</cell><cell>0.72</cell><cell>114</cell><cell></cell><cell>128</cell></row><row><cell>Llama-3.1-8B</cell><cell>Llama-3.1-8B</cell><cell cols="2">Llama-3.1-8B 2 Det. &amp; 1 Exp.</cell><cell>85.67</cell><cell>8.02 ↑</cell><cell>0.30</cell><cell>0.46</cell><cell>115</cell><cell></cell><cell>73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_36"><head>Table 27 :</head><label>27</label><figDesc>Comparative Analysis of Language Model Performance in Multi-Agent Debate Settings on the ARC-Challenge Dataset. This table showcases the impact of different Agent Settings (controlling temperature and top_p parameters) on the Accuracy of various language models in a three-agent configuration. The ∆ column quantifies the improvement (or decline) over the single base model performance (shown in parentheses after model names). Further metrics include average Debate Rounds, normalized Sycophancy (per 1172 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C), highlighting the nuanced effects of debate dynamics.</figDesc><table><row><cell>Agent 1</cell><cell>Agent 2</cell><cell>Agent 3</cell><cell>Accuracy</cell><cell>∆</cell><cell cols="3">Debate Sycophancy C→I I→C</cell><cell>Debate</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rounds (Avg / 1172)</cell><cell></cell><cell>Helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Avg)</cell><cell></cell><cell></cell><cell>(Overall)</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>82.59</cell><cell>0.94 ↓</cell><cell>1.41</cell><cell>1.40</cell><cell>148</cell><cell>629</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>68.00</cell><cell>5.12 ↓</cell><cell>1.66</cell><cell>1.85</cell><cell>311</cell><cell>489</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Phi-mini-3.8B</cell><cell>82.76</cell><cell>1.97 ↓</cell><cell>1.48</cell><cell>1.60</cell><cell>170</cell><cell>621</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-3B</cell><cell>Llama-3.1-3B</cell><cell>79.69</cell><cell>3.84 ↓</cell><cell>1.62</cell><cell>1.50</cell><cell>208</cell><cell>581</cell></row><row><cell cols="2">Qwen-2.5-0.5B Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>86.95</cell><cell>2.22 ↑</cell><cell>1.34</cell><cell>1.23</cell><cell>133</cell><cell>631</cell></row><row><cell cols="2">Qwen-2.5-0.5B Llama-3.1-3B</cell><cell>Phi-mini-3.8B</cell><cell>78.41</cell><cell>6.32 ↓</cell><cell>1.54</cell><cell>1.72</cell><cell>238</cell><cell>559</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Llama-3.1-3B</cell><cell>82.34</cell><cell>1.19 ↓</cell><cell>0.98</cell><cell>1.10</cell><cell>180</cell><cell>358</cell></row><row><cell cols="2">Qwen-2.5-1.5B Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>87.37</cell><cell>2.64 ↑</cell><cell>0.71</cell><cell>0.81</cell><cell>105</cell><cell>358</cell></row><row><cell cols="2">Qwen-2.5-1.5B Llama-3.1-3B</cell><cell>Phi-mini-3.8B</cell><cell>81.74</cell><cell>3.00 ↓</cell><cell>0.93</cell><cell>1.19</cell><cell>195</cell><cell>341</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Llama-3.1-3B</cell><cell>85.67</cell><cell>2.14 ↑</cell><cell>0.84</cell><cell>0.89</cell><cell>143</cell><cell>244</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>87.88</cell><cell>3.15 ↑</cell><cell>0.50</cell><cell>0.52</cell><cell>110</cell><cell>170</cell></row><row><cell>Qwen-2.5-3B</cell><cell>Phi-mini-3.8B</cell><cell>Phi-mini-3.8B</cell><cell>89.33</cell><cell>4.60 ↑</cell><cell>0.52</cell><cell>0.61</cell><cell>81</cell><cell>174</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-1.5B Qwen-2.5-1.5B</cell><cell>69.80</cell><cell>0.59 ↑</cell><cell>1.66</cell><cell>1.77</cell><cell>231</cell><cell>523</cell></row><row><cell cols="3">Qwen-2.5-0.5B Qwen-2.5-0.5B Qwen-2.5-1.5B</cell><cell>55.97</cell><cell>13.24 ↓</cell><cell>2.33</cell><cell>2.69</cell><cell>393</cell><cell>451</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_37"><head>Table 28 :</head><label>28</label><figDesc>Analysis of Mixed-Model Configurations in Multi-Agent Debate Settings on the ARC-Challenge Dataset. This table examines various heterogeneous model combinations in three-agent debate setups. The ∆ column quantifies the improvement (or decline) compared to the best single model performance among the three agents used in each configuration. All agent combinations use the default settings for temperature and top_p. Metrics include average Debate Rounds, normalized Sycophancy (per 1172 data points), and transitions between correct (C) and incorrect (I) states (C→I, I→C). Results demonstrate that certain model combinations can achieve higher accuracy than their constituent models when debating together.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_38"><head>Table 35 :</head><label>35</label><figDesc>Performance scaling with increasing numbers of debating agents (1-7) across different model sizes and reasoning benchmarks. Results show accuracy percentages for each configuration.</figDesc><table><row><cell>Model</cell><cell></cell><cell cols="3">Number of Agents</cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell></row><row><cell></cell><cell cols="3">GSM8K Accuracy (%)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://github.com/unslothai/unsloth</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://github.com/huggingface/trl</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://docs.vllm.ai/en/latest/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://github.com/huggingface/accelerate</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by NSF NAIRR Pilot with PSC Neocortex, NCSA Delta; Amazon, Cisco Research, Commonwealth Cyber Initiative, Amazon-Virginia Tech Center for Efficient and Robust Machine Learning, and Sanghani Center for AI and Data Analytics at Virginia Tech. The views, findings, conclusions, and recommendations expressed in this work are those of the authors and do not necessarily reflect the opinions of the funding agencies.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 Original MAD Results</head><p>We also report our experiments with the original Multi-Agent Debate (MAD) framework across various model sizes and architectures. Table <ref type="table">33</ref> presents the results on three challenging reasoning benchmarks: GSM-Plus, GSM8K, and ARC-Challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Majority Vote@3 Results</head><p>To further investigate the impact of stochastic diversity on model performance, we report results on a Majority Vote@3 approach where we sample three independent responses from each model and take a majority vote to determine the final answer. Table <ref type="table">34</ref> presents these results across five benchmarks: GSM8K, GSM-Plus, ARC-Easy, ARC-Challenge, and CommonsenseQA.</p><p>The results demonstrate that simple ensemble-based approaches can significantly boost performance without requiring multi-agent debate or model fine-tuning. Across all model sizes and architectures, Majority Vote@3 consistently outperforms single-sample inference. The relative improvements are most pronounced for smaller models, with Qwen-2.5-0.5B gaining up to 4.27 percentage points on ARC-Challenge and Qwen-2.5-1.5B showing similar substantial improvements across benchmarks.</p><p>Interestingly, this pattern holds across model families. Llama-3.1-3B, Phi-3.5-mini, and Mistral-7B all exhibit significant gains when using majority voting, suggesting that the benefits of ensemble diversity transcend specific model architectures. The results also indicate diminishing returns for larger models-Qwen-2.5-14B shows more modest improvements compared to its smaller counterparts, likely because these larger models already produce more consistent answers across samples.</p><p>These findings highlight an important baseline for our research: simple ensemble methods provide strong performance improvements with minimal computational overhead during inference. However, they still require multiple forward passes for each query, motivating our DTE approach that aims to distill these benefits into a single model through training on debate traces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 Scaling Results for Multiple Agents</head><p>We investigated how performance scales with increasing numbers of debating agents (1-7) across different model sizes and reasoning benchmarks. Table <ref type="table">35</ref> presents these results, revealing several important trends in multi-agent scaling behavior.</p><p>First, we observe that performance generally improves as we add more agents to the debate, but with diminishing returns. The most significant gains occur when moving from a single agent (equivalent to standard inference) to two agents, with more modest improvements as additional agents join the debate. For example, on GSM8K, Qwen-2.5-1.5B shows a substantial jump from 62.77% (1 agent) to 71.57% (2 agents), but only incremental improvements thereafter.</p><p>Second, the benefits of additional agents vary across tasks. On more complex tasks like GSM-Plus, we see continued performance improvements even with 7 agents, particularly for larger models. Qwen-2.5-14B shows its peak GSM-Plus performance with 7 agents (78.08%), suggesting that more difficult problems benefit from extended multi-agent collaboration. In contrast, on simpler tasks like ARC-Easy, performance plateaus more quickly.</p><p>Third, we find that model size influences scaling behavior. Smaller models like Qwen-2.5-1.5B show more variability in performance as agents are added, with occasional performance drops when moving from 3 to 4 agents. Larger models exhibit more stable scaling patterns, suggesting that they can more consistently integrate insights from multiple debate participants.</p><p>These results have important implications for our DTE framework. They demonstrate that while adding more agents generally improves performance, the computational costs may outweigh the benefits beyond 3-5 agents for most applications. This insight helped inform our design choices in balancing performance gains against computational efficiency in our final framework. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<idno>Qwen-2.5-14B 90.27 93.77 94.80 95.14 94.20 94.62 94.28</idno>
		<title level="m">ARC-Easy Accuracy (%)</title>
				<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
