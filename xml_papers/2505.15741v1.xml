<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evolutionary Computation and Large Language Models: A Survey of Methods, Synergies, and Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2025-05-21">21 May 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dikshit</forename><surname>Chauhan</surname></persName>
							<email>dikshitchauhan608@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>119077</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bapi</forename><surname>Dutta</surname></persName>
							<email>bdutta@ujaen.es</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Universidad de Jaén</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Indu</forename><surname>Bala</surname></persName>
							<email>indu.bala@adelaide.edu.au</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer and Mathematical Sciences</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<postCode>5005</postCode>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Niki</forename><surname>Van Stein</surname></persName>
							<email>n.van.stein@liacs.leidenuniv.nl</email>
							<affiliation key="aff3">
								<orgName type="department">Leiden Institute of Advanced Computer Science</orgName>
								<orgName type="institution">University Leiden</orgName>
								<address>
									<settlement>Leiden</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Bäck</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Leiden Institute of Advanced Computer Science</orgName>
								<orgName type="institution">University Leiden</orgName>
								<address>
									<settlement>Leiden</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anupam</forename><surname>Yadav</surname></persName>
							<email>anupam@nitj.ac.in</email>
							<affiliation key="aff4">
								<orgName type="department">Department of Mathematics and Computing</orgName>
								<orgName type="institution">National Institute of Technology</orgName>
								<address>
									<addrLine>Jalandhar -144011</addrLine>
									<country>Dr. B. R. Ambedkar, INDIA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evolutionary Computation and Large Language Models: A Survey of Methods, Synergies, and Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-05-21">21 May 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">9FD09FC8C133C2259CC997518B008BF8</idno>
					<idno type="arXiv">arXiv:2505.15741v1[cs.NE]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2025-05-26T20:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Evolutionary Computation</term>
					<term>Large Language Models</term>
					<term>Optimization</term>
					<term>Metaheuristics</term>
					<term>Co-Evolution</term>
					<term>AI Automation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Integrating Large Language Models (LLMs) and Evolutionary Computation (EC) represents a promising avenue for advancing artificial intelligence by combining powerful natural language understanding with optimization and search capabilities. This manuscript explores the synergistic potential of LLMs and EC, reviewing their intersections, complementary strengths, and emerging applications. We identify key opportunities where EC can enhance LLM training, fine-tuning, prompt engineering, and architecture search, while LLMs can, in turn, aid in automating the design, analysis, and interpretation of ECs. The manuscript explores the synergistic integration of EC and LLMs, highlighting their bidirectional contributions to advancing artificial intelligence. It first examines how EC techniques enhance LLMs by optimizing key components such as prompt engineering, hyperparameter tuning, and architecture search, demonstrating how evolutionary methods automate and refine these processes. Secondly, the survey investigates how LLMs improve EC by automating metaheuristic design, tuning evolutionary algorithms, and generating adaptive heuristics, thereby increasing efficiency and scalability. Emerging co-evolutionary frameworks are discussed, showcasing applications across diverse fields while acknowledging challenges like computational costs, interpretability, and algorithmic convergence. The survey concludes by identifying open research questions and advocating for hybrid approaches that combine the strengths of EC and LLMs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Large Language Models (LLMs) represent a significant advancement in artificial intelligence (AI), demonstrating remarkable capabilities in understanding and generating human-like text <ref type="bibr" target="#b0">[1]</ref>. Built upon deep learning architectures such as transformer networks, these models are trained on vast datasets, enabling them to perform a wide array of Natural Language Processing (NLP) tasks with impressive fluency and coherence <ref type="bibr" target="#b1">[2]</ref>. Their ability to comprehend context, generate structured responses, and learn from few-shot examples has led  DRAFT such as EvoPrompt utilize evolutionary strategies to explore variations in prompts, selecting and evolving those that yield the most effective responses <ref type="bibr" target="#b10">[11]</ref>. By shifting prompt engineering from a manual, trial-anderror approach to an optimization-driven process, EC enables the discovery of highly effective prompts that may not be immediately apparent to human designers <ref type="bibr" target="#b11">[12]</ref>. The integration of LLMs and EC is transforming parameters, and prompts, researchers can enhance model performance while reducing dependence on manual tuning. At the same time, LLMs contribute to EC by improving solution generation, guiding evolutionary search, and refining variation operators. This bidirectional relationship between LLMs and EC highlights the potential for a more automated and intelligent approach to AI-driven optimization. As shown in Fig. <ref type="figure" target="#fig_0">1</ref> and Table <ref type="table">1</ref>, this paper introduces a unique bidirectional framework and feature-based comparison that systematically maps how EC and LLMs mutually enhance each other, an aspect often overlooked or partially covered in previous surveys. As research in this area continues to evolve, the fusion of these paradigms is expected to drive advancements in fields such as natural language processing, scientific discovery, and creative content generation, paving the way for more sophisticated AI-driven problem-solving methodologies.</p><note type="other">DRAFT</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Survey Papers and Differences</head><p>Several recent surveys have explored the intersection between LLMs and algorithmic design, including their role in EC. However, each of these contributions has its own emphasis and limitations: Liu et al. <ref type="bibr" target="#b12">[13]</ref> present a systematic survey on how LLMs contribute to algorithm design (LLM4AD). They classify existing work based on the roles played by LLMs, prompting techniques, and underlying search strategies, with a strong focus on how LLMs can automate and innovate classical algorithm design across optimization, reasoning, and scientific computing tasks. Haleem et al. <ref type="bibr" target="#b13">[14]</ref> provides a high-level overview of ChatGPT's capabilities and limitations, focusing primarily on usability, societal impact, and general features. However, this work lacks a technical framework or a focused discussion on optimization or EC integration. Yu et al. <ref type="bibr" target="#b4">[5]</ref> offers a detailed review of how LLMs contribute specifically to optimization, especially in the context of metaheuristics and evolutionary algorithm design. The paper introduces a dedicated LLM-EA optimization paradigm that incorporates variation operators, fitness evaluation, and prompt-driven search as core components. Wu et al. <ref type="bibr" target="#b6">[7]</ref> present a broad survey on the bidirectional synergy between evolutionary algorithms and LLMs. They categorize existing approaches into LLM-enhanced EC and EC-enhanced LLMs, introduce several hybrid methods, and outline challenges and open directions, serving as a useful roadmap for future research. Cai et al. <ref type="bibr" target="#b14">[15]</ref> concentrate on the enhancement of evolutionary computation using LLMs. Their work discusses new approaches for population initialization and operator design but does not explore how evolutionary methods can, in turn, optimize or support LLMs. Chen et al. <ref type="bibr" target="#b9">[10]</ref> deliver a comprehensive review of prompt engineering DRAFT methods in LLMs, covering techniques such as chain-of-thought (CoT), context optimization (CoOp), and adversarial prompting. While technically detailed, this paper is centered on prompt design and does not address evolutionary algorithms or optimization. Huang et al. <ref type="bibr" target="#b15">[16]</ref> provides a general review of the integration of LLMs with optimization, especially from the perspective of decision-making and modeling. While insightful, their treatment is conceptual and broad, with limited emphasis on evolutionary computation or detailed bidirectional interactions between LLMs and EC.</p><p>While the reviewed papers each address specific facets of the intersection between LLMs and EC, this survey distinguishes itself by offering a unified and explicitly bidirectional perspective on their synergy. Unlike Liu et al. <ref type="bibr" target="#b12">[13]</ref>, which focuses on how LLMs contribute to algorithm design, or Cai et al. <ref type="bibr" target="#b14">[15]</ref>, which explores how LLMs enhance EC techniques, our survey systematically examines both directions of influence. It discusses how LLMs can support EC through operator generation, metaheuristic adaptation, and hyperparameter tuning and, conversely, how EC techniques can be used to improve LLM performance via prompt optimization, architecture search, and fine-tuning.</p><p>Although Wu et al. <ref type="bibr" target="#b6">[7]</ref> offers a valuable roadmap for LLM-EC interactions, our survey extends this effort through the introduction of a structured taxonomy (Figure <ref type="figure" target="#fig_0">1</ref>), which categorizes integration strategies such as LLM-generated metaheuristics, EC-based surrogate modeling, adaptive parameter control, and coevolutionary approaches. A particularly novel contribution of this work is its focus on co-adaptive paradigms, in which LLMs and EC systems evolve together in a feedback loop, promoting mutual adaptation and continual learning, a direction still underrepresented in the literature.</p><p>In addition, we emphasize application-level mapping, linking each integration strategy to real-world domains, and address critical implementation challenges such as scalability, interpretability, and data efficiency. Table <ref type="table" target="#tab_0">2</ref> summarizes these contributions and contrasts our approach with prior work. In contrast to earlier studies that examine either LLM→EC or EC→LLM in isolation, our survey provides a bidirectional framework, proposes a systematic taxonomy, highlights co-adaptive strategies, and explores both practical applications and future research challenges in the integration of LLMs and evolutionary computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Main Contributions</head><p>To the best of our knowledge, this is the first survey that systematically explores the bidirectional synergy between LLMs and EC. The key contributions of this work are summarized as follows:</p><p>(i) Bidirectional Perspective on LLM-EC Synergy: This paper presents a comprehensive, two-way investigation of how LLMs can enhance EC through operator generation, tuning, and metaheuristic design, and how EC can improve LLMs via prompt engineering, architecture optimization, and hyperparameter tuning.</p><p>(ii) Structured Taxonomy and Framework: We suggest a novel taxonomy that systematically categorizes methods, roles, and integration strategies, covering topics such as LLM-generated metaheuristics, surrogate modeling, co-evolutionary systems, and explainable EC, offering readers a unified framework to understand this emerging field.</p><p>(iii) Survey of Emerging Co-Adaptive Paradigms: This work introduces and analyzes new co-adaptive paradigms where LLMs and EC evolve together, including co-evolutionary frameworks, human-in-the-loop systems, and pattern-guided evolutionary search, which are underexplored in previous surveys.</p><p>(iv) Cross-Domain Application Landscape: We review and map the application of LLM-EC synergies across diverse domains such as scientific modeling, optimization, automated design, and decision-support systems, highlighting practical use cases and deployment insights.</p><p>DRAFT </p><formula xml:id="formula_0">✓ ✗ ✓ ✓ ✓ ✓ ✓</formula><p>(v) Identification of Research Gaps and Future Challenges: The survey outlines unresolved challenges, such as scalability, explainability, and benchmark design, and provides a forward-looking research agenda to guide future interdisciplinary work in this field.</p><p>The paper is organized into four main sections. Section 2 focuses on the use of EC to enhance LLMs, including techniques for prompt engineering, architecture search, and hyperparameter tuning. Section 3 explore how LLMs can, in turn, improve EC by automating metaheuristic design, tuning algorithm components, and generating adaptive heuristics. Finally, Section 4 presents emerging frameworks, future research directions, and the open challenges in the synergy between LLMs and EC. The conclusion of this paper is discussed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">EC for LLM Enhancement</head><p>This section explores how EC and related metaheuristic strategies can be utilized to improve LLM performance and adaptability. Applications span from evolving effective prompts (hard and soft) to discovering fine-tuning configurations and hyperparameter sets that yield superior model behavior. By treating LLMs as black-box systems amenable to optimization, EC enables a data-efficient and interpretable approach to aligning LLM outputs with task-specific objectives. As research in this intersection matures, evolutionary strategies are not only serving as tools for LLM enhancement but are also inspiring novel hybrid frameworks where the strengths of both paradigms coalesce, combining the generative fluency of LLMs with the adaptive search power of evolution. The very first focus here will be on prompt engineering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">EC in Prompt Engineering</head><p>Prompt engineering is the systematic process of designing textual inputs, known as prompts, that steer LLMs toward useful, accurate, and context-appropriate responses. Because a model's understanding of a DRAFT Components of a Prompt Instruction Defines the task (e.g., "Summarize this text in one sentence") task depends heavily on the prompt, prompt quality directly affects performance, robustness, and reliability. Unfortunately, crafting effective prompts usually demands substantial human effort, domain expertise, and iterative trial-and-error; this manual process is time-consuming, often sub-optimal, and guided by limited, subjective heuristics <ref type="bibr" target="#b16">[17]</ref>. LLMs are also highly sensitive to phrasing; semantically similar prompts can yield markedly different outputs, so methods for discovering optimal prompts are urgently needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context/Examples</head><p>A typical prompt comprises three primary components, as shown in Figure <ref type="figure" target="#fig_2">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output: Negative</head><p>As the example shows, the model combines the instruction and context to infer that the test input's sentiment is Negative. Articulated instructions reduce ambiguity, boosting clarity and accuracy; explicit examples further condition the model toward the desired behavior <ref type="bibr" target="#b17">[18]</ref>. Moreover, careful optimization of wording and prompt format can lead to considerable improvements in model performance, as even minor adjustments can result in significant changes in responses <ref type="bibr" target="#b18">[19]</ref>.</p><p>Therefore, building on the need for high-quality prompts, researchers have formalized this area of study as Prompt Engineering (PE), the systematic design and optimization of prompts to elicit precise, contextappropriate responses from language models <ref type="bibr" target="#b19">[20]</ref>. A range of prompting techniques has produced notable performance gains. For example, Few-shot prompting provides the model with multiple illustrative examples within a prompt, guiding its responses effectively <ref type="bibr" target="#b20">[21]</ref>. Another notable technique, Chain-of-Thought (CoT) DRAFT prompting, significantly improves the arithmetic and reasoning capabilities of models by explicitly demonstrating reasoning processes through few-shot examples. Similarly, zero-shot-CoT prompting boosts zero-shot performance by simply incorporating prompts such as "Let's think step by step," encouraging systematic reasoning <ref type="bibr" target="#b21">[22]</ref>.</p><p>Moreover, researchers have introduced multi-step prompting strategies, such as generating question-related knowledge statements with one language model and subsequently using those statements as input to another model for improved predictions <ref type="bibr" target="#b22">[23]</ref>. Despite these advancements, current prompt engineering methods predominantly rely on manual design. Manual prompt engineering, however, has critical limitations, including inherent subjectivity, substantial labor requirements, and extensive reliance on trial-and-error <ref type="bibr" target="#b23">[24]</ref>. Humancrafted prompts, while valuable for guiding model learning, may still be suboptimal, as optimal prompt identification through intuition alone remains highly challenging. Additionally, manually designed prompts often do not generalize effectively across diverse tasks or datasets due to the combinatorially expansive nature of the prompt optimization space, making manual exploration impractical <ref type="bibr" target="#b24">[25]</ref>. Addressing these limitations through automated optimization techniques represents an important future direction for research in prompt engineering.</p><p>These shortcomings have motivated researchers to explore automated approaches to prompt engineering, particularly through the utilization of EC. EC is a heuristic optimization method inspired by biological evolution processes, involving mechanisms like selection, crossover, and mutation. EC possesses notable strengths, including robustness, the ability to navigate complex optimization landscapes, and independence from explicit gradient information, making them especially suitable for optimizing prompts <ref type="bibr" target="#b25">[26]</ref>.</p><p>The integration of EC with prompt engineering has led to substantial advancements in optimizing LLMs. EC's search strategies systematically refine prompts, delivering gains across diverse tasks. Because EC operates effectively in both continuous and discrete spaces <ref type="bibr" target="#b25">[26]</ref>, prompt optimization for LLMs naturally splits into two branches: soft-prompt optimization in the continuous embedding space and hard-prompt optimization in the discrete textual space.</p><p>A hard prompt is an explicit, human-readable instruction that steers the model's response. EC refines these textual prompts, adjusting wording, structure, and phrasing, to maximize effectiveness <ref type="bibr" target="#b26">[27]</ref>. For instance, an initial prompt such as "Summarize this article in one paragraph" might evolve into "Write a concise, fivesentence summary highlighting the key points of this article."</p><p>In contrast, soft prompts are latent, continuous embeddings rather than visible text. These prompts are implemented as learned embeddings integrated into the model's input, represented as vectors <ref type="bibr" target="#b27">[28]</ref>. EC optimizes these embeddings by evolving their parameters to improve task performance. For example, instead of directly instructing "Summarize this article," soft prompts employ optimized hidden token embeddings that influence the model's interpretation and steer the responses without explicit linguistic instructions.</p><p>Because EC relies on selection, crossover, and mutation rather than gradients, they handle complex optimization landscapes, continuous, discrete, or hybrid, with ease. Treating sequences of prompt tokens (or embedding dimensions) like genetic material, they can systematically explore and improve both hard and soft prompt spaces while maintaining coherence and, for hard prompts, human readability. A general framework of EC for prompt engineering is presented in Figure <ref type="figure" target="#fig_1">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">EC in hard Prompting</head><p>EC has shown significant potential in optimizing hard prompts for LLMs. H. Xu <ref type="bibr" target="#b28">[29]</ref> introduced Genetic Prompt Search (GPS), a straightforward genetic algorithm method designed specifically for refining few-shot instruction prompts. This approach iteratively applies genetic operations like mutation to tokens within discrete prompts, continuously evaluating and retaining only the best-performing prompts based on task performance. Further contributions include GrIPS (Gradient-free, Edit-based Instruction Search) by A. Prasad <ref type="bibr" target="#b29">[30]</ref>, which, while not strictly a genetic algorithm, uses a similar local-edit approach to generate improved child prompts from parent instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DRAFT</head><p>Building upon this, C.I. Hsieh <ref type="bibr" target="#b30">[31]</ref> extended the GPS concept to longer prompts by incorporating beam search heuristics along with a history buffer mechanism. This strategy maintains contextual consistency across prompt mutations, significantly enhancing the optimization process for lengthy textual prompts.</p><p>Expanding the integration of EC and LLMs further, Guo et al. <ref type="bibr" target="#b31">[32]</ref> developed EvoPrompt, a unique framework where language models themselves serve as evolutionary operators. EvoPrompt enables LLMs to propose new prompt candidates through operations analogous to genetic crossover and mutation, with EC subsequently selecting prompts based on improved development-set performance.</p><p>Moreover, Fernando et al. <ref type="bibr" target="#b32">[33]</ref> presented Promptbreeder, a co-evolutionary approach leveraging evolutionary algorithm principles to simultaneously evolve task-specific prompts and mutation instructions. This dual-evolution strategy enables refined control over how prompts mutate or cross over, guided explicitly by the language model itself.</p><p>Chen et al. <ref type="bibr" target="#b33">[34]</ref>presented EvoPrompting focuses explicitly on Neural Architecture Search (NAS). It uses evolutionary prompting to guide a large language model in generating and refining neural network architectures. EvoPrompting leverages LLMs as adaptive mutation and crossover operators to optimize architectures through evolved textual prompts.</p><p>Additionally, W. Cui <ref type="bibr" target="#b34">[35]</ref> proposed PhaseEvo, a comprehensive multi-phase evolutionary pipeline. PhaseEvo optimizes instructions and exemplar sets simultaneously by alternating refinement processes between textual instructions and selected example subsets, thus integrating the optimization of both prompt elements. Complementing these methods, Chen et al. <ref type="bibr" target="#b35">[36]</ref> introduced Prompt Optimization in Multi-Step Tasks (PROMST), designed specifically for optimizing prompts in multi-step tasks. PROMST uniquely incorporates human-inthe-loop interactions and heuristic models, combining evolutionary sampling methods with direct user feedback to incrementally enhance textual prompts, thereby demonstrating an effective collaborative evolutionary optimization framework.</p><p>Similarly, Baumann and Kramer <ref type="bibr" target="#b36">[37]</ref> introduced EMO-Prompts, an evolutionary multi-objective optimization method tailored explicitly for nuanced tasks such as sentiment analysis. Their approach evolves prompts that enable language models to simultaneously express conflicting emotions, demonstrating the advanced capabilities of evolutionary optimization in achieving complex linguistic objectives.</p><p>Feng et al. <ref type="bibr" target="#b37">[38]</ref>, introduced Genetic Auto Prompt (GenAP), which leverages a genetic algorithm (GA) for optimizing discrete, human-readable textual prompts (hard prompts) without relying on gradient information. GenAP automatically designs discrete prompts by evolving their wording and structure using tailored genetic operators (crossover and mutation) to enhance performance across various code intelligence tasks.</p><p>Similarly, Wong et al. <ref type="bibr" target="#b38">[39]</ref>, presented a framework called Prompt Evolution Design Optimization (PEDO), integrating EC with prompt engineering. The framework iteratively generates and evolves text-based prompts containing user specifications for aerodynamic performance and visual attributes of 3D car designs. Each evolved prompt guides the generation of designs assessed through computational fluid dynamics simulations and evaluated using a vision-language model, which penalizes impractical designs. This combined optimization strategy ensures that user preferences regarding aesthetics and aerodynamic performance are effectively balanced, leading to optimized and practical car designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">EA in Soft Prompting</head><p>Automated soft prompt engineering, commonly referred to as prompt tuning, focuses on optimizing continuous embeddings, known as soft prompts, to effectively guide LLMs. Unlike traditional hard prompt engineering, which depends on discrete, explicit textual instructions, soft prompt engineering involves adjusting learned vector representations integrated directly into the model's embedding space. This approach provides flexibility by fine-tuning continuous prompt parameters rather than fixed textual instructions.</p><p>Most automated soft prompt engineering methods predominantly leverage gradient-based techniques <ref type="bibr" target="#b39">[40]</ref> or reinforcement learning strategies <ref type="bibr" target="#b40">[41]</ref> or sequential optimal learning <ref type="bibr" target="#b41">[42]</ref>. Gradient-based optimization DRAFT directly tunes prompt embeddings through backpropagation, continuously refining embeddings to enhance model responses. Reinforcement learning approaches treat soft prompt optimization as sequential decisionmaking, iteratively adjusting prompt embeddings based on model performance and feedback. Additionally, sequential optimal learning strategies <ref type="bibr" target="#b41">[42]</ref> employ Bayesian regression and the Knowledge-Gradient policy to systematically explore the continuous prompt embedding space and efficiently identify optimal solutions. By contrast, evolutionary computation (EC) has been widely applied to hard-prompt optimization but rarely to soft prompts. A plausible reason is the practical difficulty of mapping EC operators to a high-dimensional, continuous embedding space. Defining meaningful mutation and crossover in thousands of-dimensional vectors without producing degenerate or adversarial embeddings remains non-trivial, and the search space is vast and unstructured compared with discrete token edits. Moreover, each candidate embedding must be evaluated with a forward pass through a large model, so a naïve EC loop can become prohibitively expensive; designing a fitness function that reliably captures subtle quality differences in continuous prompts adds further complexity. These hurdles-search-space definition, operator design, fitness evaluation cost, and interpretability-help explain why EC has so far been under-utilized for soft-prompt tuning. Nevertheless, EC's gradientfree, population-based search is well-suited to non-convex landscapes and could, in principle, evolve softprompt embeddings through selection, crossover, and mutation. Bridging these practical gaps-e.g., via surrogate fitness models, dimensionality-reduction techniques, or hybrid gradient-evolution schemes-represents a promising direction for future automated soft-prompt engineering research. Additionally, systematically exploring diverse evolutionary strategies for continuous-embedding optimization could further overcome current limitations and accelerate progress in automated soft-prompt engineering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">EA Based Prompt Engineering Tools</head><p>This section focuses on three prominent techniques that exemplify the use of evolutionary principles for automatic prompt optimization: EvoPrompt <ref type="bibr" target="#b10">[11]</ref>, PhaseEvo <ref type="bibr" target="#b42">[43]</ref>, and GAAPO <ref type="bibr" target="#b43">[44]</ref>. While sharing a common foundation in EC, these methods represent distinct philosophies and approaches: (i) EvoPrompt: Pioneers the concept of using LLMs as the direct implementers of evolutionary operators like crossover and mutation within standard EA frameworks (Genetic Algorithms and Differential Evolution).</p><p>(ii) PhaseEvo: Introduces a multi-phase evolutionary framework specifically designed for the unified optimization of both prompt instructions and in-context learning examples, employing LLMs within tailored operators for different search phases.</p><p>(iii) GAAPO: Proposes a hybrid approach where a Genetic Algorithm acts as a high-level controller orchestrating a portfolio of diverse, specialized prompt generation strategies, many of which leverage LLMs.</p><p>Further, we will try to understand and summarize the core concepts, methodologies, application domains, performance characteristics, strengths, and limitations of these prompting tools. The focus of the study will address a comparative analysis, highlighting similarities, differences, and the evolution of ideas of these three prompting tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1.">EvoPrompt</head><p>EvoPrompt, developed by Guo et al. <ref type="bibr" target="#b10">[11]</ref>, represents a novel framework for discrete prompt optimization that explicitly connects LLMs with EC. The central idea is to use the inherent language processing capabilities of LLMs to perform evolutionary operations, thereby automating the search for effective natural language prompts. A key characteristic of EvoPrompt is its gradient-free nature; it operates without requiring access to the target LLM's internal parameters or gradients, making it readily applicable to proprietary, black-box  models accessed via APIs. The motivation stems from the observation that EC exhibits good performance and fast convergence in optimization tasks, and combining it with LLMs creates a synergy between optimization efficiency and language manipulation capabilities. EvoPrompt aims to generate prompts that are not only effective but also coherent and human-readable. The EvoPrompt framework follows the general structure of an evolutionary algorithm. It begins with an initial population of candidate prompts. In each iteration, it generates new prompts by applying evolutionary operators, implemented by an LLM, to selected prompts from the current population. These new prompts are evaluated based on their performance, such as accuracy and ROUGE score, on a development dataset using the target LLM. The population is then updated based on these evaluation scores, typically retaining higher-performing prompts for the next generation. EvoPrompt was manifested using two common EA types: (i) GA manifestation: This version employs canonical GA operators where parent prompts are selected from the population, often using a fitness-proportionate method like roulette wheel selection. An LLM then performs the core evolutionary operations.</p><p>a) Crossover: The LLM is instructed to combine genetic material from two parent prompts to create a new offspring prompt. For example, it might merge phrases or clauses related to the task description or output format from the parents.</p><p>DRAFT b) Mutation: The LLM is instructed to introduce random alterations to the generated offspring prompt, potentially modifying words, phrases, or structure. The population is updated by evaluating the offspring and applying a selection strategy (e.g., keeping the best individuals).</p><p>(ii) DE Manifestation: This version adapts DE principles for prompt optimization. For each prompt ('base vector') in the population, the LLM performs a sequence of operations.</p><p>a) It identifies the differences between two other randomly selected prompts from the population.</p><p>b) It mutates these identified differences.</p><p>c) It combines these mutated differences with the current best-performing prompt in the population.</p><p>d) It performs a crossover operation between this combined prompt and the original base vector prompt.</p><p>The update mechanism typically involves comparing the newly generated prompt with the original base prompt and retaining the one with the higher performance score.</p><p>A crucial aspect across both instantiations is how the LLM performs these operations. It is not explicitly trained for crossover or mutation; rather, it interprets natural language instructions provided within the EvoPrompt framework (the Evo(•) function) that describe the desired operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2.">PhaseEvo</head><p>To tackle the challenges of unified optimization, PhaseEvo employs an efficient automatic prompt optimization framework that combines the generative power of LLMs with the global search capabilities of evolution algorithms. Instead of the random operator selection often seen in traditional EC, PhaseEvo utilizes a structured, quad-phased design that strategically alternates between global exploration and local exploitation.5 This phased approach aims to balance the need to broadly explore the vast search space with the need to efficiently converge towards high-performing solutions, minimizing LLM inference costs. The four phases are:</p><p>(i) Phase 0: Global Initialization: The goal is to establish a diverse initial population of candidate prompts covering the joint instruction-example space. Two strategies are supported as mentioned below.</p><p>(a) Reverse Engineering: An LLM agent uses a "Lamarckian Mutation" operator (OL) to infer potential prompt instructions from example input-output pairs in the training data.</p><p>(b) Human Expert Input: Users can provide seed prompts, which are then diversified using a "Semantic Mutation" operator (OS) that paraphrases them while preserving meaning.</p><p>(ii) Phase (iv) Phase 3: Local Semantic Mutation: This final phase aims to accelerate convergence to the global optimum by performing fine-grained local exploitation.5 It re-employs the "Semantic Mutation" operator (OS), using an LLM to paraphrase the current best prompts, introducing subtle variations while preserving the core meaning and intent.</p><p>The explicit structuring of the optimization process, using different LLM-driven operators tailored for distinct search phases (local feedback, global evolution, local refinement), contrasts sharply with approaches like Evo-Prompt that rely on LLMs to perform generic EA operations throughout. This structured design suggests a hypothesis that targeted LLM operations within specific phases lead to more efficient and effective navigation of the complex prompt space.</p><p>2.4.3. GAPPO GAAPO (Genetic Algorithm Applied to Prompt Optimization) introduces a distinct approach to automatic prompt optimization by employing a Genetic Algorithm (GA) not just to perform basic evolutionary operations, but to act as a high-level framework for integrating and managing a portfolio of diverse, specialized prompt generation strategies. Unlike traditional GAs that rely primarily on mutation and crossover, GAAPO leverages the strengths of multiple existing and novel prompt optimization techniques within its evolutionary cycle. The core idea is that different strategies may excel at different stages of optimization or for different types of prompts, and a hybrid approach managed by a GA can dynamically leverage the most effective generators over time, leading to more robust and optimal performance. GAAPO also emphasizes maintaining a detailed record of the evolution of prompting strategies, enabling analysis of their relative effectiveness.</p><p>GAAPO operates through successive generations, following the standard GA cycle of Selection, Generation, and Evaluation.</p><p>(i) Genetic Algorithm Core: It maintains a population of prompt candidates. In each generation, a selection mechanism (typically choosing the top performers based on evaluation scores) identifies parent prompts.1 These parents are then used by various generations to create new offspring prompts. The offspring are evaluated, and the cycle repeats.</p><p>(ii) Integrated Generation Strategies: The key innovation lies in the Generation phase, which utilizes a diverse set of prompt generators.</p><p>a) OPRO (Optimization by PROmpting): An LLM-based iterative refinement strategy using a trajectory of past high-performing prompts to guide the generation of new candidates.</p><p>b) APO (Automatic Prompt Optimizer) / ProTeGi (Prompt Optimization with Textual Gradients): An iterative method that identifies errors made by existing prompts, generates "textual gradients" based on these errors, and uses them to create improved prompts. c) Random Mutator: Introduces controlled random modifications using eight distinct mutation types targeting different aspects of prompt structure and content (e.g., instruction expansion, expert persona injection, structural variation, constraint addition, creative backstory, task decomposition, concise optimization, role assignment). d) Crossover: A standard GA operator adapted for prompts, combining segments (e.g., first half of one parent, second half of another) from two parent prompts to create offspring, aiming to merge beneficial instruction blocks or strategic elements. (iii) Evaluation Methods: Recognizing the computational cost of evaluating prompts (requiring LLM inference), GAAPO incorporates flexibility in its Evaluation phase, offering several strategies. a) Complete Evaluation: Evaluates every generated prompt on the entire validation dataset. Provides the most accurate ranking but incurs the highest computational cost.</p><p>b) Successive Halving (SH): An efficiency-focused method that iteratively evaluates prompts on increasingly larger subsets of the validation data, discarding the worst-performing half in each round.</p><p>Reduces LLM calls significantly but risks eliminating promising candidates early.</p><p>c) Bandit Selection Algorithm: Employs a multi-armed bandit approach (specifically UCB-E mentioned) to efficiently allocate evaluation budget, balancing exploration of new prompts with exploitation of currently promising ones.</p><p>The framework itself is implemented in Python, named HOPR (Hint Optimization and Prompt Refinement) <ref type="bibr" target="#b44">[45]</ref>, featuring modular components for optimizers, metrics, and managing the evolution process.</p><p>Table <ref type="table" target="#tab_3">3</ref> presents the feature wise comparison of Evprompt, PhaseEvo and GAAPO and Table <ref type="table" target="#tab_4">4</ref> presents their strength, limitations and applicaiton domains found in the literature. Progress in this field seems con- tingent on moving towards a more principled integration of LLMs and EC. Indeed, it is an active and entirely separate domain of research, and we keep ourselves focused on the theme of the article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Evolutionary Hyperparameter Tuning for LLMs</head><p>Hyperparameter optimization is a critical step in developing high-performing machine learning models, including LLMs, as the choice of hyperparameters significantly influences the training dynamics and final model quality. Manually tuning these parameters is often a laborious, intuition-driven process. EC offers a compelling DRAFT DRAFT alternative (see Table <ref type="table" target="#tab_5">5</ref> for some examples) for automating this process. Their gradient-free nature is a distinct advantage, particularly for LLMs accessed as black-box APIs where internal gradients are inaccessible. EC relies solely on evaluating the performance (fitness) of different hyperparameter configurations, making them applicable even without visibility into the model's internal workings. Furthermore, EC's population-based search can effectively explore complex, high-dimensional hyperparameter spaces, potentially uncovering nonobvious interactions between parameters and escaping local optima that might trap simpler search methods. Table <ref type="table" target="#tab_6">6</ref> presents an overview of applications of evolutionary algorithms in LLM hyperparameter optimization Explored GA/PSO for autonomous HPO in a specific scientific domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1.">Evolutionary Architecture Optimization for LLMs</head><p>Designing optimal neural network architectures, particularly for complex models like LLMs, is a significant challenge <ref type="bibr" target="#b48">[49]</ref>. Manual design is often resource-intensive, relies heavily on expert intuition, and may struggle to navigate the vast combinatorial space of possible architectural configurations. Neural Architecture Search (NAS) aims to automate this process by formulating architecture design as an optimization problem: finding the architecture that maximizes a given objective, such as accuracy, under certain constraints (parameter budget, latency). Table <ref type="table" target="#tab_7">7</ref> shows some examples of the architectural aspects of evolutionary NAS for LLMs. EC has proven to be a powerful tool for NAS.10 Their population-based approach allows for parallel exploration of the architecture space, and their gradient-free nature makes them suitable for handling discrete architectural choices or complex search spaces where gradients are ill-defined or unavailable.8 EC can effectively search the space of neural architectures by representing architectures as individuals, evaluating their performance (fitness), and applying evolutionary operators (selection, mutation, crossover) to generate and refine new candidate architectures iteratively. Table <ref type="table" target="#tab_8">8</ref> presents a summary of evolutionary approaches for neural architectural search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Current Challenges and Future Directions</head><p>EC faces significant challenges when applied to LLM optimization, primarily due to the enormous computational costs involved. Evaluating each candidate solution requires partial or full LLM training, making the process prohibitively expensive and limiting feasible population sizes. The vast search spaces of modern DRAFT </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Macro-Level Hyperparameters</head><p>Optimizes high-level structural parameters (encoder/decoder blocks, hidden dimensions, attention heads, FFN sizes).</p><p>SuperShaper <ref type="bibr" target="#b50">[51]</ref>,</p><p>AutoTinyBERT <ref type="bibr" target="#b45">[46]</ref> Component Choices Discrete choices within components (activation functions, sub-module layer counts).</p><p>-Layer Configuration Layer-specific hyperparameters or novel layer connectivity patterns.</p><p>LiteTransformerSearch <ref type="bibr" target="#b51">[52]</ref> Code-Level Modifications LLM-guided direct source code manipulation for flexible architectural variations.</p><p>LLMatic <ref type="bibr" target="#b16">[17]</ref>, EvoPrompting <ref type="bibr" target="#b33">[34]</ref> Evolutionary NAS Methods and Techniques</p><p>Standard EC (GA/NSGA-II)</p><p>Established genetic algorithms adapted for architecture search, including multi-objective variants.</p><p>AutoBERT-Zero, DistilBERT (NSGA-II) <ref type="bibr" target="#b52">[53]</ref> Multi-Objective EC (MOEAs)</p><p>Optimizes trade-offs between performance and computational cost (latency, memory, parameters).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LiteTransformerSearch</head><p>Quality-Diversity (QD) Seeks diverse high-performing solutions rather than a single optimum (e.g., via MAP-Elites).</p><p>LLMatic (dual-archive system)</p><p>LLM-driven Evolution Uses LLMs as intelligent variation operators for code-level mutations and crossovers.</p><p>EvoPrompting DRAFT DRAFT LLMs with billions of parameters push current computational limits, restricting most applications to optimizing subsets of architectures rather than full models. Effective representation of LLM architectures in evolvable formats remains difficult, particularly when using code-based approaches. The exploration-exploitation balance becomes especially challenging when using LLMs as evolutionary operators, as they tend to bias toward known solutions. Fitness evaluation presents a bottleneck, often requiring noisy approximations through proxy tasks or surrogate models. Handling constraints like architectural validity or latency requirements adds further complexity. When LLMs are integrated into the evolutionary loop, they introduce additional challenges, including calibration issues, generator collapse (reduced diversity), limitations in complex reasoning, dependence on clear reward signals, and high sensitivity to input prompts. These combined factors make EA-based LLM optimization both computationally demanding and methodologically complex, requiring advances in efficient evaluation techniques and hybrid approaches to become more practical. Future research has numerous potential directions to address current limitations and unlock further possibilities, including efficiency improvements through more accurate, cheaper, and scalable surrogate models or training-free fitness evaluation techniques, as well as reducing the computational overhead of integrating LLMs into optimization. Scalability enhancements are needed to design EC and representations capable of handling larger search spaces from future LLM generations. Improved representations should explore sophisticated encodings for complex LLM architectures and hyperparameters to enhance evolutionary search. Advanced hybrid algorithms could integrate LLMs more deeply for reasoning, planning, or strategy generation, enabling dynamic adaptation of EA operators based on LLM insights. A stronger theoretical foundation is required to understand the convergence properties and limitations of hybrid EA-LLM systems. Robustness and generalization must be ensured so that optimized solutions perform well on unseen data and avoid catastrophic forgetting in continuous fine-tuning. Automated algorithm design (AutoML/AutoAD) could extend EC and LLMs to self-improving optimization systems. Security and safety research is crucial as LLMs gain autonomy through evolutionary optimization, necessitating risk mitigation. Finally, multimodal LLM optimization requires adapting EA techniques to handle non-textual data like images and audio.</p><p>EC can, in principle, complement gradient methods for large-language model optimization, yet scaling EC beyond toy settings exposes several distinctive hurdles. The first is cost: every candidate in an evolutionary population must be scored with at least one forward (and occasionally training) pass, so large populations become prohibitively slow and expensive. High-dimensional soft-prompt vectors compound that cost: mutating and recombining dense embeddings without collapsing them into noise or adversarial artefacts is non-trivial, and the resulting fitness landscape lacks the smooth gradients that guide back-propagation. Representing entire transformer architectures in an evolvable form is equally tricky-crossover must preserve weight sharing and block legality-while evaluation remains a bottleneck because full-task metrics are noisy and expensive; proxy tasks or surrogate regressors help but can mislead selection. Additional complications arise when the LLM itself acts as a mutation operator, because its inductive bias gravitates toward familiar phrasing and reduces diversity. Practical constraints such as latency, memory limits, or safety filters must also be respected during search. Finally, the theory lags behind practice: little is known about sample complexity, convergence guarantees, or how an LLM's "learning strategy" co-evolves with an EA's "search strategy." (Broader hybridsystem issues-distributed search, interpretability, catastrophic forgetting-are treated later in Section 4.4.) Addressing these EC-specific obstacles will require a mix of engineering and theory. Promising directions include fast, training-free fitness surrogates that widen feasible population sizes; geometry-aware mutation and crossover operators for continuous embeddings; legality-preserving encodings and grammar-guided search for ultra-large transformer variants; and hybrid schemes in which back-propagation performs local refinement while EC supplies global exploration. A firmer theoretical footing-for example, sample-efficiency bounds or criteria that predict when EC + LLM synergy outperforms either component alone-would guide algorithm design and resource allocation. Progress along these lines could make EC a practical, scalable tool for prompt and architecture optimisation in the next generation of LLMs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. LLM-Powered Generation of Metaheuristics</head><p>LLMs, such as GPT-4, represent a breakthrough in artificial intelligence, known for generating coherent and contextually meaningful text <ref type="bibr" target="#b57">[58]</ref>. Trained on vast corpora of textual data, LLMs like GPT-4 excel in various tasks including text generation, summarization, translation, and question answering. GPT-4, developed by OpenAI and based on the transformer architecture <ref type="bibr" target="#b58">[59]</ref>, has demonstrated state-of-the-art performance in natural language processing (NLP), making it a powerful tool not only for language tasks but also for supporting broader applications such as optimization and algorithm design.</p><p>Recognizing these capabilities, Pluhacek et al. <ref type="bibr" target="#b59">[60]</ref> leveraged GPT-4 to design a novel mutation strategy for Differential Evolution (DE) <ref type="bibr" target="#b60">[61]</ref>, aiming to enhance the adaptability and performance of DE in solving complex optimization problems. The authors initiated the design process by prompting GPT-4 with a carefully crafted request: Prompt: Provide a novel and innovative mutation strategy for DE with superior performance to DE/rand/1/bin on the proposed benchmark set.</p><p>In response, GPT-4 proposed a mutation strategy named DE/dynamic-switch/1/bin. This approach introduces a dynamic switching mechanism, where individuals are selected for mutation based on a probabilistic model. Specifically, two probabilities, p i and p j , determine whether the i th and j th individuals in the population are replaced by the current best-performing individual. By incorporating these probabilities, the mutation process gains an adaptive quality, enabling the algorithm to balance exploration and exploitation more effectively as it navigates the search space.</p><p>Further extending this line of inquiry, Pluhacek et al. <ref type="bibr" target="#b61">[62]</ref> explored the generation of novel hybrid swarm intelligence algorithms using GPT-4. They focused on six prominent swarm-based algorithms: Particle Swarm Optimization (PSO), Cuckoo Search (CS), Artificial Bee Colony (ABC), Grey Wolf Optimizer (GWO), Self-Organizing Migrating Algorithm (SOMA), and Whale Optimization Algorithm (WOA), and tasked GPT-4 with constructing hybrid frameworks that integrate the strengths of these methods. To facilitate this, the researchers developed five structured tasks and fifteen tailored prompts, guiding GPT-4 through selecting algorithms, identifying key algorithmic components, and generating novel strategies to enhance diversity and maintain an effective balance between exploration and exploitation.</p><p>The Enhanced Swarm Exploration and Exploitation Optimizer (ESEEO) was among the outcomes, complete with algorithmic description, pseudocode, and Python implementation. Additionally, GPT-4 was prompted to design a metaheuristic optimized for expensive problems with limited function evaluations. This resulted in the Limited Evaluation of Swarm Optimizer (LESO), which was designed with practical efficiency. Full prompt details and implementation steps are provided in the Supplementary File, while the experimental flow is visually depicted in Fig. <ref type="figure" target="#fig_7">4</ref>.</p><p>Building on these findings, Pluhacek et al. introduced a subsequent extension in <ref type="bibr" target="#b5">[6]</ref>, where GPT-4 was used to enhance the Self-Organizing Migrating Algorithm (SOMA) <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b63">64]</ref>. They developed a Python template incorporating SOMA's All-To-All variant (SOMA-ATA) as the baseline algorithm due to its relatively lower representation in LLM training datasets compared to algorithms like Differential Evolution (DE) or PSO. It mimics self-organization and cooperative behavior, with the SOMA-ATA strategy guiding each individual to migrate toward all others in the population. This approach offers a fresh perspective on autonomously generating metaheuristic algorithms, potentially leading to novel and unbiased enhancements. The study assessed whether iterative prompting without feedback could continuously refine performance by leveraging the model's extensive context size. In other words, the SOMA-ATA variant was selected as the baseline due to its comparatively limited representation in GPT-4's training data, potentially offering less biased outcomes.  SOMA-ATA simulates cooperative migration behaviors by guiding individuals to move toward all other individuals in the population, making it an ideal testbed for autonomous enhancement using LLMs.</p><p>In this study, the researchers employed a Python-based SOMA-ATA implementation as the starting prompt.</p><p>DRAFT They adopted a "Repetitive Prompt" strategy, wherein GPT-4 was iteratively prompted using the latest version of the code it had just generated. This cycle was repeated twenty times, with each iteration representing an opportunity for the model to autonomously refine and improve the algorithm. This method demonstrated GPT-4's capacity to act as a self-improving system for metaheuristic algorithm development, offering novel insights into automated algorithmic innovation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">LLM-Based Hyper-Heuristic Frameworks</head><p>This subsection focuses on hyper-heuristic frameworks where LLMs are employed to reason over and generate heuristic strategies. These strategies often include both abstract reasoning (in natural language) and executable code to solve optimization problems. The LLMs are tightly integrated into an evolutionary loop to discover, refine, and adapt heuristics in a task-aware manner. Compared to metaheuristics, which are fullfledged algorithmic solvers, hyper-heuristics typically operate at a higher level by generating or selecting heuristics that guide problem-solving.</p><p>Recent advances have demonstrated that LLMs can be effectively integrated with evolutionary frameworks to autonomously generate, evaluate, and refine code for optimization tasks. This paradigm enables the automated synthesis of algorithms without requiring human-crafted rules or manually trained models, fostering a new generation of metaheuristic design systems.</p><p>A notable milestone in this direction is FunSearch <ref type="bibr" target="#b64">[65]</ref>, developed by Google DeepMind<ref type="foot" target="#foot_0">1</ref> , which demonstrated how LLMs can be integrated with evolutionary algorithms to generate and evolve functional code for solving mathematical and algorithmic problems. FunSearch introduced the paradigm of iteratively generating code snippets via LLMs, evaluating them through task-specific reward functions, and feeding back successful candidates to guide further generation. This paradigm strongly influenced subsequent efforts, including AoL (Algorithm of Language), FunBo, and Evolution of Heuristics (EoH), by establishing a foundation for LLMdriven program synthesis in an evolutionary loop. Building on this idea, the FunBO framework <ref type="bibr" target="#b65">[66]</ref> extended FunSearch to the domain of Bayesian optimization by evolving new acquisition functions (AFs) through LLM-guided code generation. FunBO leverages a limited number of evaluations over a set of objective functions to discover AFs that generalize well both within and beyond the training distribution. It demonstrates competitive or superior performance compared to hand-crafted and transfer-learned AFs, highlighting the potential of LLMs to design data-efficient search strategies across optimization landscapes.</p><p>In another promising direction of LLM integration, Liu et al. <ref type="bibr" target="#b66">[67]</ref> introduced the Evolution of Heuristics (EoH), a pioneering framework that integrates LLMs with EC to autonomously generate, evaluate, and refine heuristics. The goal of EoH is to fully automate the heuristic design process, eliminating the need for humancrafted rules or dedicated models to be trained. EoH uses the generative power of LLMs to propose new heuristics and iteratively improves them through evolutionary refinement, creating a closed-loop system for optimization algorithm development.</p><p>A distinctive feature of EoH is its dual representation of heuristics, both in natural language (referred to as "thought") and executable code. In each iteration, the LLM generates a conceptual explanation of a heuristic and then translates this concept into a working implementation. This mimics the heuristic development process of a human expert, capable of articulating ideas and immediately implementing them.</p><p>EoH uses a series of prompting strategies to navigate the heuristic space effectively, encouraging the LLM to reason over previously generated heuristics and their performance. These strategies enhance the model's ability to reuse and modify prior knowledge, improving exploration across the search space. The evolutionary loop is driven by typical genetic operations such as crossover and mutation, applied in this case by the LLM itself, and guided by a selection mechanism that retains only high-performing heuristics for future iterations.</p><p>Expanding upon this concept, Yao et al. <ref type="bibr" target="#b67">[68]</ref> proposed a Multi-objective Evolution of Heuristics (MEoH) framework, extending the original EoH to support multi-objective optimization tasks. MEoH integrates LLMs DRAFT with Multi-objective Evolutionary Algorithms (MOEAs) to produce heuristics that satisfy multiple design objectives simultaneously, such as computational efficiency, scalability, and solution quality, rather than optimizing a single performance metric.</p><p>A central innovation in MEoH is introducing a dominance-dissimilarity mechanism that enhances diversity in objective and heuristic spaces. This mechanism manages population diversity by evaluating dominant relationships among solutions in the objective space and dissimilarity among heuristics in the solution space. MEoH also inherits five LLM-driven operators from EoH <ref type="bibr" target="#b66">[67]</ref>, E1, E2, M1, M2, and M3, that enable exploration and exploitation through heuristic generation and modification. The framework is validated on classic combinatorial problems, including the online Bin Packing Problem (BPP) and the Travelling Salesman Problem (TSP), demonstrating its versatility and efficacy.</p><p>Furthering the idea of LLM-guided hyper-heuristics, Ye et al. <ref type="bibr" target="#b68">[69]</ref> introduced ReEvo. ReEvo<ref type="foot" target="#foot_1">2</ref>  <ref type="bibr" target="#b68">[69]</ref> is a novel framework that integrates evolutionary search with large LLM reflections to enhance language hyperheuristics (LHHs) <ref type="foot" target="#foot_2">3</ref> for combinatorial optimization problems (COPs).</p><p>ReEvo leverages LLMs to generate heuristics while employing Genetic Programming (GP) to explore the heuristic space efficiently. By combining evolutionary search with LLM-based self-reflections, ReEvo enhances the reasoning capabilities of LLMs. It mimics human experts by analyzing heuristic performance across iterations, providing a "verbal gradient" within search spaces. ReEvo incorporates both short-term and long-term reflections to refine heuristic design:</p><p>(i) Short-term reflections: The generator LLM creates offspring heuristics based on task specifications, parent heuristics, relative performance, and generation instructions.</p><p>(ii) Long-term reflections: Expertise accumulates by summarizing previous reflections and generating hints for improved heuristic design.</p><p>Within an evolutionary framework, ReEvo represents heuristics as code snippets and follows a structured process including population initialization, selection, short-term reflection, crossover, long-term reflection, and elitist mutation. By incorporating both local adaptation and global reasoning, ReEvo brings human-like adaptability to the automated discovery of optimization strategies.</p><p>Stein et al. <ref type="bibr" target="#b11">[12]</ref> developed the LLaMEA framework <ref type="foot" target="#foot_3">4</ref> , which integrates GPT-4 with EC to iteratively generate and refine optimization strategies. LLaMEA follows an EA-like loop: algorithms are generated, mutated, and selected based on performance evaluations. This enables the dynamic evolution of optimization code without requiring extensive prior expertise or manual coding.</p><p>To evaluate the generated algorithms, LLaMEA incorporates the IOHprofiler suite <ref type="bibr" target="#b69">[70]</ref>, which includes IOHexperimenter <ref type="bibr" target="#b70">[71]</ref> for benchmark execution and IOHanalyzer <ref type="bibr" target="#b71">[72]</ref> for statistical performance analysis. The framework uses in-context learning, error handling, and selection strategies to iteratively improve algorithm quality. Its selection strategy determines whether a refined algorithm is accepted based on performance improvement or if novel algorithms are always accepted. The mutation and selection steps involve constructing a feedback prompt for the LLM, guiding it to either refine an existing algorithm or generate a new one. The LLaMEA framework relies on two key prompts that define the optimization process:</p><p>(i) Task prompt (S): Your task is to design novel metaheuristic algorithms to solve black-box optimization problems. The optimization algorithm should handle many tasks and be evaluated on a large test suite DRAFT of noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain one function: def __call__(self, f) which should optimize the black-box function f using budget function evaluations. The function ' f ()' can only be called as many times as the budget allows.</p><p>An example of such code is as follows: &lt;initial example code&gt; Give a novel heuristic algorithm to solve this task. Give the response in the format:</p><p># Name : &lt;name o f t h e a l g o r i t h m &gt; # Code : &lt;code &gt; (ii) Task-feedback prompt: List of previously generated algorithm names with their mean AOCC score. Selected algorithm to refine (full code), along with mean and standard deviation (AOCC) scores. Either refine or redesign the algorithm to improve its performance.</p><p>These prompts form the core of LLaMEA's optimization loop, enabling GPT-4 to participate in evolutionary algorithm design as a solution generator and a performance-aware optimizer. By continuously refining algorithmic components using benchmark feedback, LLaMEA demonstrates how LLMs can facilitate the automated generation of high-quality, adaptive metaheuristic algorithms.</p><p>As a follow-up to LLaMEA, LLaMEA-HPO <ref type="bibr" target="#b11">[12]</ref> <ref type="foot" target="#foot_4">5</ref> extends this framework to offload hyper-parameter tuning HPO to an external Bayesian Optimization tool specialized at HPO. This way the LLM can focus on the structural parts of algorithm discovery while the tuning of the generated algorithm happens inside the loop by HPO tooling. It introduces a hybrid optimization scheme that integrates LLM-generated suggestions with surrogate-assisted tuning, making it suitable for data-efficient scenarios.</p><p>Like EoH <ref type="bibr" target="#b66">[67]</ref>, LLaMEA-HPO uses evolutionary principles and language model reasoning to improve optimization performance. Both frameworks aim to fully automate the optimization process, but they target complementary aspects: EoH on heuristic discovery for combinatorial optimization, and LLaMEA and LLaMEA-HPO on efficient discovery of complete code-bases, focusing on continuous black-box optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">LLM-Assisted EC Tuning</head><p>LLMs have recently emerged as powerful tools for enhancing the performance of EC by enabling more intelligent and adaptive control of algorithmic behavior. In particular, their capacity for inference and contextual reasoning allows them to support EA components such as surrogate modeling and operator tuning. This section explores two major contributions in this direction: using LLMs as surrogate models for approximating fitness evaluations, and their role in adaptive operator selection based on performance feedback. These advancements show how LLMs can be integrated into EC as passive generators and active agents guiding search dynamics through learned inference, adaptation, and reflective reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Surrogate Modeling for EA Optimization</head><p>Hao et al. <ref type="bibr" target="#b72">[73]</ref> introduced a novel surrogate modeling approach that leverages the inference capabilities of LLMs to enhance selection mechanisms in EC <ref type="bibr" target="#b73">[74]</ref>. Their proposed method transforms model-assisted selection into an inference task, where LLMs evaluate the quality of candidate solutions using historical evaluation data. This is achieved through tailored prompt engineering that allows LLMs to classify or regress fitness estimates based on learned patterns from previous generations. The resulting framework, LLM-assisted EA (LAEA), integrates LLMs as surrogate models to support evolutionary search.</p><p>The integration process consists of four core steps: preprocessing, prompt generation, inference, and postprocessing, as detailed in Algorithm 1. Let X denote the set of evaluated solutions, Y their corresponding DRAFT values or labels, U the unevaluated candidate solutions, Ỹ the predicted outputs, and Opt the task type, either regression or classification.</p><p>In the case of regression tasks, the algorithm utilizes the historical input-output pairs (X,Y ) to predict values for the new candidates U. Prompt generation, illustrated in Fig. <ref type="figure" target="#fig_8">5</ref>, includes five structured components: a task description, a process description, a dataset summary containing historical records, feature vectors of new candidate solutions (u), and an output specification requiring JSON-formatted responses.</p><p>For classification tasks, a similar methodology is applied. Here, the objective is to assign binary labels (e.g., 1 or 0) to the unevaluated candidates U, based on patterns inferred from the previously labeled set (X,Y ). The generation of classification-specific prompts is shown in Fig. <ref type="figure" target="#fig_9">6</ref>, where the label set Y is typically derived from upstream decision tasks or heuristics.</p><p>By embedding these inference capabilities within the evolutionary loop, LAEA enables LLMs to serve as powerful surrogates. Instead of relying on traditional machine learning models, the LLM provides probabilistic predictions or binary decisions that guide the selection process. This approach combines linguistic and statistical reasoning, offering a flexible and generalizable alternative for surrogate-assisted evolutionary algorithms (SAEAs).</p><p>A complementary and noteworthy contribution is LLAMBO <ref type="foot" target="#foot_5">6</ref> (Large Language Models to Enhance Bayesian Optimization) <ref type="bibr" target="#b74">[75]</ref>, which brings LLMs into the surrogate modeling loop for black-box optimization tasks. LLAMBO addresses the cold-start problem in Bayesian Optimization (BO) by using LLMs for zero-shot warm-starting, predicting promising initial configurations without requiring prior evaluations. This is particularly valuable in scenarios with limited data or expensive fitness evaluations.</p><p>LLAMBO integrates LLM-generated prompts into the BO workflow by encoding prior configurationperformance pairs as text. The LLM then provides predictions that enhance three critical BO components:</p><p>(1) it initializes the surrogate model via LLM-generated predictions, (2) proposes candidate solutions using LLM-inferred priors, and (3) incorporates LLM-based sampling strategies that are informed by the trajectory of the optimization process.</p><p>The framework features a modular, interpretable architecture that seamlessly integrates into existing BO pipelines. Across various synthetic and real-world benchmarks, LLAMBO demonstrates superior performance, underscoring the utility of LLMs not only as repositories of general knowledge but also as active agents in guiding and accelerating optimization. Its plug-and-play design makes it especially appealing for EC-based hyperparameter tuning and surrogate modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Adaptive Operator Selection via LLMs</head><p>Martinek et al. <ref type="bibr" target="#b75">[76]</ref> explored using LLMs for tuning parameters and operators in metaheuristic algorithms, including GA, ACO, PSO, and SA. Their study focused on solving two classical combinatorial problems: the TSP and the Graph Coloring Problem (GCP). The goal was to determine whether LLMs could effectively suggest adaptive parameter configurations for these algorithms and refine them based on iterative feedback.</p><p>In this framework, the LLMs are first provided with detailed problem specifications, an initial algorithmic setup, and performance statistics from early runs. Based on this information, the LLM suggests a set of parameter values for the algorithm in question. These values are then evaluated through controlled experiments, and the resulting performance, particularly the average solution quality and population variance, is fed back into the model for refinement.</p><p>This feedback loop enables the LLM to iteratively improve parameter suggestions, often leading to better performance than the initial configurations. To ensure fair benchmarking across algorithms and configurations, the authors constrained the total computational effort by fixing the product of population size and the number of epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DRAFT</head><p>The experiments incorporated multiple LLMs, including two versions of ChatGPT (OpenAI), Gemini (Google), and Le Chat (Mistral AI). The prompts used in each iteration, summarized in Table <ref type="table" target="#tab_11">9</ref>, contained comprehensive information including the optimization problem, current parameter settings, observed population variance, approximated global optima, and performance at the most recent epoch.</p><p>The study demonstrated that LLMs possess a strong capability for adaptive reasoning. They could meaningfully update parameter values in response to observed data, suggesting that LLMs are suitable for static configuration and online adaptive operator control in metaheuristic optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt for regression</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure Historical examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt for LLM</head><p>Your task is to predict the numerical value of each object based on its attributes. These attributes and their corresponding values are outcomes of a black box function's operation within its decision space. The target value for each object is determined by a specific mapping from these attributes through the black box function. Your objective is to infer the underlying relationships and patterns within the black box function using the provided historical data. This task goes beyond simple statistical analyses, such as calculating means or variances, and requires understanding the complex interactions between the attributes. Please do not attempt to fit the function using code similar to Python; instead, directly learn and infer the numerical values.. <ref type="bibr" target="#b0">1</ref>. Analyze the historical data to uncover how attributes relate to the numerical values. 2. Use these insights to predict the numerical value of new objects based on their attributes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt for LLM</head><p>You are tasked with evaluating each object based on its numerical attributes to determine its category as 'better' or 'worse'. These attributes derive from a black box function's decision space, with the assessment of the label based on the post-mapping function values. Your role involves discerning the internal variable relationships of the black box function from provided historical data, moving beyond mere statistical analyses like calculating means and variances.</p><p>1. Identify patterns in how attributes are categorized. 2. Apply these patterns to assess new objects, determining whether their category is better or worse. 3. Respond using JSON format, e.g. 'Class': 'result' Features: &lt;0.555, 0.881, ..., 0.491&gt;; Class: better Features: &lt;0.593, 0.515, ..., 0.456&gt;; Class: worse ... Features: &lt;0.253, 0.747, ..., 0.475&gt;; Class: better &lt;0.189, 0.917, ..., 0.443&gt; better or worse? Note: Respond in JSON with the format 'Class': 'result' only. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Pattern-Guided Evolution via LLMs</head><p>OptiPattern <ref type="bibr" target="#b76">[77]</ref> is a novel hybrid framework that enhances metaheuristic (MH) optimization by leveraging LLMs for pattern recognition within problem instance metrics. Rather than relying on LLMs to act as direct optimizers, which often restricts them to small problems due to limitations in reproducibility and DRAFT Algorithm 1 LLM as Surrogate Model Require: X, Y , U, LLM, Opt. Ensure: Ỹ .</p><p>1: Ỹ ← / 0 2: X,U ← Preprocessing(X,U) 3: for u ∈ U do   scale, OptiPattern capitalizes on LLMs' semantic understanding and generalization capabilities to extract meaningful patterns from input data that can guide evolutionary search.</p><p>The approach is validated on the Multi-Hop Influence Maximization in Social Networks (MHIM) problem <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b78">79]</ref>, a complex combinatorial optimization task involving graph structures. OptiPattern competently performs, outperforming conventional hybrid metaheuristics that combine MHs with deep learning models. The implementation is publicly available at https://github.com/camilochs/optipattern.</p><p>At the core of OptiPattern lies a Biased Random Key Genetic Algorithm (BRKGA), where the decoder is augmented with node selection probabilities predicted by the LLM. These probabilities guide the mapping of random keys to valid solutions, embedding LLM-inferred structural knowledge directly into the search process. This fusion allows the MH to benefit from LLM-generated priors without compromising its exploratory and adaptive nature. The framework operates in three key phases:</p><p>(i) LLM Prompt Generation and Execution: Automatically structured prompts are generated based on the problem instance, including graphs and rule descriptions.</p><p>(ii) Pattern Extraction via Probabilistic Encoding: The LLM outputs ten parameters (five α and five β values), which are used to compute the node-level probabilities in the evaluation graph using a predefined analytical formula.</p><p>(iii) Probability-Guided Decoding in the MH: These probabilities are embedded into the BRKGA decoding process, influencing solution construction by prioritizing nodes more likely to contribute to optimal outcomes.</p><p>The prompt design is instrumental in determining the quality of LLM outputs. Each prompt consists of In contrast to previous works where LLMs function as black-box optimizers, OptiPattern provides a middle ground, enabling LLM-informed evolutionary optimization. It retains the scalability and robustness of MHs while enriching them with semantic and structural insights from LLMs, establishing a powerful blueprint for hybrid, pattern-driven optimization workflows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">LLM-Generated Metaheuristics</head><p>This subsection covers approaches where LLMs are directly used to synthesize novel metaheuristic algorithms and self-contained optimization strategies designed to solve black-box problems. Unlike hyperheuristics, which guide low-level solvers, metaheuristics define the algorithmic search behavior themselves. Here, LLMs act as autonomous designers of complete optimization algorithms, often modeled after evolutionary or swarm-based strategies.</p><p>Recent advancements in LLMs have enabled the automatic generation of novel metaheuristic (MH) algorithms. By leveraging the powerful reasoning and language capabilities of models like ChatGPT-3.5 and GPT-4, researchers have begun to explore using LLMs as autonomous agents for optimization algorithm design. This subsection reviews emerging approaches that employ LLMs to generate, execute, and iteratively refine metaheuristics, highlighting the potential of natural language as a new interface for metaheuristic innovation.</p><p>Zhong et al. <ref type="bibr" target="#b79">[80]</ref> proposed Zoological Search Optimization (ZSO), an MH inspired by collective animal behaviors and generated entirely through ChatGPT-3.5. The authors introduced the CRISPE framework, Capacity and Role, Insight, Statement, Personality, and Experiment, to guide the LLM through a structured, prompt engineering process. In the insight phase, the LLM is instructed to generate an animal-inspired MH suitable for black-box optimization problems. The statement phase requests a detailed algorithm design, including inspiration, mathematical equations, parameter settings, and a flowchart. The personality component encourages novelty by ensuring the output differs significantly from existing methods such as GA, DE, ES, and PSO. Finally, in the experiment phase, the LLM is constrained to output only one unique algorithm per prompt. This structured approach allowed ZSO to demonstrate how LLMs can autonomously generate innovative algorithms without human intervention, showcasing the potential of prompt-driven MH design.</p><p>Liu et al. <ref type="bibr" target="#b8">[9]</ref> introduced LLM-driven EA (LMEA), a zero-shot approach that uses LLMs as combinatorial optimizers <ref type="bibr" target="#b80">[81]</ref>. LMEA eliminates the need for domain-specific knowledge, additional model training, or hand-coded operators. Instead, the LLM performs evolutionary operations-such as parent selection, crossover, and mutation-to generate offspring in a GA setting. These offspring are then evaluated and incorporated into the population for the next generation.</p><p>A key feature of LMEA is its self-adaptation mechanism, which dynamically adjusts the LLM's temperature to balance exploration and exploitation and to avoid premature convergence to local optima using the framework presented in Algorithm 2. LMEA operates based on a structured prompt consisting of three main components: (i) problem description and solution properties, which define the optimization task and valid solution characteristics; (ii) in-context examples, which provide previous solutions and their fitness values; and (iii) task instructions that guide the LLM to perform parent selection, crossover, and mutation.</p><p>For example, in solving the traveling salesman problem (TSP), the prompt specifies city coordinates, solution constraints (e.g., visiting each city exactly once), and fitness (total travel distance). The LLM then uses evolutionary principles to generate new solutions. To ensure consistency, outputs are enclosed in standardized DRAFT tags, such as &lt; selection &gt; for parents and &lt; res &gt; for solutions. Unlike traditional EC, which rely on manually programmed operators, LMEA delegates these responsibilities to the LLM, enabling flexible and scalable optimization with minimal expert intervention. Fig. <ref type="figure" target="#fig_16">7</ref> illustrates an example of a prompt used for solving the TSP with LMEA. The problem description includes the coordinates of the cities, while the solution properties outline constraints such as visiting each city exactly once and minimizing the total travel distance. The incontext examples contain previously generated TSP solutions and their corresponding fitness (path lengths). The task instructions direct the LLM to generate new solutions based on evolutionary principles.</p><p>While both Sections 3.1.2 and 3.3 explore the use of LLMs in optimization algorithm design, they differ in abstraction level: the former focuses on heuristic reasoning and selection (hyper-heuristics), while the latter targets the automatic generation of executable metaheuristic solvers. This separation allows a clearer comparison of LLM utility across different levels of algorithm synthesis. Construct a prompt based on T and P 5:</p><p>Generate N offspring solutions P ′ using LLM with the constructed prompt 6:</p><p>Select the top N solutions from P ∪ P ′ 7:</p><p>Adjust LLM parameters (e.g., temperature) if necessary 8:</p><p>Increment generation counter g ← g + 1 9: end while 10: Select the best solution s * from P 11: return s *</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Genetic Programming &amp; LLM Synergy</head><p>This subsection examines the synergistic integration of Genetic Programming (GP), machine learning, and LLMs within EC. The first part focuses on GP-based generative hyper-heuristics, which evolve high-level decision-making rules across multiple tasks to enable adaptive and generalizable scheduling solutions. These approaches operate in the heuristic space and leverage multifactorial optimization and knowledge-sharing mechanisms to enhance multitasking performance.</p><p>The second part explores learnable evolution models that embed inductive learning into the evolutionary process. In these frameworks, machine learning methods guide the generation of new individuals, enabling more informed and data-driven search strategies. One notable example is LEMABE, a hybrid model that alternates between machine learning and evolutionary operations to optimize key components, such as feature weighting in analogy-based estimation.</p><p>Together, these strategies illustrate a shift toward more intelligent, adaptable, and automated metaheuristic generation by combining GP, data-driven learning, and the natural language reasoning and generation capabilities of LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">GP-Based Generative Hyper-Heuristics</head><p>Zhang et al. <ref type="bibr" target="#b81">[82]</ref> introduced a multitask GP-based generative hyper-heuristic framework for dynamic scheduling problems. Unlike most existing multitask hyper-heuristics, which primarily focus on heuristic You are given a list of points with coordinates: {points}. Your task is to find a trace, with the shortest possible length, that traverses each point exactly once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In-context examples (population)</head><p>Below are some previous traces and their lengths, ordered by their lengths: Provide traces in XML-like format using &lt; selection &gt; and &lt; res &gt; tags. selection, this approach emphasizes the generation of new heuristics. The framework leverages multifactorial evolutionary principles from evolutionary multitask learning (MFEA) to solve multiple scheduling tasks simultaneously, facilitating knowledge transfer across tasks and improving overall performance.</p><p>Operating within the heuristic space, the method evolves high-level scheduling heuristics rather than optimizing solution instances directly. This makes the approach particularly suitable for dynamic environments requiring adaptive, real-time decision-making. GP is the core hyper-heuristic engine, utilizing its flexible tree-based representation to evolve scheduling rules without requiring predefined structures. The authors proposed an origin-based offspring reservation strategy to enhance the learning process further. This mechanism preserves essential characteristics from each task's subpopulation while allowing for cross-task knowledge exchange during crossover operations.</p><p>Zhang et al. <ref type="bibr" target="#b82">[83]</ref> extended this work by proposing a multitask multi-objective GP framework tailored for dynamic flexible job shop scheduling (DFJSS). In this variant, tasks are partitioned into distinct populations, and inter-task knowledge sharing is facilitated through a task-aware crossover operator. A task-oriented knowledge-sharing strategy was introduced to ensure that individuals remain effective in their original task context while benefiting from cross-task genetic exchange. The framework automates the generation of flexible and adaptive scheduling heuristics in the heuristic space, targeting improvements in routing and sequencing decisions critical to DFJSS environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Learnable Evolution Models</head><p>Dashti et al. <ref type="bibr" target="#b83">[84]</ref> proposed LEMABE (Learnable Evolution Model in Analogy-Based Estimation), a hybrid framework designed to enhance the accuracy of software cost estimation. The method builds on analogy-based estimation (ABE), a widely used technique that predicts the cost of new software projects by comparing them with similar historical cases. ABE involves constructing a historical project dataset, extracting relevant features, measuring similarity between projects (typically using Euclidean or Manhattan distances), and applying a solution function to generate estimates. DRAFT LEMABE integrates the Learnable Evolution Model (LEM), a machine learning-guided evolutionary approach alternating between inductive learning and Darwinian evolution. LEM generates new populations based on inductive hypotheses derived from high-quality individuals. This learning-guided evolution mechanism is employed to optimize the feature weights in the similarity function used by ABE.</p><p>The LEMABE framework is composed of two phases: a training phase and a testing phase. During training, the evolutionary algorithm explores the weight space to minimize prediction error using predefined evaluation criteria. The optimized feature weights are recorded once convergence or termination conditions are met. These weights are applied to new instances in the testing phase to assess the model's estimation accuracy. By combining ABE with learnable evolutionary modeling, LEMABE enhances prediction robustness and adaptability in software cost estimation scenarios. A comprehensive summary is presented in Table <ref type="table">10</ref>, which serves as a quick reference guide to understand the landscape of LLM-assisted and LLM-generated advancements in EC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Emerging Frameworks, Future Directions and Challenges</head><p>The convergence of EC and LLMs marks opens up new possibilities in artificial intelligence, allowing the development of novel frameworks that combine adaptive search with deep semantic understanding. As EC methods evolve to address increasing demands for robustness, generalizability, and interpretability, the integration with LLMs introduces new paradigms for representation learning, automated model design, and zero-shot generalization. This synergy paves the way for hybrid architectures that uses evolutionary search strategies to optimize not just parameters, but the structural and prompt-based configuration of LLMs themselves. However, alongside these promising directions emerge significant challenges, ranging from computational scalability and reproducibility to explainability and alignment with human intent. This section explores these emerging frameworks, outlines key research trajectories, and highlights the critical obstacles that must be addressed to fully realize the potential of EC-LLM integration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Co-Evolution of LLMs and EC</head><p>The co-evolution of LLMs and EC presents a promising frontier for intelligent, automated systems. Drawing upon the synergetic benefits listed in Table <ref type="table">11</ref>, we observe that LLMs and EC can iteratively enhance each other across multiple dimensions. While EC offers robust global search strategies that thrive in nondifferentiable and high-dimensional spaces, LLMs contribute their contextual reasoning and language-generation prowess, allowing for semantically guided optimization and intelligent decision-making. Together, they form a dual feedback loop in which one guides, refines, and accelerates the evolution of the other.</p><p>In this co-evolutionary paradigm, we have observed that EC can be used to optimize components of LLM workflows such as prompt structures, architecture configurations, or hyperparameters. Conversely, LLMs can generate and analyze intermediate EA outputs, propose candidate solutions, or even serve as intelligent mutation and crossover operators. The iterative refinement inherent to evolutionary processes complements the generative capabilities of LLMs, enabling the joint system to adapt to dynamic problem landscapes more efficiently and autonomously.</p><p>This synergy between LLMs and EC creates a powerful automated framework in which both learning and evolution occur concurrently. Such frameworks not only enable the automation of highly complex tasks but also have the potential to discover novel solutions that might not be easily conceived by humans or found by using either method alone <ref type="bibr" target="#b6">[7]</ref>. This co-evolutionary framework is finding applications across a diverse range of fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Co-evolutionary Framework Applications</head><p>Beyond the extensive use in prompt engineering and optimization, the combination of LLMs and EC is being explored in the realm of Automated Machine Learning <ref type="bibr" target="#b84">[85]</ref>. EC, potentially guided or enhanced by DRAFT Table <ref type="table">10</ref>: Summary of LLM-Enhanced EC Approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Framework</head><p>A Comprehensive Summary SOMA / SOMA-ATA <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b61">62]</ref> The SOMA framework uses LLMs to manage and evolve search operators dynamically. It maintains a search operator pool and selects appropriate operators based on learned patterns. SOMA-ATA enhances SOMA by incorporating LLM-generated textual feedback as auxiliary signals, improving operator selection via soft prompts and meta-level guidance.</p><p>EoH / MEoH <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b67">68]</ref> EoH and MEoH employ LLMs to iteratively refine or evolve heuristic rules. EoH fine-tunes heuristics for specific tasks using LLM-driven variation and selection, while MEoH generalizes the process by evolving the heuristic evolution mechanisms themselves. These approaches introduce task embeddings and expert demonstrations to improve performance.</p><p>ReEvo <ref type="bibr" target="#b68">[69]</ref> ReEvo uses LLMs for reflective self-improvement in EA design. After running an optimization cycle, LLMs analyze their performance and generate new algorithm variants or tuning suggestions. ReEvo embodies meta-cognitive behavior, aiming to build adaptive evolutionary solvers through cycles of reflection, evaluation, and generation.</p><p>ZSO <ref type="bibr" target="#b79">[80]</ref> ZSO is a novel metaheuristic algorithm automatically generated using ChatGPT-3.5 under the CRISPE framework. This framework structures prompt design into five phases (Capacity, Role, Insight, Statement, Personality, and Experiment) to guide the LLM in creating a distinct, animalinspired optimization algorithm with a full description, equations, and flowchart.</p><p>LMEA <ref type="bibr" target="#b8">[9]</ref> LMEA uses LLMs to perform parent selection, crossover, and mutation in GAs in a zero-shot setting. It introduces a self-adaptive mechanism to adjust the temperature parameter for explorationexploitation balance. Structured prompts guide the evolutionary steps, and outputs follow defined tagging (e.g., &lt;res&gt;) to ensure format consistency.</p><p>LLaMEA <ref type="bibr" target="#b11">[12]</ref> LLaMEA integrates GPT-4 into an EA loop that iteratively generates, mutates, and selects optimization algorithms. It uses IOHprofiler, IOHexperimenter, and IOHanalyzer for systematic benchmarking. Task and task-feedback prompts facilitate continuous refinement or regeneration of algorithms based on their performance metrics.</p><p>Multitask GP <ref type="bibr" target="#b81">[82]</ref> This multitask GP-based generative hyperheuristic solves dynamic scheduling problems by evolving heuristics across multiple tasks using multifactorial optimization. It promotes knowledge transfer and uses a tree-based GP representation to generate flexible, real-time heuristics. A novel offspring reservation strategy improves quality and diversity.</p><p>Multiobjective GP <ref type="bibr" target="#b82">[83]</ref> An extension of the previous work, this approach introduces multiobjective optimization to enhance heuristic learning for DFJSS. It isolates populations per task and introduces task-oriented crossover for effective knowledge sharing while preserving task-specific quality.</p><p>LEMABE <ref type="bibr" target="#b83">[84]</ref> LEMABE combines the LEM with ABE to improve software cost estimation. LEM uses inductive learning to guide evolutionary search and optimize feature weights in ABE's similarity function. It alternates between ML-driven and Darwinian evolutionary modes during training.</p><p>OptiPattern <ref type="bibr" target="#b76">[77]</ref> OptiPattern enhances BRKGA by using LLMs to analyze graph-based problem instances (e.g., MHIM) and produce node-wise probabilities that guide the metaheuristic search. The system follows three phases: LLM prompt execution, probability extraction via α and β parameters, and integration of these into decoding. Prompts are auto-generated using structured tags that describe the problem, example, evaluation graph, and rules.</p><p>LLMs, can automate the design and optimization of entire machine learning pipelines. This includes tasks such as feature selection (choosing the most relevant features for a model), model selection (choosing the best type of model for a given problem), and hyperparameter tuning (finding the optimal settings for the chosen model) <ref type="bibr" target="#b85">[86]</ref>. LLMs can contribute to this process by leveraging their knowledge of machine learning concepts, historical data from previous experiments, and domain-specific insights to predict optimal configurations for hyperparameters, thereby enhancing model performance and reducing the reliance on exhaustive trial-anderror methods <ref type="bibr" target="#b84">[85]</ref>.</p><p>In the field of robotics and autonomous systems, the synergy between LLMs and EC offers exciting possibilities <ref type="bibr" target="#b85">[86]</ref>. These integrated systems can enable robots to evolve new communication strategies and proto-DRAFT Table <ref type="table">11</ref>: Benefits of Combining LLMs and EC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benefit Description</head><p>Enhanced exploration and exploitation EC explores broadly, while LLMs guide the search toward meaningful solutions, balancing exploration and exploitation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Improved adaptability and flexibility</head><p>The combination adapts optimization strategies based on the task or domain, leveraging LLM knowledge and EA adaptiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automation of complex processes</head><p>Automates tasks like prompt engineering, hyperparameter tuning, and neural architecture search, reducing manual effort.</p><p>Utilizing language understanding and generation LLMs enable EC to work with natural language representations of problems and solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Potential for discovering novel solutions</head><p>The synergy can lead to the discovery of solutions or strategies that might not be found by using either method alone.  cols, potentially enhancing collaboration between machines or between human-robot teams <ref type="bibr" target="#b85">[86]</ref>. Furthermore, LLMs combined with EC can help robots optimize complex decision-making processes for tasks such as navigation in dynamic environments, interaction with objects and humans, and coordination of multiple robotic agents <ref type="bibr" target="#b85">[86]</ref>.</p><formula xml:id="formula_1">EA</formula><p>The creative potential of this integration is also being explored in generative design and the creation of novel content <ref type="bibr" target="#b85">[86]</ref>. EC can be used to evolve prompts or parameters that guide LLMs in generating unique forms of art, musical compositions, engaging stories, and even entire game worlds <ref type="bibr" target="#b85">[86]</ref>. Projects like Artbreeder, which uses EC to combine and modify images, exemplify this trend and suggest the possibility of integrating language models to evolve visual narratives and storytelling through generative art <ref type="bibr" target="#b85">[86]</ref>.</p><p>The domains of synthetic biology and drug discovery are also witnessing the application of LLM-EA integration <ref type="bibr" target="#b85">[86]</ref>. LLMs trained on vast amounts of biological data, such as protein structures and genetic sequences, can be combined with EC to evolve novel proteins or genes with desired properties for drug de-DRAFT velopment or synthetic biology applications <ref type="bibr" target="#b85">[86]</ref>. This includes the potential for evolving models that can accurately predict molecular interactions, a critical step in the drug discovery process <ref type="bibr" target="#b85">[86]</ref>.</p><p>In recommender systems, LLMs can enhance the accuracy and diversity of recommendations, particularly for addressing challenges related to long-tail items (items rarely interacted with) and long-tail users (users with limited interaction history) <ref type="bibr" target="#b86">[87]</ref>. By providing semantic embeddings of items and users, LLMs can improve the understanding of user preferences and item characteristics. Evolutionary approaches can then be used to optimize the recommendation strategies based on these enhanced representations, potentially leading to more personalized and relevant recommendations <ref type="bibr" target="#b86">[87]</ref>.</p><p>Finally, in software engineering and code generation, the integration of LLMs and EC is showing promise <ref type="bibr" target="#b6">[7]</ref>. EC, potentially guided by the code understanding capabilities of LLMs, can be used in neural architecture search to discover more effective neural network architectures for code generation tasks. Additionally, EC can be employed to optimize the strategies used by LLMs to generate high-quality code based on natural language descriptions or other forms of input <ref type="bibr" target="#b6">[7]</ref>. A summary of the applications is presented in Table <ref type="table" target="#tab_13">12</ref>. The breadth of these applications highlights the significant potential of combining LLMs and EC to drive innovation and solve complex problems across a wide spectrum of domains, ranging from creative arts and entertainment to fundamental scientific research and advanced engineering. The ability of LLMs to generate and refine prompts for themselves or other tasks optimized by EC also suggests a form of meta-learning or selfimprovement within AI systems <ref type="bibr" target="#b6">[7]</ref>. This capability could pave the way for more autonomous and adaptive AI systems that can continuously optimize their performance without extensive human intervention.</p><p>As we have observed, the coevolutionary framework has the potential to drive scientific discovery, which could transform the future research outlook in the domain of metaheuristic algorithm design, necessitating a closer examination in that direction to guide closely the future agenda.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Novel Metaheuristic Design with LLMs</head><p>Integrating LLMs with EC opens up exciting opportunities for the development of advanced optimization algorithms tailored to tackle complex optimization tasks. Early studies have explored various frameworks for combining EC and LLMs to create novel metaheuristic algorithms, as summarized in Table <ref type="table">10</ref>. Their DRAFT development is based on the interpretation of what we mean by novel algorithms. Therefore, it is crucial to establish a clear understanding of what constitutes a novel, new, or improved EA to effectively guide future advancements. This aspect is crucial to define the learning objective for such novel algorithm discovery.</p><p>A novel metaheuristic algorithm can be characterized by its ability to introduce fundamentally new mechanisms, components, or hybrid approaches that significantly enhance problem-solving capabilities. Further, a novel metaheuristic algorithm is not just an incremental modification but a fundamental improvement that surpasses existing state-of-the-art (SOTA) methods. To qualify as a novel metaheuristic algorithm, it must: (i) Introduce fundamentally new mechanisms in any core components of EA, such as the representation of solutions, initialization, variation operators, selection mechanism, replacement strategy, and adaptive control, or develop new heuristics beyond SOTA.</p><p>(ii) Achieve superior performance compared to the SOTA metaheuristic in terms of some of the aspects that measure performance, such as accuracy, convergence speed, scalability, or robustness.</p><p>(iii) Demonstrate generalizability across a class of problems or several classes of problem domains rather than excelling in a few specific cases.</p><p>Based on this understanding of what constitutes a novel algorithm, we envisage the following high-level framework (Fig. <ref type="figure" target="#fig_18">9</ref>) for the future development of novel algorithms with the help of LLMs. The framework supports two complementary paths to designing novel algorithms: (a) improving existing algorithms (Section 4.2.1), and (b) generating entirely novel algorithms from scratch (Section 4.2.2). These two paths diverge at the very first stage based on the nature of the initial idea and objective, which is either to enhance existing algorithmic components or synthesize fundamentally new ones. In both tracks, the process starts by transforming the novel idea for the optimization task into prompting, a set of instructions, to interact with LLMs. With its vast knowledge, the LLM then generates corresponding algorithmic structures and/or code. These candidates are then evaluated for novelty and performance against SOTA, a step that informs iterative refinement through feedback and creative thinking. This cyclic refinement enables continuous evolution either through incremental component upgrades or via first-principle derivations of novel algorithmic designs. The framework thus serves as a unified pipeline for both strategies of innovation: evolutionary enhancement and de novo discovery.</p><p>Prompting  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DRAFT</head><p>The core of this framework revolves around the transition from "idea" to "prompting" and the subsequent evolution of that idea. Existing studies emphasize the need for expert-level prompting in algorithm design, as effective prompting requires not only knowledge of how to craft prompts but also a deep understanding of optimization algorithms to ensure meaningful outcomes. Additionally, the process of refining an idea, often driven by creative thinking, can be partially automated through iterative prompting based on predefined rules or expert knowledge. While some studies suggest that this refinement could be enhanced through another evolutionary process <ref type="bibr" target="#b56">[57]</ref>, such an approach introduces additional complexity and may risk overlooking the expertise embedded in human-driven design <ref type="bibr" target="#b87">[88]</ref>.</p><p>A recent study found that human-GenAI collaboration through differentiated search can lead to more impactful creative problem-solving compared to independent AI-driven or human-only approaches <ref type="bibr" target="#b88">[89]</ref>. Therefore, we advocate for a human-GenAI collaboration in the idea evolution stage, leveraging the strengths of both AI-driven automation and expert intuition. Furthermore, this stage can be significantly strengthened by integrating a robust diagnostic module in the SOTA verification phase, which would systematically highlight weaknesses in the current approach and guide further improvements.</p><p>We observe that while most existing studies in this direction align with aspects of this framework, they do not fully comply with it. Building on this foundation, we can advocate for the future development of novel algorithms by exploring two broader dimension of desinging the novel metaheuirstic algorithm in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Improving Existing Algorithms</head><p>An important avenue to develop a superior metaheuristic algorithm is the enhancement of existing ECs through the integration of LLMs, which attempt to change and introduce some novel mechanisms in the core components of the existing algorithms.</p><p>(i) Core component evolution: LLMs could improve existing metaheuristics with high-level prompting, with the specification of the core components (e.g., mutation operators, selection mechanisms, or base heuristic) the designer wants to change to improve performance like Pluhacek et al. <ref type="bibr" target="#b59">[60]</ref> or EoH framework. This is probably the simplest strategy and less computationally intensive way to improve metaheuristics capability. It is also easy to interpret at the algorithmic level and know the novelty. Of course, its success completely depends on the complexity of the problems at hand. In the future, it will be interesting to develop a modular framework for core metaheuristics component evolution, in which LLMs not only generate alternative designs for core components but also evaluate their synergistic effects across different combinations and problem types, leveraging frameworks like RoEvo.</p><p>(ii) Algorithmic structure or Code level refinement: LLMs can iteratively refine existing algorithms dynamically changing the baseline algorithm code with high-level prompting, as demonstrated in SOMA/SOMA-ATA framework <ref type="bibr" target="#b5">[6]</ref>. A future direction in this line could be building an LLM agent for improving the performance of a baseline algorithm in certain optimization tasks, where LLMs act as autonomous algorithm designers capable of iteratively rewriting and debugging EA code following the framework 9. LLaMEA is one such that integrates GPT-4 into an EA loop to mutate and select metaheuristics algorithms codes based on IOHprofiler benchmarks. One typical issue with this framework is the interpretability and identification of the novelty in generated algorithms.</p><p>(iii) Hybridization of existing metaheuristics: Another promising direction is the hybridization of existing metaheuristics, where different evolutionary paradigms are combined to capitalize on their respective strengths. Traditionally, hybrid metaheuristics have been developed by manually integrating multiple optimization strategies. LLMs can play a crucial role in automating the design of hybrid metaheuristics by identifying optimal combinations of algorithms <ref type="bibr" target="#b61">[62]</ref>, generating hybrid structures, and evaluating their DRAFT performance against SOTA by following the Framework LLaMEA. The hybridization strategies could be further interpretable by adopting the AutoOpt <ref type="bibr" target="#b87">[88]</ref> searching framework, in which the design space of the novel hybrid algorithm includes all core components and strategies of the original algorithms and LLMs with their knowledge bases and feedback on the current version decides which components to invoke to improve performance. Furthermore, hybridization strategies could be instrumental in addressing complex optimization tasks with the support of LLMs. One promising direction is the dynamic adaptation of hybrid EA algorithms during the optimization process, like RoEVO, where LLMs enable the algorithm to evolve its structure and strategy in real time based on intermediate performance feedback. This adaptive capability has the potential to significantly enhance the efficiency, scalability, and robustness of solving complex optimization problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Generating New Algorithms from Scratch</head><p>Beyond conventional hybridization and improvement of existing algorithms, a new frontier in LLMsassisted EA development is the development of an autonomous metaheuristic discovery system, where LLMs learn a taxonomy of algorithmic components (e.g., encodings, operators, fitness adaptation rules) and synthesise entirely new EC.</p><p>(i) First principle discovery: LLMs can derive algorithms from fundamental optimization principles, bypassing existing metaheuristics. ZSO <ref type="bibr" target="#b79">[80]</ref> is one such semi-autonomous framework to generate novel animal-inspired EA architecture by LLMs based on the standard prompt engineering framework CRISPE and then tested with the benchmark. But it is difficult to verify, except the analogy, whether producing algorithms is different from the hybridization of existing metaheuristics.</p><p>(ii) Autonomous Metaheuristic Discovery: LLMs can self-improve through iterative prompting and benchmarking. LLaMEA <ref type="bibr" target="#b11">[12]</ref> provides one such framework for the autonomous development of novel EC, where evolutionary strategies have been adopted for evolving the lists of algorithms generated by LLMs with feedback on performance to guide the search for novel algorithms in terms of performance benchmark. Although LLaMEA is capable of generating superior performance, it has been found that in most cases, it generates hybridized EC. Further, explaining and interpreting such generated algorithms is also very difficult.</p><p>These approaches could complement each other, and their integration may lead to a more powerful framework for discovering novel EC. However, we argue that future frameworks for developing novel EC should prioritize first-principles discovery, that is, the creation of entirely new algorithmic structures from the ground up, based on fundamental principles of optimization or the basic laws governing the search for optimal solutions, rather than relying on established paradigms such as GA, PSO, or DE. In this paradigm, LLMs would autonomously derive fundamental search heuristics by exploring a meta-space of algorithmic abstractions, rather than starting from known metaheuristic building blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Enhancing Decision Support Systems</head><p>Although a promising set of mature EC has been developed over the past decades with some decision support, their application to practical problems for users without specialized knowledge in this area remains quite challenging. This often limits their adoption beyond the research community. LLMs, with their ability to interact through natural language, have the potential to drastically transform decision support in the application of EC by making it not only more effective and efficient but also more transparent and better aligned with human values. Two core aspects are shaping this transformation: first, the role of explainability in increasing transparency and trust in the evolutionary optimization process; and second, the emergence of Human-in-the-Loop optimization frameworks, where human is embedded within an LLM-guided EA pipeline. Explainable Artificial Intelligence (XAI) has become a central concern in AI research, aiming to make machine learning systems more transparent, understandable, and trustworthy <ref type="bibr" target="#b89">[90]</ref>. In the context of EC, explainability is equally critical, as EC often operates as black-box optimizers whose decision-making processes are opaque to users <ref type="bibr" target="#b90">[91]</ref>. LLMs, with their exceptional capacity to process, summarize, and reason about complex patterns, offer a promising avenue to enhance the explainability of EC processes. Leveraging LLMs to interpret, describe, and communicate the inner workings of EC could bridge the gap between sophisticated optimization strategies and human understanding, enabling better trust, control, and adoption of EC methods in sensitive or high-stakes domains.</p><p>Although the intersection of XAI, EC, and LLMs is still emerging, related initiatives are visible across several LLMs enhanced EA improvement frameworks, presented in Table <ref type="table">10</ref>. For example, (i) In OptiPattern framework, LLMs were already used to abstract latent structures from data and guide evolutionary search, hinting at their capacity for semantic interpretation.</p><p>(ii) In evolutionary hyper-heuristic generation frameworks (e.g., ReEvo, EoH), LLMs generate natural language thoughts alongside executable heuristics, naturally embedding a form of self-explanation during the evolutionary process.</p><p>(iii) Surrogate modeling with LLMs offers another indirect pathway to explainability by turning modelassisted evaluation into interpretable, textual inferences, providing insight into how decisions are made without resorting to opaque numerical surrogates.</p><p>While none of these frameworks have been explicitly framed as Explainable EC systems, they demonstrate an important trend: using LLMs' linguistic reasoning abilities to render evolutionary processes more interpretable and self-documenting. Early experimental results suggest that LLMs can capture the rationale behind heuristic design decisions, operator tuning, and search space exploration strategies, which are all critical components for creating genuinely explainable EC frameworks. Looking ahead, Explainable AI for EC with LLMs could evolve along several exciting directions:</p><p>(i) Narrative-Driven Evolution: Instead of only logging metrics, future EC frameworks could generate dynamic evolutionary narratives, where LLMs describe each generation's progress, highlight why specific mutations or selections occurred, and speculate about search trajectories.</p><p>(ii) Post-Hoc Analysis and Visualization: LLMs could be combined with visualization tools to generate human-readable post-hoc reports, offering evolutionary histories, justification for key evolutionary decisions, and analysis of population dynamics.</p><p>(iii) Interactive Explanations: Embedding LLMs into EC platforms could allow users to ask questions about ongoing or completed evolutionary runs ("Why was this solution preferred?", "What mutation operator worked best?") and receive meaningful, context-aware responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Human-in-the-Loop Optimization frameworks</head><p>With advancements in the algorithmic development of EC, LLMs can guide users throughout the entire evolutionary optimization pipeline from problem formulation to algorithm selection and hyperparameter tuning that ultimately improves decision support in complex decisions involving optimization tasks.</p><p>(i) LLMs for Optimization problem formulation: One of the fundamental challenges for non-experts is modelling a real-world problem as an appropriate optimization problem and recognising specific structures in the problem to exploit them to produce accurate and tractable optimization formulations <ref type="bibr" target="#b91">[92]</ref>. LLMs could assist the non-expert users in this direction in the following ways: DRAFT a) Understanding and Structuring Optimization Problems: Users can describe their real-world optimization challenges in natural language, and LLMs can convert them into well-defined evolutionary optimization tasks, specifying objective functions, constraints, and decision variables. There are some initial attempts for the development of machine learning models that turn natural language into optimization formulations <ref type="bibr" target="#b92">[93]</ref> or ChatGPT prompts to formulate the optimization model <ref type="bibr" target="#b91">[92]</ref> (iii) Hyperparameter Tuning for EC: Fine-tuning hyperparameters is crucial for achieving optimal search performance after selecting an appropriate EA. LLMs could help choose the appropriate parameters for EA. A recent study by Martinek et al. <ref type="bibr" target="#b75">[76]</ref> suggested a framework to tune the hyperparameters of the EA from the high-level prompt. A promising direction for future study lies in developing a selfreflective hyperparameter tuning framework, where LLMs not only suggest optimal parameters but also analyze the EA's convergence behavior and performance dynamics in real-time. This would allow the LLM to iteratively refine its parameter recommendations during optimization phases (exploration vs. exploitation), moving beyond static tuning. Such a framework could leverage a feedback loop between LLM reasoning, surrogate performance models, and meta-learning strategies, making the tuning process adaptive, context-aware, and robust across problem domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Challenges and Open Research Questions</head><p>Despite the numerous benefits, the integration of LLMs and EC also presents several challenges, limitations, and open questions that need to be considered in future development. Fig. <ref type="figure" target="#fig_0">10</ref> presents a word cloud of challenges in the synergetic environment of LLM and EC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1.">Computational Complexity and Scalability</head><p>As discussed in Section 2.6, training and operating large LLMs is computationally intensive, requiring substantial memory and processing power <ref type="bibr" target="#b93">[94]</ref>. These demands pose significant challenges even before integration with evolutionary frameworks. When combined with EC, which involves evaluating large populations DRAFT Figure <ref type="figure" target="#fig_0">10</ref>: Challenges in the synergetic environment of LLM and EC over multiple generations, the computational burden of the hybrid EC-LLM system increases substantially. This computational overhead can severely limit feasibility, especially for smaller research groups or applications in resource-constrained environments. Moreover, the search space can become prohibitively large when prompts, architectures, or model parameters are co-evolved. Addressing this challenge will require the use of efficient surrogate models, scalable evaluation strategies, and selective sampling to support a sustainable and accessible hybrid system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2.">Theoretical and Algorithmic Foundations</head><p>The complexity of implementing and integrating two sophisticated paradigms like LLMs and EC can also be a significant challenge. It requires a deep understanding of both fields and careful design to ensure that they work together effectively. A fundamental challenge is defining models that describe how LLM's "learning strategy" and EA's "search strategy" co-evolve. LLMs have complementary strengths (broad knowledge, powerful pattern extraction) while EAs provide flexible, iterative search. Developing theoretical frameworks or metrics to quantify when and why this synergy yields gains (versus using either alone) would guide design of autonomous hybrid systems. <ref type="bibr" target="#b6">[7]</ref>.</p><p>Hybrid systems combine symbolic (language-based) and numeric representations, resulting in vast and poorly understood search spaces. Notably, even defining such a search space for LLM-driven evolution remains unclear, and characterizing its complexity is still an open problem <ref type="bibr" target="#b94">[95]</ref>. Formalizing these representations and their properties, potentially through approaches such as algorithmic information theory <ref type="bibr" target="#b95">[96]</ref>, could help guide the development of more efficient search strategies.</p><p>Understanding algorithmic guarantees for hybrid systems is largely open. Most existing works are empirical <ref type="bibr" target="#b6">[7]</ref>. It is necessary to analyze convergence and complexity for hybrid algorithms (e.g. when LLMs are used as mutation operators or fitness evaluators) <ref type="bibr" target="#b94">[95]</ref>. To better understand how such hybrid algorithms work, we need to ask several key questions, including: When does an LLM-guided EA converge to an optimum or local optimum? and How does the use of LLM queries affect time and space complexity? These analyses would also expose trade-offs between sample/resource cost and solution quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3.">Benchmarking and Evaluation Protocols</head><p>Establishing robust benchmarking protocols for evaluating hybrid EC-LLM systems remains a critical challenge. As these systems blend discrete optimization with language-based reasoning, traditional EC bench-DRAFT marks may not fully capture their capabilities or limitations. There is a growing need for comprehensive, transparent, and diverse benchmarking suites that reflect the unique dynamics of a hybrid EC-LLM system. Recent efforts such as LLM4AD (LLMs for Automated Design) <ref type="bibr" target="#b96">[97]</ref> and BLADE (Benchmarking Language model Agents for Data-driven Science) <ref type="bibr" target="#b97">[98]</ref> represent promising steps toward addressing this gap by providing structured tasks and evaluation protocols tailored to evaluate such hybrid systems. However, community-wide adoption and the development of more challenging, multi-modal, and compositional tasks are needed to robustly assess generalization, creativity, and optimization efficiency. Establishing such benchmarks is critical to ensure fair comparison, reproducibility, and meaningful progress in this emerging research area.</p><p>Further, the evaluation of LLM-generated heuristics also suffers from specific limitations. Common issues include the use of overly simplistic or narrow benchmark problems, which can lead to overfitting and inflated perceptions of performance <ref type="bibr" target="#b98">[99,</ref><ref type="bibr" target="#b99">100]</ref>. The Dagstuhl Seminar <ref type="bibr" target="#b100">[101]</ref> on Challenges in Benchmarking Optimization Heuristics emphasized the need for more rigorous and standardized benchmarking protocols. Key concerns raised include:</p><p>• Cherry-Picked Benchmarks: Selecting benchmark problems that favor the proposed algorithm, thereby skewing performance comparisons <ref type="bibr" target="#b101">[102]</ref>.</p><p>• Lack of Diversity: Using benchmark sets that do not capture the variability and complexity of realworld problems leads to limited generalizability.</p><p>• Inadequate Performance Metrics: Relying on single metrics without considering other aspects like robustness, scalability, and computational efficiency.</p><p>To address these issues, the seminar advocates for the development and adoption of community-wide benchmarking standards <ref type="bibr" target="#b102">[103]</ref>, including:</p><p>• Comprehensive Benchmark Suites: Utilizing diverse and representative problem sets that encompass various domains and difficulty levels <ref type="bibr" target="#b103">[104]</ref>.</p><p>• Transparent Reporting: Providing detailed descriptions of experimental setups, parameter settings, and evaluation criteria to ensure reproducibility.</p><p>• Collaborative Efforts: Encouraging collaboration among researchers to establish and maintain benchmarking repositories and protocols.</p><p>Implementing these practices is crucial for the credible assessment of LLM-generated heuristics and for fostering meaningful advancements in the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4.">Memorization and Long-Term Knowledge Retention Risks</head><p>An important issue in LLM-driven EC is the uncertainty surrounding training/testing overlap, which raises concerns about whether LLM outputs reflect genuine generalization or mere memorization of patterns seen during pretraining <ref type="bibr" target="#b104">[105]</ref>. Since the training data of most LLMs is not publicly disclosed, it is difficult to determine whether high performance in hybrid EC-LLM systems stems from effective problem-solving or the recall of previously encountered solutions. To ensure scientific rigor, future research should focus on creating novel frameworks, using attribution methods to detect memorization, and designing experiments that reduce the risk of training data leakage. Developing such evaluation frameworks is crucial for validating the originality and generalizability of hybrid systems.</p><p>Continuously adapting LLM-based components (e.g. via prompt evolution or online fine-tuning) risks forgetting prior knowledge. Managing resources and memory over long-term evolution is an open problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DRAFT</head><p>For instance, resource limitations and catastrophic forgetting have been identified as critical issues in evolving LLM agents <ref type="bibr" target="#b105">[106]</ref>. To better understand and mitigate such behavior, a key question arises: How can a hybrid system retain valuable prior solutions or knowledge while iteratively refining its prompts, parameters, or populations? Addressing this will require deeper investigation into memory mechanisms and knowledge distillation strategies in hybrid EA-LLM agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.5.">Fitness Design and Semantic Evaluation</head><p>Designing appropriate fitness functions and evaluation metrics is crucial for guiding the evolutionary process, whether it's optimizing LLM parameters or searching for effective prompts <ref type="bibr">[107]</ref>. However, defining these functions, especially when dealing with the nuanced outputs of LLMs, can be non-trivial. Similarly, evaluating the quality of LLM-generated content within the evolutionary loop can be subjective and require sophisticated metrics. Beyond standard fitness measures, hybrid EA-LLM systems may require new metrics such as semantic diversity or factual accuracy <ref type="bibr" target="#b106">[108]</ref> to assess candidate solutions. A central open question is: How should we define and measure "improvement" when LLMs modify or generate candidates? Related challenges include determining whether LLMs can effectively estimate the novelty or quality-diversity of evolving populations, and how to benchmark hybrid systems consistently across different domains. Addressing these questions through standardized evaluation frameworks will be essential for the progress of the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.6.">Distributed and Federated Hybrid Systems</head><p>The integration of LLMs into federated or distributed EAs <ref type="bibr" target="#b107">[109]</ref> represents an emerging and largely unexplored research area. A central challenge is determining how LLMs can effectively coordinate evolutionary search across multiple nodes or agents in large-scale or multi-agent environments. For instance, LLMs may be capable of summarizing and synthesizing information from several evolving sub-populations, thereby facilitating knowledge transfer and improving global search efficiency. Designing robust communication protocols in which LLMs act as "communicators" or "mediators" within distributed evolutionary frameworks is a key open question. Addressing this challenge could lead to more scalable, intelligent, and collaborative evolutionary systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.7.">Interpretability and Explainability</head><p>Interpretability and explainability pose a significant challenge in the integration of LLMs with EC <ref type="bibr" target="#b108">[110]</ref>. LLMs are inherently black-box models, making it difficult to understand the internal reasoning behind their outputs. When combined with EC, which is based on stochastic and non-deterministic search paradigms, the lack of clarity becomes worse, making it harder to understand how and why certain solutions are found. This lack of transparency hinders our ability to interpret the decision-making process within the hybrid system, which is crucial for building user trust, ensuring reproducibility, and enabling further improvements. Without clear explanations for why certain integration strategies or evolved solutions succeed, progress remains largely empirical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This survey demonstrates the transformative synergy between Evolutionary Computation (EC) and Large Language Models (LLMs), revealing how their integration drives innovation in AI optimization and automation. Key findings reinforce that EC techniques significantly enhance LLM performance through automated prompt engineering, hyperparameter tuning, and architecture optimization, reducing reliance on manual intervention. Conversely, LLMs advance EC by automating metaheuristic design, refining evolutionary algorithms, and generating adaptive heuristics, leading to more efficient and scalable solutions. Emerging co-evolutionary frameworks highlight the potential for mutual improvement, with applications spanning robotics, generative DRAFT design, and scientific discovery. However, challenges such as computational costs, interpretability, and convergence stability remain critical barriers. Future research must address these limitations while utilizing hybrid approaches to unlock the full potential of EC-LLM collaboration. By bridging evolutionary search with linguistic intelligence, this synergy paves the way for more autonomous, adaptive, and intelligent AI systems capable of solving complex real-world problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Organization of the paper.</figDesc><graphic coords="3,68.73,43.74,471.71,654.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3</head><label>3</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Few-shotFigure 2 :</head><label>2</label><figDesc>Figure 2: Components of a typical LLM Prompt.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(i) Instruction: Explicitly defines the task the model is expected to perform, such as summarizing text, translating languages, or classifying sentiments. (ii) Context or Examples: Provides additional context or illustrative examples (often referred to as "few-shot examples") to clearly indicate the desired behavior or response pattern. (iii) Input or Query: Presents the specific question or input requiring a response from the model. Consider the following structured example: Input Instruction: Classify the sentiment of the given sentence. For Example, I love sunny weather. → Positive Test Input: This restaurant was disappointing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A General Framework of EC for Prompt Engineering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>DRAFTe)</head><label></label><figDesc>Fewshot: Uses ICL by augmenting existing prompts with a small number (1-3) of labeled examples randomly selected from the training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>DRAFT 3 .</head><label>3</label><figDesc>LLMs for EC Improvement 3.1. LLM-Driven Automated Metaheuristic Design 3.1.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Experimental workflow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Prompt and procedure for regression task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Prompt and procedure for classification task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>(i) Which metaheuristic algorithms would you use to solve a TSP? (ii) I want to solve TSP (defined on 15 cities) with GA. Its mealpy implementation takes the following parameters: parameters. Advise on parameter values. (iii) For the TSP task with 15 cities, you previously suggested parameter values for Genetic Algorithm metaheuristic. Parameters and values. I ran the GA algorithm 100 times and got the average global optimum of 0.375 with a standard deviation of 0.03. I also measured the variance of the population at the beginning and last epoch: 9.598 and 5.675 correspondingly, with std of 0.09 and 0.58. The solution at the last epoch had an average fitness of 0.45 with a standard deviation of 0.37. What changes to the parameters would you suggest to improve performance? Keep the epoch*pop size constant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>DRAFTfour structured tags: P := prompt(Tag1, Tag2, Tag3, Tag4), where: Tag1 = [PROBLEM] formal textual description of the optimization task. Tag2 = [EXAMPLE GRAPH] illustrative graph used to teach structure. Tag3 = [EVALUATION GRAPH] the real instance on which optimization is performed. Tag4 = [RULES ANSWERING] instruction constraints to enforce format and correctness. This design allows the LLM to abstract useful latent structures and patterns from the instance-specific context and translates them into useful probabilistic priors for the MH.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Algorithm 2</head><label>2</label><figDesc>Pseudo code of LMEA Require: Optimization problem T , maximum generations G, population size N Ensure: Best found solution s * 1: Initialize population P with N random solutions for T 2: Set generation counter g ← 1 3: while g ≤ G do 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>{trace 1} {Length of trace 1} {trace 2} {Length of trace 2} {trace 3} {Length of trace 3} ... {trace N} {Length of trace N} Task instructions 1. Select two traces from the above. 2. Crossover the two traces from Step 1 and generate a new trace. 3. Mutate the trace from Step 2 to generate a new trace. 4. Repeat the process until {N} traces are generated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: An overview of LMEA. The right half illustrates a prompt example of solving TSPs using LMEA. Placeholders in {} are replaced dynamically.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Conceptual Overview of LLM-EA Co-Evolution Directions with Framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Unified framework for development of novel metaheuristic algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>DRAFT 4 . 3 . 1 .</head><label>431</label><figDesc>Explainable AI for EC with LLMs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="41,94.93,42.52,419.31,209.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Comparison of the current survey with existing literature on LLM and EC synergy.</figDesc><table><row><cell>Dimension</cell><cell cols="3">Current Work</cell><cell></cell><cell cols="7">[13] [14] [5] [7] [15] [10] [16]</cell></row><row><cell>Bidirectional Focus (LLM↔ EC)</cell><cell>✓</cell><cell>Full</cell><cell>bidirectional</cell><cell>taxonomy</cell><cell>✗</cell><cell>✗</cell><cell cols="2">✗ ✓</cell><cell>✗</cell><cell>✗</cell><cell>✓</cell></row><row><cell></cell><cell cols="3">(LLM→EC, EC→LLM)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Methodological Structure</cell><cell cols="4">✓ Detailed subsections: soft prompting,</cell><cell>✓</cell><cell>✗</cell><cell cols="2">✓ ✓</cell><cell>✗</cell><cell>✓</cell><cell>✗</cell></row><row><cell></cell><cell cols="3">EA synergy, tuning strategies</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tooling and Frameworks</cell><cell cols="4">✓ EvoPrompt, GAAPO, PhaseEvo,</cell><cell>✗</cell><cell>✗</cell><cell>✗</cell><cell>✗</cell><cell>✗</cell><cell>✗</cell><cell>✗</cell></row><row><cell></cell><cell cols="2">prompt modes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Applications Mapped to Methods</cell><cell cols="4">✓ Neural search, code gen, VLMs, rein-</cell><cell>✗</cell><cell>✗</cell><cell cols="2">✓ ✓</cell><cell>✗</cell><cell>✗</cell><cell>✗</cell></row><row><cell></cell><cell cols="3">forcement tasks</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Hybrid Evolution-Language Systems</cell><cell cols="4">✓ GP + LLM, Co-evolution, DSL gener-</cell><cell>✗</cell><cell>✗</cell><cell cols="2">✗ ✓</cell><cell>✗</cell><cell>✗</cell><cell>✗</cell></row><row><cell></cell><cell>ation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Novelty in LLM-Based Operator Design ✓ Mutation, crossover, and fitness eval</cell><cell>✗</cell><cell>✗</cell><cell cols="2">✓ ✓</cell><cell>✗</cell><cell>✗</cell><cell>✗</cell></row><row><cell></cell><cell cols="2">via LLM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Prompt Engineering Depth</cell><cell cols="4">✓ Prompt design, auto-prompt, reinforce-</cell><cell>✗</cell><cell>✗</cell><cell cols="2">✓ ✗</cell><cell>✗</cell><cell>✓</cell><cell>✗</cell></row><row><cell></cell><cell cols="3">ment in prompt cycles</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Explicit Synergy Framework Provided</cell><cell cols="4">✓ LLM-EC interaction models, roles,</cell><cell>✗</cell><cell>✓</cell><cell cols="2">✓ ✓</cell><cell>✗</cell><cell>✗</cell><cell>✓</cell></row><row><cell></cell><cell cols="2">flow diagrams</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Empirical Use Cases/Benchmarks</cell><cell cols="4">✓ Survey of tasks, datasets, output types</cell><cell>✗</cell><cell>✗</cell><cell cols="2">✓ ✓</cell><cell>✗</cell><cell>✓</cell><cell>✗</cell></row><row><cell></cell><cell cols="3">(e.g., Bin Packing, TSP, DSLs)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Future Directions &amp; Research Gaps</cell><cell cols="4">✓ Co-evolution, explainability, LLM-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">tuned DSLs, evaluation bottlenecks</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Feature Comparison of EvoPrompt, PhaseEvo, and GAAPO.</figDesc><table><row><cell>Feature</cell><cell>EvoPrompt</cell><cell>PhaseEvo</cell><cell></cell><cell>GAAPO</cell></row><row><cell>Primary Goal</cell><cell>Discrete Prompt Optimiza-</cell><cell cols="2">Unified Instruction &amp; Example Op-</cell><cell>Hybrid Prompt Optimization via Strategy</cell></row><row><cell></cell><cell>tion</cell><cell>timization</cell><cell></cell><cell>Integration</cell></row><row><cell>Core Algorithm</cell><cell>Genetic Algorithm (GA) /</cell><cell cols="2">Custom Multi-Phase Evolutionary</cell><cell>Genetic Algorithm (GA) as Controller</cell></row><row><cell></cell><cell>Differential Evolution (DE)</cell><cell>Algorithm</cell><cell></cell><cell></cell></row><row><cell>LLM Role</cell><cell>Implements Generic EA Op-</cell><cell cols="2">Implements Phased Operators</cell><cell>Component within Diverse Generation</cell></row><row><cell></cell><cell>erators (Crossover, Mutation)</cell><cell cols="2">(Feedback, EDA, Crossover, Se-</cell><cell>Strategies (OPRO-like, APO-like, etc.)</cell></row><row><cell></cell><cell></cell><cell>mantic Mut.)</cell><cell></cell><cell></cell></row><row><cell>Optimization Target</cell><cell>Primarily Instruction</cell><cell cols="2">Joint Instruction &amp; Examples</cell><cell>Primarily Instruction (with Few-shot</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Generator for Examples)</cell></row><row><cell>Key Operators/Strat.</cell><cell>LLM-based Crossover, LLM-</cell><cell>Feedback Mut.,</cell><cell>EDA Mut.,</cell><cell>OPRO-like, APO-like, Random Mutator</cell></row><row><cell></cell><cell>based Mutation</cell><cell cols="2">Crossover Mut., Semantic Mut.</cell><cell>(8 types), Crossover, Few-shot</cell></row><row><cell>Evaluation</cell><cell>Dev Set Score</cell><cell>Dev Set Score</cell><cell></cell><cell>Flexible: Complete, Successive Halving,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bandit Selection</cell></row><row><cell>Notable Innovations</cell><cell>LLM as direct EA operator;</cell><cell cols="2">Unified ICL optimization; Multi-</cell><cell>Hybrid integration of multiple APO</cell></row><row><cell></cell><cell>Gradient-free black-box opt.</cell><cell cols="2">phase structure; Task-aware simi-</cell><cell>strategies; Flexible evaluation; Trade-off</cell></row><row><cell></cell><cell></cell><cell>larity metric</cell><cell></cell><cell>analysis</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of Features, Strengths, Limitations, and Application Domains for EvoPrompt, PhaseEvo, and GAAPO.</figDesc><table><row><cell>Features</cell><cell>EvoPrompt</cell><cell>PhaseEvo</cell><cell>GAAPO</cell></row><row><cell>Strengths</cell><cell>Pioneered the framework connecting</cell><cell>Addresses the interplay between in-</cell><cell>Uses the strengths of multiple diverse</cell></row><row><cell></cell><cell>LLMs and EC for discrete prompt</cell><cell>structions and examples for potentially</cell><cell>prompt optimization strategies within</cell></row><row><cell></cell><cell>optimization.</cell><cell>better performance.</cell><cell>a single framework.</cell></row><row><cell></cell><cell>Applicable to black-box LLMs with-</cell><cell>Balances global exploration and local</cell><cell>Implemented as a flexible framework</cell></row><row><cell></cell><cell>out needing internal access.</cell><cell>exploitation effectively.</cell><cell>(HOPR) with adaptable components,</cell></row><row><cell></cell><cell>Generates human-readable and inter-</cell><cell>Innovative metric promotes functional</cell><cell>particularly in evaluation methods.</cell></row><row><cell></cell><cell>pretable natural language prompts.</cell><cell>diversity based on performance.</cell><cell>The portfolio approach may lead to</cell></row><row><cell></cell><cell>Demonstrated significant improve-</cell><cell>Demonstrated significant improve-</cell><cell>more robust performance and bet-</cell></row><row><cell></cell><cell>ments over manual prompts and earlier</cell><cell>ments over strong baselines across</cell><cell>ter generalization compared to single-</cell></row><row><cell></cell><cell>APO methods across diverse tasks in</cell><cell>diverse benchmarks.</cell><cell>strategy methods.</cell></row><row><cell></cell><cell>initial studies.</cell><cell>Can generate zero-shot or few-shot</cell><cell>Provides a testbed for analyzing</cell></row><row><cell></cell><cell>Motivated by the potential for good</cell><cell>prompts and adapt the prompt length.</cell><cell>key optimization trade-offs (popula-</cell></row><row><cell></cell><cell>performance and fast convergence</cell><cell>Claimed to maintain good computa-</cell><cell>tion size vs. generations, evaluation</cell></row><row><cell></cell><cell>associated with EC.</cell><cell>tional efficiency compared to some</cell><cell>cost vs. accuracy).</cell></row><row><cell></cell><cell></cell><cell>evolutionary strategies, despite the</cell><cell>Enables analysis of the relative effec-</cell></row><row><cell></cell><cell></cell><cell>complexity.</cell><cell>tiveness and evolution of different gen-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>eration strategies over the optimization</cell></row><row><cell></cell><cell></cell><cell></cell><cell>process.</cell></row></table><note>Limitations Performance trajectory can be unstable, sometimes failing to improve or even degrading performance compared to initial prompts or other methods like OPRO. Comparative studies show that Evo-Prompt is outperformed by newer techniques like PhaseEvo, StraGo, and GReaTer on various benchmarks. Relies on the LLM's ability to interpret and execute abstract evolutionary operations ("crossover", "mutate") based on fixed natural language instructions. The effectiveness likely depends significantly on the capability of the LLM used to perform the evolutionary operations. Susceptible to prompt drift, where optimizing for some cases negatively impacts others. Concerns were raised about the lack of concrete details on the evaluation process, especially for complex prompts. While potentially more efficient than some EC, it still requires a considerable number of LLM API calls ( 4000 mentioned for 12 iterations). Performance can vary depending on the chosen initialization strategy (reverse engineering vs. expert prompt). Effectiveness hinges on the capabilities of the underlying LLM used for the various mutation and evaluation steps. The multi-phase design with specialized operators is more complex to implement and understand than simpler methods. Potential for Drift: Like other APO methods, it may still be susceptible to prompt drift. Managing multiple distinct generation strategies within a GA framework increases implementation complexity compared to simpler methods. Performance gains are highly dependent on the specific task and the potential for improvement over baseline prompts. Susceptible to overfitting, particularly with larger population sizes. While offering efficient evaluation options like bandit selection, the overall process can still be computationally intensive due to repeated LLM calls. The overall effectiveness is bounded by the quality and complementarity of the integrated generator strategies (OPRO, APO, etc.) and the capability of the LLM used.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Summary of EA applications in LLM hyperparameter optimization across studies.</figDesc><table><row><cell>Study/Method</cell><cell>EA used</cell><cell cols="2">Targeted Hyperparameters LLM/Task</cell><cell></cell><cell>Key Finding/Contribution</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Context</cell><cell></cell></row><row><cell>AutoTinyBERT [46]</cell><cell>Custom EA</cell><cell>Architectural Dims, Layers</cell><cell cols="2">BERT / Ef-</cell><cell>Automated architectural HPO using</cell></row><row><cell></cell><cell>(Evolver)</cell><cell>(l t , d m , etc.)</cell><cell>ficiency</cell><cell>(La-</cell><cell>EA and SuperPLM proxy for effi-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>tency)</cell><cell></cell><cell>cient PLMs.</cell></row><row><cell>Custode et al. [47]</cell><cell>ES + LLM</cell><cell>ES Step-Size</cell><cell cols="2">(1+1)-ES Opti-</cell><cell>LLMs can analyze logs and provide</cell></row><row><cell></cell><cell>Advisor</cell><cell></cell><cell>mization</cell><cell></cell><cell>real-time EA hyperparameter (step-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>size) recommendations.</cell></row><row><cell>Evolutionary Merg-</cell><cell>CMA-ES</cell><cell>Model Merging Recipe,</cell><cell>Foundation</cell><cell></cell><cell>EA automates the discovery of opti-</cell></row><row><cell>ing [8]</cell><cell></cell><cell>(TIES/DARE)</cell><cell cols="2">Model Merging</cell><cell>mal merging hyperparameters, sur-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>passing manual intuition.</cell></row><row><cell>LMEA [9]</cell><cell>LLM-driven</cell><cell>LLM Temperature, (Self-</cell><cell cols="2">Combinatorial</cell><cell>LLM integrated into EA loop with</cell></row><row><cell></cell><cell>EA</cell><cell>Adaptation)</cell><cell cols="2">Opt. (TSP) via</cell><cell>self-adapting temperature for ex-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>LLM+EA</cell><cell></cell><cell>ploration/exploitation.</cell></row><row><cell>Tani et al. [48]</cell><cell>GA, PSO</cell><cell>General ML Hyperparame-</cell><cell cols="2">ML for High</cell></row><row><cell></cell><cell></cell><cell>ters</cell><cell cols="2">Energy Physics</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Comparative overview of EA applications in LLM hyperparameter optimization.</figDesc><table><row><cell>Targeted Hyperparameters</cell><cell>Evolutionary Techniques Employed</cell><cell cols="2">Case Studies and Examples</cell><cell></cell></row><row><cell>Architectural Hyperparameters:</cell><cell>Custom EC:</cell><cell>AutoTinyBERT:</cell><cell></cell><cell></cell></row><row><cell>• Number of Transformer layers</cell><cell>• AutoTinyBERT's "Evolver"</cell><cell cols="3">• Optimizes BERT architecture (lay-</cell></row><row><cell>• Hidden state dimension</cell><cell>-Selection via performance</cell><cell cols="2">ers, dimensions)</cell><cell></cell></row><row><cell>• Number of attention heads</cell><cell>ranking -Mutation of hyperparameters</cell><cell cols="3">• Uses Evolver + Evaluator compo-nents</cell></row><row><cell>• Feed-forward network intermediate size</cell><cell>-Architecture exploration</cell><cell cols="3">• Leverages "SuperPLM" proxy model</cell></row><row><cell>Methods: AutoTinyBERT (as HPO), SuperShaper, LiteTransformerSearch (as</cell><cell></cell><cell cols="3">• Incorporates latency predictor</cell></row><row><cell>NAS)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model Merging Hyperparameters:</cell><cell>Evolution Strategies (ES):</cell><cell cols="3">LLM-Guided Step-Size Adaptation:</cell></row><row><cell>• Parameters for TIES-Merging +</cell><cell>• (1+1)-ES with LLM-guided adap-</cell><cell cols="2">• Uses Llama2-70b, Mixtral</cell><cell></cell></row><row><cell>DARE</cell><cell>tation</cell><cell cols="2">• LLM analyzes (1+1)-ES logs</cell><cell></cell></row><row><cell>• Weight combination strategies</cell><cell></cell><cell cols="3">• Provides real-time step-size recom-</cell></row><row><cell>Optimized via CMA-ES</cell><cell></cell><cell>mendations</cell><cell></cell><cell></cell></row><row><cell>EA-Specific Hyperparameters:</cell><cell>Covariance Matrix Adaptation ES (CMA-</cell><cell cols="2">Evolutionary Model Merging:</cell><cell></cell></row><row><cell>• Step-size in Evolution Strategies</cell><cell>ES):</cell><cell>• CMA-ES</cell><cell>optimizes</cell><cell>TIES-</cell></row><row><cell>• Temperature parameter in LMEA</cell><cell>• Used for continuous optimization</cell><cell cols="2">Merging+DARE</cell><cell></cell></row><row><cell>• Self-adaptation mechanisms</cell><cell>• Applied to model merging parame-ters</cell><cell cols="3">• Creates superior merged models • Targets Open LLM Leaderboard</cell></row><row><cell></cell><cell></cell><cell>performance</cell><cell></cell><cell></cell></row><row><cell>General ML Hyperparameters:</cell><cell>Genetic Algorithms &amp; PSO:</cell><cell></cell><cell></cell><cell></cell></row><row><cell>• Learning rate, batch size, dropout</cell><cell>• General HPO methods</cell><cell></cell><cell></cell><cell></cell></row><row><cell>• Potential applications via GA/PSO</cell><cell>• Applicable to LLM training</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Evolutionary NAS for LLMs: Architectural Aspects and Methods.</figDesc><table><row><cell>Category</cell><cell>Description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Summary of Evolutionary Approaches for Neural Architecture Search.</figDesc><table><row><cell>Study/Method</cell><cell cols="2">EA/Search Technique Optimized Aspects</cell><cell cols="2">Objectives/Metrics</cell><cell>Key Finding/Contribution</cell></row><row><cell>AutoBERT-Zero</cell><cell>EA (Custom)</cell><cell>BERT Backbone Struc-</cell><cell cols="3">Performance (Implied) Evolved universal LLM back-</cell></row><row><cell></cell><cell></cell><cell>ture</cell><cell></cell><cell></cell><cell>bones from scratch using EA-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>based NAS.</cell></row><row><cell>DistilBERT NAS</cell><cell>NSGA-II (MOEA)</cell><cell>Attention Heads, FFN</cell><cell cols="2">QA Perf. (F1/EM) vs.</cell><cell>Applied MOEA for NAS</cell></row><row><cell></cell><cell></cell><cell>(Activation/Layers/-</cell><cell>Model Size</cell><cell></cell><cell>on DistilBERT under budget,</cell></row><row><cell></cell><cell></cell><cell>Size), Encoder Blocks</cell><cell></cell><cell></cell><cell>showing efficient exploration.</cell></row><row><cell>LLMatic</cell><cell>QD (MAP-Elites) +</cell><cell>Code-level (CNNs ini-</cell><cell cols="2">Accuracy + Diversity</cell><cell>Novel dual-archive QD ap-</cell></row><row><cell></cell><cell>LLM</cell><cell>tially)</cell><cell cols="2">(Width/Depth, FLOPS)</cell><cell>proach using LLM for code-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>level variation, seeking di-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>verse networks.</cell></row><row><cell>EvoPrompting</cell><cell>LM Operator + Evo-</cell><cell>Code-level (GNNs)</cell><cell cols="2">Performance + Diver-</cell><cell>LM as adaptive operator; evo-</cell></row><row><cell></cell><cell>Prompting</cell><cell></cell><cell>sity (Implied)</cell><cell></cell><cell>lutionary prompt engineer-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ing + tuning finds superior</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>GNNs.</cell></row><row><cell cols="2">LiteTransformerSearch MOEA</cell><cell>Decoder Layer Hyper-</cell><cell cols="2">Perplexity vs. Latency</cell><cell>Training-free MOEA-NAS</cell></row><row><cell></cell><cell></cell><cell>parameters</cell><cell>vs. Memory</cell><cell></cell><cell>for efficient GPT-2 style</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>models.</cell></row><row><cell>SuperShaper [51]</cell><cell>EA (Implied)</cell><cell>Hidden Dimensions</cell><cell>Task-Agnostic</cell><cell>Pre-</cell><cell>Searched hidden dimensions</cell></row><row><cell></cell><cell></cell><cell></cell><cell>training</cell><cell></cell><cell>for BERT using EC.</cell></row><row><cell>Klein et al. [54]</cell><cell>MOEA (Implied)</cell><cell>Subnetwork Structures</cell><cell cols="2">Performance vs. Model</cell><cell>Used MOEA for multi-</cell></row><row><cell></cell><cell></cell><cell>(Pruning)</cell><cell>Size</cell><cell></cell><cell>objective structural pruning</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>of LLMs via NAS.</cell></row><row><cell>Choong et al. [55]</cell><cell>MO-MFEA</cell><cell>Model Configurations</cell><cell>Multi-Task</cell><cell>Perfor-</cell><cell>Used multi-objective multi-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>mance vs. Size</cell><cell></cell><cell>task EA to find specialized</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>smaller models from founda-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>tion models.</cell></row><row><cell>GPT-NAS [56]</cell><cell>EA + LLM</cell><cell>Network Architecture</cell><cell cols="3">Performance (Implied) Used LLM's generative capa-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>bility within EA framework</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>for NAS.</cell></row><row><cell cols="2">Guided Evolution [57] EA + LLM</cell><cell>Code-level Models</cell><cell cols="3">Performance (Implied) Used LLM guidance within</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>an evolutionary framework</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>for model improvement.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>3. Respond using JSON format, e.g. 'Value': 'approximation result'</figDesc><table><row><cell>Features: &lt;0.338, 0.531, ..., 0.363&gt;; Value: 0.41148</cell><cell></cell></row><row><cell>Features: &lt;0.207, 0.598, ..., 0.285&gt;; Value: 0.35745 ...</cell><cell>Note: Respond in JSON with the format 'Value': 'approximation result' only.</cell></row><row><cell>Features: &lt;0.629, 0.029, ..., 0.279&gt;; Value: 0.67179</cell><cell></cell></row><row><cell>Features: &lt;0.189, 0.917, ..., 0.443&gt;</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Three types of prompts used in Ref.<ref type="bibr" target="#b75">[76]</ref>.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Enhancing LLMs (EA → LLM)</figDesc><table><row><cell cols="2">LLM Enhancing EC (LLM → EA)</cell></row><row><cell>Prompt Optimization</cell><cell>Heuristic Generation</cell></row><row><cell>Hyperparameter Tuning</cell><cell>Operator Tuning</cell></row><row><cell>Architecture Search</cell><cell>Surrogate Modeling</cell></row><row><cell>Multi-step Prompt Design</cell><cell>Pattern Recognition</cell></row><row><cell>(e.g., GPS (2022), GrIPS</cell><cell>(e.g., GPT-4 Metaheuristics (2023),</cell></row><row><cell>(2022), EvoPrompting (2023),</cell><cell>EoH (2023), MEoH (2023),</cell></row><row><cell>PROMST (2024), GAAPO (2024))</cell><cell>ReEvo (2024), OptiPattern (2024))</cell></row><row><cell cols="2">Synergistic Co-Evolution (EA ↔ LLM)</cell></row><row><cell cols="2">Bidirectional Feedback Loops</cell></row><row><cell>Self-Improving Systems</cell><cell></cell></row><row><cell>Multi-phase Evolution</cell><cell></cell></row><row><cell cols="2">(e.g., PhaseEvo (2024), Prompt-</cell></row><row><cell cols="2">breeder (2023), EvoPrompt (2023)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12 :</head><label>12</label><figDesc>Application Areas of LLM-EA Integration.</figDesc><table><row><cell>Application Area</cell><cell>Description</cell><cell>Examples</cell></row><row><cell>Prompt Engineering</cell><cell>Automating the design of effective</cell><cell>EvoPrompt framework for various NLP tasks, Evolu-</cell></row><row><cell></cell><cell>prompts for LLMs</cell><cell>tionary multi-objective prompt optimization</cell></row><row><cell>Automated Machine Learn-</cell><cell>Automating the design and optimization</cell><cell>Feature selection, model selection, hyperparameter</cell></row><row><cell>ing (AutoML)</cell><cell>of ML pipelines</cell><cell>tuning guided by LLMs and optimized by EC</cell></row><row><cell>Robotics and Autonomous</cell><cell>Evolving robot control and communica-</cell><cell>Optimizing robot navigation, human-robot interac-</cell></row><row><cell>Systems</cell><cell>tion strategies</cell><cell>tion, and multi-agent coordination</cell></row><row><cell>Generative Design and Cre-</cell><cell>Generating novel art, music, and game</cell><cell>Evolving prompts for image and music generation,</cell></row><row><cell>ative Content Gen.</cell><cell>content</cell><cell>creating new game levels and characters</cell></row><row><cell>Synthetic Biology and Drug</cell><cell>Evolving proteins and genes, predicting</cell><cell>Designing novel proteins for specific functions, Op-</cell></row><row><cell>Discovery</cell><cell>molecular interactions</cell><cell>timizing drug candidates based on predicted interac-</cell></row><row><cell></cell><cell></cell><cell>tions</cell></row><row><cell>Recommender Systems</cell><cell>Enhancing recommendation accuracy and</cell><cell>Optimizing recommendation prompts, Improving rec-</cell></row><row><cell></cell><cell>diversity</cell><cell>ommendations for long-tail items and users using</cell></row><row><cell></cell><cell></cell><cell>LLM embeddings and evolutionary strategies</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>. It will be interesting in the future to explore the capability of LLMs in formulating the appropriate optimization problem from a natural language description. b) Identifying Problem Categories: LLMs could classify the problem as single-objective, multi-objective, constrained, combinatorial, or dynamic optimization, ensuring the selection of an appropriate EA approach. The capability of LLMs in this direction has not been explored yet. c) Suggesting Problem Transformations: For highly complex or non-convex problems, LLMs could recommend problem reformulations, such as encoding transformations or decomposition strategies to improve the efficiency of evolutionary search. This direction is also yet to be investigated. Future research could develop an LLM agent for problem reframing, wherein LLMs autonomously analyze problem structures and suggest strategic reformulations. (ii) Algorithm Recommendation: Selecting the most suitable EA variant for a given problem is critical for achieving high performance. LLMs could act as intelligent EA advisors by: a) Matching Problem Characteristics to Suitable EA Variants: Based on the problem characteristics, LLMs can recommend appropriate EA paradigms.</figDesc><table /><note>b) Justifying Algorithm Selection: LLMs can provide explanations on why a specific EA framework is best suited for a given problem, considering exploration-exploitation balance, scalability, and robustness. c) Generating EA Variants Dynamically: LLMs can propose novel EC by analyzing the problem characteristics and invoking one of the novel algorithm design faces to enhance performance.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://github.com/google-deepmind/funsearch</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://ai4co.github.io/reevo</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">For a COP with solution space S and objective function f : S → R, a HH searches for the optimal heuristic h * in a heuristic space H such that a meta-objective function F : H → R is minimized, i.e., h * = arg min h∈H F(h). A LHH is an HH variant where heuristics in H are generated by LLMs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://zenodo.org/records/13268663</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">https://zenodo.org/records/13834123</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">https://github.com/tennisonliu/LLAMBO,https://github.com/vanderschaarlab/LLAMBO</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work was supported by Dr B. R. Ambedkar National Institute of Technology Jalandhar, the Anusandhan National Research Foundation, Government of India (Award No. MTR/2021/000503), the Australian Researcher Cooperation Hub through the Australia-India Women Researchers' Exchange Program, and the Spanish Ministry of Economy and Competitiveness through the Ramón y Cajal Research Grant (Award No. RYC2023-045020-I).</p><p>Compliance with ethical standards</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conflict of interest: All the authors declare that they have no conflict of interest. Ethical approval: This article does not contain any studies with human participants or animals performed by any of the authors.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Do large language models know what they don</title>
		<author>
			<persName><forename type="first">Zhangyue</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiushi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qipeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18153</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">t know? arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A survey of large language models</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beichen</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zican</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.18223</idno>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bartz-Beielstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jörn</forename><surname>Mehnen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olaf</forename><surname>Mersmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="178" to="195" />
			<date type="published" when="2014">2014</date>
			<publisher>Wiley Interdisciplinary Reviews</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A comprehensive survey on artificial electric field algorithm: theories and applications</title>
		<author>
			<persName><forename type="first">Dikshit</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anupam</forename><surname>Yadav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Archives of Computational Methods in Engineering</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2663" to="2715" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Deep insights into automated optimization with large language models and evolutionary algorithms</title>
		<author>
			<persName><forename type="first">He</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.20848</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using llm for automatic evolvement of metaheuristics from swarm algorithm soma</title>
		<author>
			<persName><forename type="first">Michal</forename><surname>Pluhacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jozef</forename><surname>Kovac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Viktorin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Janku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Kadavy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Senkerik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference Companion</title>
				<meeting>the Genetic and Evolutionary Computation Conference Companion</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="2018" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Evolutionary computation in the era of large language model: Survey and roadmap</title>
		<author>
			<persName><forename type="first">Xingyu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng-Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jibin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kay</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Evolutionary optimization of model merging recipes</title>
		<author>
			<persName><forename type="first">Takuya</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Makoto</forename><surname>Shing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ke Tang, and Yew-Soon Ong. Large language models as evolutionary optimizers</title>
		<author>
			<persName><forename type="first">Shengcai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caishun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinghua</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation (CEC)</title>
		<imprint>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2024">2024. 2024</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Unleashing the potential of prompt engineering in large language models: a comprehensive review</title>
		<author>
			<persName><forename type="first">Banghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaofeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Langrené</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengxin</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.14735</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Connecting large language models with evolutionary algorithms yields powerful prompt optimizers</title>
		<author>
			<persName><forename type="first">Qingyan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junliang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujiu</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Llamea: A large language model evolutionary algorithm for automatically generating metaheuristics</title>
		<author>
			<persName><forename type="first">Niki</forename><surname>Van Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bäck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A systematic survey on large language models for algorithm design</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xialiang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenkun</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.14716</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An era of chatgpt as a significant futuristic support tool: A study on features, abilities, and challenges</title>
		<author>
			<persName><forename type="first">Abid</forename><surname>Haleem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohd</forename><surname>Javaid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><forename type="middle">Pratap</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BenchCouncil transactions on benchmarks, standards and evaluations</title>
				<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">100089</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploring the improvement of evolutionary computation via large language models</title>
		<author>
			<persName><forename type="first">Jinyu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinglue</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takuto</forename><surname>Yamauchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hitoshi</forename><surname>Iba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenji</forename><surname>Tei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference Companion</title>
				<meeting>the Genetic and Evolutionary Computation Conference Companion</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="83" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">When large language model meets optimization. Swarm and Evolutionary Computation</title>
		<author>
			<persName><forename type="first">Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaixiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page">101663</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Llmatic: neural architecture search via large language models and quality diversity optimization</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Muhammad Umair Nasir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Earle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><surname>Cleghorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the Genetic and Evolutionary Computation Conference</title>
				<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1110" to="1118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Llm-informed discrete prompt optimization</title>
		<author>
			<persName><forename type="first">Zeeshan</forename><surname>Memon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Arham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adnan</forename><surname>Ul-Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Shafait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2024 Workshop on LLMs and Cognition</title>
				<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Model-driven prompt engineering</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Clarisó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Cabot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems (MODELS)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Prompt engineering a prompt engineer</title>
		<author>
			<persName><forename type="first">Qinyuan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxamed</forename><surname>Axmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reid</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fereshte</forename><surname>Khani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.05661</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">More samples or more prompts? exploring effective in-context sampling for llm few-shot prompt engineering</title>
		<author>
			<persName><forename type="first">Bingsheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guiming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruishi</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yisi</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Hendler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dakuo</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.09782</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Active prompting with chain-ofthought for large language models</title>
		<author>
			<persName><forename type="first">Shizhe</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.12246</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Msprompt: Multi-step prompt learning for debiasing few-shot event detection</title>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianming</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueshan</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">103509</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cathy</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joanna</forename><surname>Crofts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Draycott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Muchatuta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>PROMPT course manual</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Prompting ai art: An investigation into the creative skill of prompt engineering</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Oppenlaender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rhema</forename><surname>Linder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johanna</forename><surname>Silvennoinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of human-computer interaction</title>
		<imprint>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms and their applications to engineering problems</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Slowik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Halina</forename><surname>Kwasnicka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Computing and Applications</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="12363" to="12379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery</title>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Kirchenbauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micah</forename><surname>Goldblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Geiping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="51008" to="51025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning how to ask: Querying lms with mixtures of soft prompts</title>
		<author>
			<persName><forename type="first">Guanghui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.06599</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Gps: Genetic prompt search for efficient few-shot learning</title>
		<author>
			<persName><forename type="first">Hanwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.17041</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Grips: Gradient-free, edit-based instruction search for prompting large language models</title>
		<author>
			<persName><forename type="first">Archiki</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Hase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.07281</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Automatic engineering of long prompts</title>
		<author>
			<persName><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Si</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inderjit S</forename><surname>Dhillon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.10117</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Connecting large language models with evolutionary algorithms yields powerful prompt optimizers</title>
		<author>
			<persName><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Song</surname></persName>
		</author>
		<author>
			<persName><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.08532</idno>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Promptbreeder: Self-referential self-improvement via prompt evolution</title>
		<author>
			<persName><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.16797</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Evoprompting: Language models for code-level neural architecture search</title>
		<author>
			<persName><forename type="first">Angelica</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>So</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="7787" to="7817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Phaseevo: Towards unified in-context prompt optimization for large language models</title>
		<author>
			<persName><forename type="first">Wendi</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuohang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Malin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sricharan</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.11347</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Prompt optimization in multi-step tasks (promst): Integrating human feedback and heuristic-based sampling</title>
		<author>
			<persName><forename type="first">Yongchao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Arkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yilun</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuchu</forename><surname>Fan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.08702</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Evolutionary multi-objective optimization of large language model prompts for balancing sentiments</title>
		<author>
			<persName><forename type="first">Jill</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on the applications of evolutionary computation (part of evoStar)</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="212" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Genetic auto-prompt learning for pre-trained code intelligence language models</title>
		<author>
			<persName><forename type="first">Chengzhe</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancheng</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aojun</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.13588</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Generative ai-based prompt evolution engineering design optimization with vision-language model</title>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Menzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yew Soon</forename><surname>Ong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.09143</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Prompt-aligned gradient for prompt tuning</title>
		<author>
			<persName><forename type="first">Beier</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulei</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yucheng</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
				<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="15659" to="15669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Tianjun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.11890</idno>
		<title level="m">Tempera: Test-time prompting via reinforcement learning</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">A sequential optimal learning approach to automated prompt engineering in large language models</title>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somayeh</forename><surname>Moazeni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Klabjan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2501.03508</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Phaseevo: Towards unified in-context prompt optimization for large language models</title>
		<author>
			<persName><forename type="first">Wendi</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuohang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Malin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sricharan</forename><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Gaapo: Genetic algorithmic applied to prompt optimization</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Sécheresse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacques-Yves</forename><surname>Guilbert-Ly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Villedieu De Torcy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Autohint: Automatic prompt optimization with hint generation</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xue</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinchuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youkow</forename><surname>Homma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Charles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Autotinybert: Automatic hyperparameter optimization for efficient pre-trained language models</title>
		<author>
			<persName><forename type="first">Yichun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">An investigation on the use of large language models for hyperparameter tuning in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Lucio Custode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Caraffini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anil</forename><surname>Yaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Iacca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference Companion</title>
				<meeting>the Genetic and Evolutionary Computation Conference Companion</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1838" to="1845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms for hyperparameter optimization in machine learning for application in high energy physics</title>
		<author>
			<persName><forename type="first">Laurits</forename><surname>Tani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Rand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Veelken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Kadastik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The European Physical Journal C</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">A survey on intelligent network operations and performance optimization based on large language models</title>
		<author>
			<persName><forename type="first">Sifan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bomin</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengxiao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangfan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nei</forename><surname>Kato</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
			<publisher>IEEE Communications Surveys &amp; Tutorials</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Autobertzero: Evolving bert backbone from scratch</title>
		<author>
			<persName><forename type="first">Jiahui</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaozhe</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="10663" to="10671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Supershaper: Task-agnostic super pre-training of bert models with variable hidden dimensions</title>
		<author>
			<persName><forename type="first">Vinod</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gowtham</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratyush</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.04711</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Litetransformersearch: Training-free neural architecture search for efficient language models</title>
		<author>
			<persName><forename type="first">Mojan</forename><surname>Javaheripi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><forename type="middle">H</forename><surname>De Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhabrata</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shital</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomasz</forename><forename type="middle">L</forename><surname>Religa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Caio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastien</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farinaz</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debadeepta</forename><surname>Koushanfar</surname></persName>
		</author>
		<author>
			<persName><surname>Dey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Resource-constrained neural architecture search on language models: A case study</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Paraskeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joao</forename><forename type="middle">Pedro</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">N</forename><surname>Van Rijn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Workshop on Advancing Neural Network Training: Computational Efficiency, Scalability, and Resource Optimization (WANT@ ICML 2024</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Structural pruning of pre-trained language models via neural architecture search</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacek</forename><surname>Golebiowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingchen</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cedric</forename><surname>Valerio Perrone</surname></persName>
		</author>
		<author>
			<persName><surname>Archambeau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.02267</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Jack and masters of all trades: one-pass learning sets of model sets from large pre-trained models</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Choong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Yew-Soon</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caishun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="29" to="40" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Gpt-nas: Evolutionary neural architecture search with the generative pre-trained model</title>
		<author>
			<persName><forename type="first">Caiyang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianggen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenwei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancheng</forename><surname>Lv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05351</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Llm guided evolution-the automation of models advancing models</title>
		<author>
			<persName><forename type="first">Clint</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jurado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Zutty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
				<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A review on the long short-term memory model</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Van Houdt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Mosquera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gonzalo</forename><surname>Nápoles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5929" to="5955" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
	<note>Attention is all you need</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Investigating the potential of ai-driven innovations for enhancing differential evolution in optimization tasks</title>
		<author>
			<persName><forename type="first">Michal</forename><surname>Pluhacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anezka</forename><surname>Kazikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Viktorin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Kadavy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Senkerik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1070" to="1075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Differential evolution: a practical approach to global optimization</title>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rainer</forename><forename type="middle">M</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jouni</forename><forename type="middle">A</forename><surname>Lampinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Leveraging large language models for the generation of novel metaheuristic optimization algorithms</title>
		<author>
			<persName><forename type="first">Michal</forename><surname>Pluhacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anezka</forename><surname>Kazikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Kadavy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Viktorin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Senkerik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Companion Conference on Genetic and Evolutionary Computation</title>
				<meeting>the Companion Conference on Genetic and Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1812" to="1820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Soma-self-organizing migrating algorithm</title>
		<author>
			<persName><surname>Godfrey C Onwubolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><surname>Zelinka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Optimization Techniques in Engineering</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="167" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Soma-self-organizing migrating algorithm</title>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Zelinka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Self-Organizing Migrating Algorithm: Methodology and Implementation</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Mathematical discoveries from program search with large language models</title>
		<author>
			<persName><forename type="first">Bernardino</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammadamin</forename><surname>Barekatain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Novikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matej</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilien</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><forename type="middle">Jr</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><forename type="middle">S</forename><surname>Ellenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Fawzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">625</biblScope>
			<biblScope unit="issue">7995</biblScope>
			<biblScope unit="page" from="468" to="475" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Aglietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ira</forename><surname>Ktena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Schrouff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName><surname>Chiappa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.04824</idno>
		<title level="m">Funbo: Discovering acquisition functions for bayesian optimization with funsearch</title>
				<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Evolution of heuristics: Towards efficient automatic algorithm design using large language model</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xialiang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenkun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingfu</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.02051</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Multi-objective evolution of heuristic using large language model</title>
		<author>
			<persName><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenkun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingfu</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2409.16867</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Reevo: Large language models as hyper-heuristics with reflective evolution</title>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Berto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanbo</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haeyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinkyoo</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guojie</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.01145</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Iohprofiler: A benchmarking and profiling tool for iterative optimization heuristics</title>
		<author>
			<persName><forename type="first">Carola</forename><surname>Doerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furong</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Van Rijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bäck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.05281</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Iohexperimenter: Benchmarking platform for iterative optimization heuristics</title>
		<author>
			<persName><forename type="first">Furong</forename><surname>Jacob De Nobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederick</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Vermetten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carola</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Doerr</surname></persName>
		</author>
		<author>
			<persName><surname>Bäck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="205" to="210" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Iohanalyzer: Detailed performance analyses for iterative optimization heuristics</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederick</forename><surname>Vermetten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furong</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carola</forename><surname>Doerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bäck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Evolutionary Learning and Optimization</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Large language models as surrogate models in evolutionary algorithms: A preliminary study</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aimin</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page">101741</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Model uncertainty in evolutionary optimization and bayesian optimization: A comparative analysis</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aimin</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation (CEC)</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2024">2024. 2024</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Nabeel Seedat, and Mihaela van der Schaar. Large language models to enhance bayesian optimization</title>
		<author>
			<persName><forename type="first">Tennison</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolás</forename><surname>Astorga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.03921</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Large language models as tuning agents of metaheuristics</title>
		<author>
			<persName><forename type="first">Alicja</forename><surname>Martinek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Szymon</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName><surname>Amir</surname></persName>
		</author>
		<author>
			<persName><surname>Gandomi</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Metaheuristics and large language models join forces: Towards an integrated optimization approach</title>
		<author>
			<persName><forename type="first">Chacón</forename><surname>Camilo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Sartori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filippo</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Bistaffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corominas</forename><surname>Rodríguez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>IEEE Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Fastcover: An unsupervised learning framework for multi-hop influence maximization in social networks</title>
		<author>
			<persName><forename type="first">Runbo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guihai</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.00463</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Finding influential nodes in social networks using minimum khop dominating set</title>
		<author>
			<persName><forename type="first">Partha</forename><surname>Basuchowdhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhashis</forename><surname>Majumder</surname></persName>
		</author>
		<idno>ICAA 2014</idno>
	</analytic>
	<monogr>
		<title level="m">Applied Algorithms: First International Conference</title>
				<meeting><address><addrLine>Kolkata, India</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">January 13-15, 2014. 2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="137" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Leveraging large language model to generate a novel metaheuristic algorithm with crispe framework</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuefeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cluster Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="13835" to="13869" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Multitask genetic programmingbased generative hyperheuristics: A case study in dynamic scheduling</title>
		<author>
			<persName><forename type="first">Fangfang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kay</forename><surname>Chen Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengjie</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="10515" to="10528" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Multitask multiobjective genetic programming for automated scheduling heuristic learning in dynamic flexible job-shop scheduling</title>
		<author>
			<persName><forename type="first">Fangfang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengjie</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="4473" to="4486" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Lemabe: a novel framework to improve analogy-based software cost estimation using learnable evolution model</title>
		<author>
			<persName><forename type="first">Maedeh</forename><surname>Dashti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javdani</forename><surname>Taghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dariush</forename><surname>Gandomani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hazura</forename><surname>Hasanpoor Adeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abu</forename><surname>Zulzalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Bakar</surname></persName>
		</author>
		<author>
			<persName><surname>Sultan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PeerJ Computer Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">e800</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Large language models for constructing and optimizing machine learning workflows: A survey</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengyu</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muran</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyou</forename><surname>Qian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.10478</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Mixing LLM and genetic algorithms: New trends and research projects</title>
		<author>
			<persName><surname>Nexyad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Online</title>
		<imprint>
			<date type="published" when="2025-03-31">2025. March 31, 2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Exploring the prompt space of large language models through evolutionary sampling</title>
		<author>
			<persName><forename type="first">Martina</forename><surname>Saletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Ferretti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
				<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1345" to="1353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Autoopt: A general framework for automatically designing metaheuristic optimization algorithms with diverse structures</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bai</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianglong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taiwei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhui</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.00998</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">The crowdless future? generative ai and creative problem-solving</title>
		<author>
			<persName><forename type="first">Léonard</forename><surname>Boussioux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacqueline</forename><forename type="middle">N</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miaomiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Jacimovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karim</forename><forename type="middle">R</forename><surname>Lakhani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1589" to="1607" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Explainable artificial intelligence (xai): Concepts, taxonomies, opportunities and challenges toward responsible ai. Information fusion</title>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Barredo Arrieta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Díaz-Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Del Ser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrien</forename><surname>Bennetot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siham</forename><surname>Tabik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Barbado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvador</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Gil-López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Benjamins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="82" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Enhancing explainability and reliable decision-making in particle swarm optimization through communication topologies</title>
		<author>
			<persName><forename type="first">Nitin</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Indu</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bapi</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anupam</forename><surname>Yadav</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2504.12803</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Robust and adaptive optimization under a large language model lens</title>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Bertsimas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Margaritis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2501.00568</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Nl4opt competition: Formulating optimization problems based on their natural language descriptions</title>
		<author>
			<persName><forename type="first">Rindranirina</forename><surname>Ramamonjison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haley</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bissan</forename><surname>Ghaddar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahdi</forename><surname>Mostajabdaveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Banitalebi-Dehkordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zirui</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2022 Competition Track</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="189" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">What are large language models (llms</title>
		<ptr target="https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-are-large-language-models-llms" />
		<imprint>
			<date type="published" when="2025-03-31">2025. March 31, 2025</date>
			<publisher>Microsoft Azure</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Evolving code with a large language model</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hemberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Moskal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Una-May O'</forename><surname>Reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetic Programming and Evolvable Machines</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Algorithmic information theory</title>
		<author>
			<persName><forename type="first">Chaitin</forename><surname>Gregory</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM journal of research and development</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="350" to="359" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<author>
			<persName><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoliang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenkun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingfu</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.17287</idno>
		<title level="m">Llm4ad: A platform for algorithm design with large language model</title>
				<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<author>
			<persName><forename type="first">Ken</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruien</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keying</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard-John</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghe</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youran</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqian</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.09667</idno>
		<title level="m">Benchmarking language model agents for data-driven science</title>
				<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Beyond the hype: Benchmarking llm-evolved heuristics for bin packing</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Renau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on the Applications of Evolutionary Computation (Part of EvoStar)</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2025">2025</date>
			<biblScope unit="page" from="386" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Searching for benchmark problem instances from data-driven optimisation</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Hajari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Gallagher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference Companion</title>
				<meeting>the Genetic and Evolutionary Computation Conference Companion</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="139" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Challenges in benchmarking optimization heuristics (dagstuhl seminar 23251)</title>
		<author>
			<persName><forename type="first">Anne</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Bosman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darrell</forename><surname>Kerschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lennart</forename><surname>Whitley</surname></persName>
		</author>
		<author>
			<persName><surname>Schäpermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dagstuhl Reports</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="55" to="80" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bartz-Beielstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carola</forename><surname>Doerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sowmya</forename><surname>Bossek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tome</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Eftimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Fischbach</surname></persName>
		</author>
		<author>
			<persName><surname>Kerschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">La</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Cava</surname></persName>
		</author>
		<author>
			<persName><surname>Lopez-Ibanez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03488</idno>
		<title level="m">Benchmarking in optimization: Best practice and open issues</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Towards benchmarking of collaborative robots in production</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kinast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Braune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">253</biblScope>
			<biblScope unit="page" from="1505" to="1514" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Blade: Benchmark suite for llm-driven automated design and evolution of iterative optimization heuristics</title>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">V</forename><surname>Niki Van Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Kononova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><surname>Bäck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2504.20183</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Generalization or memorization: Data contamination and trustworthy evaluation for large language models</title>
		<author>
			<persName><forename type="first">Yihong</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xue</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.15938</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">When large language models meet evolutionary algorithms: Potential enhancements and challenges</title>
		<author>
			<persName><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Licheng</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyuan</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/Evolutionary_algorithm" />
		<imprint>
			<date type="published" when="2025-03-31">2025. March 31, 2025</date>
		</imprint>
	</monogr>
	<note>Research, 8:0646, 2025. DRAFT [107] Wikipedia contributors. Evolutionary algorithm</note>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Do automatic factuality metrics measure factuality? a critical evaluation</title>
		<author>
			<persName><forename type="first">Sanjana</forename><surname>Ramprasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byron</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.16638</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">A federated data-driven evolutionary algorithm. Knowledge-based systems</title>
		<author>
			<persName><forename type="first">Jinjin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaochu</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenli</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sai</forename><surname>Gu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">233</biblScope>
			<biblScope unit="page">107532</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<ptr target="https://en.wikipedia.org/wiki/Large_language_model" />
		<title level="m">Wikipedia contributors. Large language model</title>
				<imprint>
			<date type="published" when="2025-03-31">2025. March 31, 2025</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
