<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Campus AI vs Commercial AI: A Late-Breaking Study on How LLM As-A-Service Customizations Shape Trust and Usage Patterns</title>
				<funder>
					<orgName type="full">UA Ruhr</orgName>
				</funder>
				<funder>
					<orgName type="full">Research Center Trustworthy Data Science and Security</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2025-05-15">15 May 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Leon</forename><surname>Hannig</surname></persName>
							<email>leon.hannig@uni-due.de</email>
						</author>
						<author>
							<persName><forename type="first">Annika</forename><surname>Bush</surname></persName>
							<email>annika.bush@tu-dortmund.de</email>
						</author>
						<author>
							<persName><forename type="first">Steffen</forename><surname>Becker</surname></persName>
							<email>steffen.becker@rub.de</email>
							<affiliation key="aff5">
								<orgName type="department">Also with Max Planck Institute for Security and Privacy. Authors&apos; Contact Information: Leon Hannig</orgName>
								<orgName type="institution">University of Duisburg-Essen</orgName>
								<address>
									<settlement>Duisburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Greta</forename><surname>Ontrup</surname></persName>
							<email>greta.ontrup@uni-due.de.</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Duisburg</orgName>
								<address>
									<settlement>Essen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">TU Dortmund University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">MELTEM AKSOY</orgName>
								<orgName type="institution" key="instit2">TU Dortmund University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Ruhr University Bochum</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">University of Duisburg</orgName>
								<address>
									<settlement>Essen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">TU Dortmund University</orgName>
								<address>
									<settlement>Annika Bush, Dortmund</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution" key="instit1">Meltem Aksoy</orgName>
								<orgName type="institution" key="instit2">TU Dortmund University</orgName>
								<address>
									<settlement>Dortmund</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">Ruhr University Bochum</orgName>
								<address>
									<settlement>Steffen Becker, Bochum</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">Greta Ontrup</orgName>
								<orgName type="institution">University of Duisburg-Essen</orgName>
								<address>
									<settlement>Duisburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Campus AI vs Commercial AI: A Late-Breaking Study on How LLM As-A-Service Customizations Shape Trust and Usage Patterns</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-05-15">15 May 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">1CF244137B031875F699F2CDE222B0A7</idno>
					<idno type="arXiv">arXiv:2505.10490v1[cs.CY]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-19T11:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Large Language Models as-a-Service (LLMaaS)</term>
					<term>Customization</term>
					<term>Trust</term>
					<term>Hallucinations</term>
					<term>University</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As the use of Large Language Models (LLMs) by students, lecturers and researchers becomes more prevalent, universities -like other organizations -are pressed to develop coherent AI strategies. LLMs as-a-Service (LLMaaS) offer accessible pre-trained models, customizable to specific (business) needs. While most studies prioritize data, model, or infrastructure adaptations (e.g., model finetuning), we focus on user-salient customizations, like interface changes and corporate branding, which we argue influence users' trust and usage patterns. This study serves as a functional prequel to a large-scale field study in which we examine how students and employees at a German university perceive and use their institution's customized LLMaaS compared to ChatGPT. The goals of this prequel are to stimulate discussions on psychological effects of LLMaaS customizations and refine our research approach through feedback. Our forthcoming findings will deepen the understanding of trust dynamics in LLMs, providing practical guidance for organizations considering LLMaaS deployment.</p><p>CCS Concepts: ‚Ä¢ Human-centered computing ‚Üí Empirical studies in HCI; User studies; Field studies; ‚Ä¢ Security and privacy ‚Üí Privacy protections.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As Large Language Models (LLMs) become increasingly prevalent in professional and educational settings, organizations face mounting pressure to develop coherent strategies for AI integration <ref type="bibr" target="#b31">[32]</ref>. Current research shows high adoption rates of commercial off-the-shelf LLMs such as ChatGPT among students and university staff for various professional and academic tasks <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66]</ref>. In order to guide the informed and secure use of AI, many organizations, including universities, corporations, and government agencies, are exploring the deployment of LLMs as-a-Service (LLMaaS) as an achievable and cost-effective way to adopt AI in-house <ref type="bibr" target="#b32">[33]</ref>. This trend is driven by several practical considerations: the opportunity to offer access to all university members while maintaining institutional oversight and alignment with organizational policies or the ability to provide dedicated technical support <ref type="bibr" target="#b45">[46]</ref>. One of the main benefits of AI as-a-Service (AIaaS) solutions is the flexibility they offer in customizing various aspects <ref type="bibr" target="#b21">[22]</ref>, such as fine-tuning models or displaying user interfaces in corporate design.</p><p>Customizations are important because they can, e.g., improve model performance for the specific organizational context or enhance security and privacy safeguards <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b54">55]</ref>. However, even choices that do not impact model performance or security, such as branding a user interface, could lead to significant changes in how the system is perceived and used.</p><p>From a psychological perspective, users rely on various cues to assess the trustworthiness and consequently align their use of AI <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b52">53]</ref>. Users interpret information about and from the system in terms of its performance, purpose, and processes <ref type="bibr" target="#b20">[21]</ref>. We argue that end users may interpret customizations of LLMs as indicative of the system's capabilities, goals, and underlying processes, even if the design choices (e.g., corporate branding) do not directly impact functionality.</p><p>While organizations invest in LLMaaS, we lack systematic empirical evidence on how customization choices within the adoption process influence users' trust, usage patterns, and overall acceptance of these systems compared to commercial off-the-shelf alternatives (hereinafter referred to as "commercial LLMs"). This is especially relevant for customization choices that are salient to the user (e.g., user interface) but have no real technical impact on the pre-trained data/model/algorithm/infrastructure <ref type="bibr" target="#b21">[22]</ref>. We aim to close this research gap by conducting an empirical study that answers the following research question:</p><p>RQ: How do customizations of LLMaaS impact end users' trust, perception, and usage of LLMs in professional and academic contexts compared to commercial AI alternatives? This late-breaking work presents the research motivation, hypotheses, and study design of an ongoing large-scale field study. The purpose of this "prequel" is twofold: first, we compile a comprehensive overview of LLMaaS customization options to guide the hypothesis formulation, aiming to stimulate further discussion and research into the psychological effects of customization choices on end users. Second, we seek feedback from our professional peers on our proposed field study to enhance its effectiveness. Outcomes from our large-scale field study will enrich both theoretical insights into trust in organizational AI systems and practical applications of AI strategies across different sectors.</p><p>2 Background</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">LLMs (as-a-Service) at Universities</head><p>LLMs, such as ChatGPT, have become increasingly prevalent in academic settings, with significant adoption among university students. For example, von Garrel and Mayer <ref type="bibr" target="#b58">[59]</ref> report that nearly two thirds of German students use LLMs for tasks that include concept clarification, literature review, and translation. Similarly, Amani et al. <ref type="bibr" target="#b4">[5]</ref> demonstrate the widespread use of LLMs for personalized learning purposes at Texas A&amp;M University. Researchers have reported using LLMs <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b55">56]</ref>, e.g., for language editing or literature search <ref type="bibr" target="#b1">[2]</ref>.</p><p>Thus, universities are caught between enabling students and staff to access and use AI in an informed way to leverage the benefits while also protecting data, privacy, rights, and ethical principles. One way to appropriately shape the use of AI is for universities to introduce "their own" LLMs, the same way as organizations in the private sector do (e.g.,</p><p>W√§rtsil√§GPT by the Finnish company W√§rtsil√§ Oyi; <ref type="bibr" target="#b45">[46]</ref>). However, the introduction of AI poses a massive challenge for universities, due to a lack of internal technical abilities and knowledge about the deployment of AI and the high costs of developing and maintaining a sufficient IT infrastructure <ref type="bibr" target="#b35">[36]</ref>.</p><p>LLMs as-a-Service (LLMaaS) provide a practical solution by offering easy access to pre-trained models via cloud providers <ref type="bibr" target="#b60">[61]</ref>. This approach is a subset of AI as-a-Service (AIaaS), broadly defined as "cloud-based systems providing on-demand services to organizations and individuals for deploying, developing, training, and managing AI models" <ref type="bibr">[36, p. 424</ref>]. Often referred to as "no-code or low-code" AI, these systems are recognized as a means of democratizing AI, enabling organizations to adopt and afford AI technologies without requiring extensive technological expertise <ref type="bibr" target="#b54">[55]</ref>.</p><p>Moreover, LLMaaS solutions emphasize enhanced data protection and security, offering a viable option for institutions like universities to leverage AI's advantages while adhering to stringent compliance and security standards <ref type="bibr" target="#b45">[46]</ref>. The primary benefits of AIaaS include reducing complexity, increasing automation, and enabling customization <ref type="bibr" target="#b35">[36]</ref>.</p><p>One proposed advantage of LLMaaS is that organizations can tailor various aspects of LLMs to better align with their unique requirements and objectives. In this context, customizations are defined as configurations of parameters at various architectural layers to improve the fit between the system and organization-specific needs <ref type="bibr" target="#b21">[22]</ref>. Table <ref type="table" target="#tab_0">1</ref> outlines customization options, which encompass customizations of data, models, algorithms, and infrastructure <ref type="bibr" target="#b21">[22]</ref>, security and governance adaptations <ref type="bibr" target="#b14">[15]</ref>, customizations that relate to the design of the user interface and experience, and choices regarding the organizational integration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category Examples References</head><p>Model fine-tuning and Configuration Adjust/add system prompts, fine-tuning on proprietary data, hyperparameter configuration, domain-specific knowledge integration, customizable output. <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b46">47]</ref> Integration and Interoperability API integration, integration with other tools and systems. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b35">36]</ref> Security and Governance Access control and security, compliance and regulatory requirements, monitoring and evaluation.</p><p>[ <ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b46">47]</ref> User Interface and Experience Incorporation of corporate design, sustainability measures (e.g., token visualization), user profiling and personalization, customizable error handling, multi-language support.</p><p>[13]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Organizational integration</head><p>Providing context-specific training or workshops, providing contextspecific information and use recommendations regarding the model.</p><p>[42]</p><p>To date, existing literature has focused primarily on methods and effects of model fine-tuning and configuration, integration and interoperability, as well as security and governance-related consequences of LLMaaS. These aspects are critical, as adapting AI systems -for example, to ensure data protection or to fine-tune them for internal company data -plays a key role in their secure and human-centered integration into organizations. However, other customization choices, such as interface design, remain largely unexplored in terms of their impact on end users. For instance, research and reports on LLMaaS deployment in organizations focus mostly on technical customizations, mentioning other customizations pertaining to the user interface and experience or the organizational integration as a side note (e.g., Weber et al. <ref type="bibr" target="#b61">[62]</ref> report on the architectural designs of Frauenhofers LLMaaS "FhGenie"). This could be because these adjustments have no effect on the actual performance or security of the models. However, from a psychological perspective, users' trust and corresponding use of AI depend on so-called cues, i.e. "any information element that can be used to make a trust assessment about an agent" <ref type="bibr">[21, p. 253]</ref>. Users have been shown to rely on various cues when deciding whether or not to trust and use AI, e.g., system explanations or a logo of a company <ref type="bibr" target="#b52">[53]</ref>. Gong et al. <ref type="bibr" target="#b24">[25]</ref> for example theorize on the effects of user experience (UX) design on perceived trustworthiness. We therefore posit that it is essential to recognize that end users could perceive customizations of LLMs as reflections of the system's capabilities, goals, and inner workings, even if these customizations (such as using a corporate design) do not actually affect the functioning of the system.</p><p>This study investigates the usage patterns and trust perceptions of end users when interacting with commercial LLMs and customized LLMaaS. In the following, we derive hypotheses based on previous research to assess how the customization choices of LLMaaS affect the perception and use of the system by users compared to a commercial LLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Trust in AI Systems</head><p>Trust, as a key determinant of technology adoption <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b57">58]</ref>, has been recognized as an important factor for LLM adoption among academic staff and students <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b56">57]</ref>. Research has shown that both insufficient and excessive trust in AI systems can be critical, as a lack of trust may hinder their adoption, while overtrust can lead to risks such as reliance on incorrect or potentially harmful outputs <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b59">60]</ref>. This underscores the importance of ensuring that students and staff place appropriate trust in LLM chatbots.</p><p>Trust is commonly defined as the trustor's positive expectations towards the trustee, combined with the trustor's vulnerability and uncertainty within the specific context <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b33">34]</ref>. Research has shown that trust levels in human-human interaction depend on three perceived qualities of the trustee: ability, integrity, and benevolence <ref type="bibr" target="#b37">[38]</ref>. In the context of human-automation interaction, these three factors have been reframed as performance, process (e.g. availability, confidentiality, understandability of a system) and purpose (e.g., the developer's intentions) <ref type="bibr" target="#b33">[34]</ref>. Additional factors have been identified as particularly important for trust in LLMs. These include transparency <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b53">54]</ref>, access to a human operator <ref type="bibr" target="#b43">[44]</ref>, and perceived privacy and robust data security <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b47">48]</ref>. These insights provide a robust basis for examining how users develop trust when choosing between organizations' customized LLMaaS and commercial LLMs.</p><p>Customizations of LLMaaS in corporate design could serve as a salient trust cue for users, increasing the perceived trustworthiness of the system in two dimensions: (a) purpose and (b) process. The perceived purpose of the system may appear more trustworthy when the customizations incorporate university branding, as the university is likely to be seen as a benevolent provider with minimal financial or marketing-driven motives <ref type="bibr" target="#b43">[44]</ref>. This perception may be further enhanced due to a sense of familiarity evoked by the university's branding <ref type="bibr" target="#b2">[3]</ref>. Second, the process dimension of the system may be perceived as more trustworthy because it is easily accessible and embedded in the existing organizational framework. Here, features such as the option to contact a human operator for assistance could contribute to users' trust through perceived openness and accessibility <ref type="bibr" target="#b33">[34]</ref>. Additionally, a customized LLMaaS may be perceived as more transparent due to context-specific information about the system available on the university's website. These factors together lead us to the following hypothesis:</p><p>H1: Users report higher levels of trust in a customized LLMaaS compared to a commercial LLM.</p><p>We further hypothesize that higher trust in the organization's customized LLMaaS will likely depend on its members' trust in the organization itself. Organizational trust describes the extent to which individuals trust an organization <ref type="bibr" target="#b49">[50]</ref>.</p><p>Prior research on AI implementation <ref type="bibr" target="#b66">[67]</ref> and attitudes towards LLMs <ref type="bibr" target="#b6">[7]</ref> suggests that organizational trust can significantly shape users' trust in the system. In line with this, Nordheim et al. <ref type="bibr" target="#b43">[44]</ref> have demonstrated that customers' trust in a company's service chatbot is influenced by their trust in the company itself. We therefore assume: H2: The level of organizational trust moderates the effect of system type (customized vs. commercial) on user trust, such that the effect is stronger when organizational trust is higher and weaker when it is lower.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">LLM Hallucinations</head><p>When implementing LLMaaS, universities face the challenge of ensuring that their students and staff can interact with these systems effectively, correctly and safely. A key aspect of this responsibility is addressing the issue of hallucinations. Hallucinations in LLMs describe the generation of content that appears plausible but is either factually incorrect or inconsistent with user input <ref type="bibr" target="#b27">[28]</ref>. Hallucinations in human-AI interaction pose a dual challenge: they impair effective collaboration through reduced output quality and undermine users' trust <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b44">45]</ref>. In the academic context, hallucinations present particularly serious risks. For example, LLMs have been shown to often fabricate inaccurate scientific references <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref>. For university staff and students, hallucinations could thus lead to severe consequences.</p><p>Despite various efforts and technological advances, hallucinations cannot be completely eliminated from LLMs <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b63">64]</ref>.</p><p>This issue calls for a focus on the human side, with the ultimate goal of identifying strategies to help users anticipate, mitigate, and react to hallucinations. In this context, we consider two customization aspects of the user interface: corporate design and warnings about false information. Research has shown that the presence of logos from reputable companies can create positive associations, enhancing the perceived credibility of mobile systems <ref type="bibr" target="#b36">[37]</ref>. We argue that branding a chatbot with a university logo leads users to interpret the chatbot as university-approved, i.e., reliable and infallible. This could potentially make users less critical and cautious in their interactions with the university-branded system. Another notable customization choice of LLMaaS is the display of warnings about hallucinations or false information. Research suggests that such warnings can help users detect hallucinations more frequently <ref type="bibr" target="#b42">[43]</ref>. While</p><p>ChatGPT's interface includes a disclaimer below the prompt box stating "ChatGPT can make mistakes. Please consider checking important information", LLMaaS allow such warnings to be adapted, removed, or altered. We argue that making hallucination warnings less visible leads users to be less cautious about hallucinations in their LLM interactions, and thus to detect fewer hallucinations. Based on this reasoning, we propose the following hypotheses: H3: Users report less cautious behavior towards hallucinations when using a customized LLMaaS compared to a commercial LLM.</p><p>H4: Users report fewer experienced hallucinations when using a customized LLMaaS compared to a commercial LLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Data Security and Privacy Concerns</head><p>End users often express concerns about data security and privacy when interacting with LLMs. Key risks include (unauthorized) data retention <ref type="bibr" target="#b18">[19]</ref>, where providers may retain and use customer data to enhance their models, inference attacks that aim to extract sensitive information from trained models <ref type="bibr" target="#b30">[31]</ref>, and the unintended exposure of confidential data during model training or operation <ref type="bibr" target="#b15">[16]</ref>. Technical customization options in LLMaaS offer promising avenues to mitigate these risks, thereby playing a pivotal role in enhancing users' perceptions of privacy and security while fostering trust. These options include user-configurable privacy settings that empower users to control how their data is stored and used <ref type="bibr" target="#b5">[6]</ref>, transparency mechanisms like privacy explanations <ref type="bibr" target="#b9">[10]</ref>, which provide clarity about data handling practices, and the implementation of privacy-preserving techniques such as differential privacy <ref type="bibr" target="#b0">[1]</ref> during training and fine-tuning processes. Beyond their direct technical benefits, we posit that customization measures, even those without tangible impacts on privacy or security, can still foster higher perceived privacy levels. In this context, we again draw on the role of corporate branding as a salient customization feature: institution-branded LLMs could enhance data security and privacy perceptions, which in turn could lead users to perceive the system as more trustworthy, believing that their data will be handled with care and not shared with third parties. In this context, we propose the following hypothesis:</p><p>H5: Users perceive greater privacy when using a customized LLMaaS compared to a commercial LLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Sustainable AI Use</head><p>Having explored potential impacts of customization on users' trust, perceived hallucinations and privacy concerns, it becomes evident that organizations need to carefully consider their approach to LMMaaS. In this last part, we want to open the door for broader considerations that pertain to the global strategy of an organization, specifically the corporate social responsibility (CSR). CSR refers to situations in which organizations pursue strategies that go beyond business needs and legal regulations but aim at furthering social good <ref type="bibr" target="#b39">[40]</ref>. This includes various aspects, such as improving an organization's sustainability and environmental performance <ref type="bibr" target="#b40">[41]</ref>. We argue that customization of LLMaaS offer organizations opportunities to align AI deployment with their CSR strategy and corresponding sustainability goals, thereby not only shaping the trust in and perception of the systems but also their environmental impact.</p><p>The environmental impact of AI systems and LLMs has become an increasingly critical concern in computing research. Recent work by Rafael and Reis <ref type="bibr" target="#b50">[51]</ref> emphasizes how the invisibility of digital energy consumption often leads to unconscious and potentially wasteful usage patterns. This mirrors findings in energy consumption studies <ref type="bibr" target="#b38">[39]</ref> that identify varying levels of user awareness -from "energy unaware" to "energy aware and active" -highlighting how visibility of resource consumption can transform user behavior. Our research extends these insights and considers the impact of customization choices aimed at promoting sustainable AI usage patterns.</p><p>Making resource consumption visible has shown promising results across different domains. Penkert and Gr√∂schel <ref type="bibr" target="#b48">[49]</ref> demonstrated that transparency in sustainability information significantly influences user choices, while Sanduleac et al. <ref type="bibr" target="#b51">[52]</ref> found that real-time energy data promotes more responsible consumption patterns. LLMaaS offer customization options to make AI resource limitations explicit through token visibility. We argue that customizing token visibility can foster what we term "AI resource consciousness" -a more deliberate and efficient approach to AI interaction that considers both immediate utility and broader environmental impact. Based on these previous findings, we hypothesize: H6: Users report (a) more resource-efficient prompting behaviors and (b) increased sensitivity to AI sustainability concerns when using a customized LLMaaS compared to a commercial LLM.</p><p>3 Method</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Study Design, Participants and Setting</head><p>To answer our hypotheses, we plan a quantitative, cross-sectional field study. We designed a comprehensive survey instrument combining validated measures from existing research with questions specific to the use of LLM-based chatbots. In the following, we report on the planned design, method and questionnaire.</p><p>The large-scale study will be conducted in the spring of 2025 at a large German research university that has implemented a customized LLMaaS in late 2024. The system has approximately 6,000 registered users and 800 active users per week as of January 22, 2025. Our participant pool includes three distinct user groups within the university ecosystem: (a) students across all academic levels and disciplines, (b) research staff, including PhDs, PostDocs, faculty, and (c) administrative staff. A sample size of ùëÅ = 250 (accounting for dropout) is planned (ùëì 2 = 0.05, ùõº = 0.05, ùõΩ = .80).</p><p>The goal is to ensure an equal distribution of participants between users of the customized LLMaaS and ChatGPT as well as an equal representation across the three status groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Customized LLMaaS</head><p>The LLM-based chatbot introduced by the university is OpenAI's ChatGPT deployed via Microsoft Azure. Customizations regarding the data and model were kept to a minimum, but the university made some adjustments regarding the user interface and incorporated detailed information and training materials (see Table <ref type="table" target="#tab_1">2</ref>). Organizational integration Supporting materials provided on the chatbot landing page and intranet; training sessions on effectively using LLMs in higher education 1 The temperature parameter in LLMs, ranging from 0 to 1, controls response randomness, with values near 0 favoring deterministic outputs and values near 1 producing diverse, creative outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Survey Instrument</head><p>We designed a comprehensive survey to investigate the perceptions and usage patterns of both the university's customized LLMaaS chatbot and OpenAI's ChatGPT. The proposed survey design is summarized in Figure <ref type="figure" target="#fig_0">1</ref>. Participants are guided through the survey based on their use/non-use of the university-customized chatbot and ChatGPT. The main part consists of questions regarding the perception and use of the university's system and ChatGPT (green blocks in Figure <ref type="figure" target="#fig_0">1</ref>). The survey questions are available in the supplementary material. The survey begins by capturing usage patterns, including frequency of use (ranging from "never" to "multiple times per day") and the context of use (private versus work/study-related). In the first step, several aspects of system perception and use are explored: the context of use (specific tasks), use of training/information material, perceived usefulness (productivity enhancement, task facilitation), and ease of use (interface clarity, learning curve), both assessed following the Technology Acceptance Model (TAM) <ref type="bibr" target="#b19">[20]</ref>. For users familiar with either system, we also assess their awareness and use of different language models available within each platform. For users who have never used or rarely use the university's chatbot, we explore their reasons for non-adoption or limited use.</p><p>The main part of the survey is structured around the key constructs (see hypotheses), measured in parallel for both systems. Participants who use both systems will respond to the same set of items twice: once for the university's customized LLMaaS and once for ChatGPT. At the beginning of the main part, participants are reminded to answer the following questions specifically in regard to their work-related or academic use of the chatbots, and not for their private use. We use five-point Likert scales ranging from "strongly disagree" to "fully agree".</p><p>Trust. Trust is measured along two dimensions: trust in the providing organization (university) is measured with three items following B√∏e <ref type="bibr" target="#b11">[12]</ref> (e.g., "My university will safeguard my interests. ") and trust in the chatbots themselves is assessed by the facets of global trust, benevolence/purpose, integrity/process and ability/performance using four items from Wischnewski et al. <ref type="bibr" target="#b62">[63]</ref> (e.g., "I trust [the university's chatbot/ChatGPT]. ").</p><p>Hallucinations. We investigate users' cautious behavior towards LLM hallucinations, including their verification practices and task-specific trust decisions, with three items (e.g., "I check important information from [the university's chatbot/ChatGPT] responses through external sources. "). Users also report their experienced hallucinations with three items (e.g., "I have noticed that [the university's chatbot/ChatGPT] makes up facts that do not correspond to reality. ").</p><p>The items are self-developed based on Christensen et al. <ref type="bibr" target="#b17">[18]</ref>.</p><p>Data security and privacy concerns. We measure privacy concerns following Hsu and Lin <ref type="bibr" target="#b26">[27]</ref> with three items (e.g., "My decision to use [the university's chatbot/ChatGPT] exposes me to privacy risks. ").</p><p>Sustainable AI use. The survey also assesses the intentions for sustainable use, environmentally conscious behavior, and considerations of energy consumption with three items (e.g., "I often think about the energy consumption of [the university's chatbot/ChatGPT]. "). Since the university-chatbot displays the remaining number of tokens as a percentage, we assessed the university-chatbot users' awareness of token usage with two items (e.g., "During use, I pay attention to how many tokens I still have available. "). Because there are no tested surveys focusing explicitly on the sustainable use of LLMs yet, the items are self-developed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Data Collection Procedure</head><p>To maximize participation and ensure representative sampling, we employ a multi-channel recruitment strategy through the university's chatbot landing page, department office communications, university-wide communication channels, and supplementary physical materials where needed. The university communications department will assist in disseminating the survey through official social media channels and website postings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Outlook: Expected Contributions</head><p>Our research provides three key contributions to the field: First, for higher education institutions and organizations in general, we offer evidence-based insights for AI implementation strategies, helping decision-makers understand how customization choices of LLMaaS solutions impact user trust and adoption patterns. Second, we develop design recommendations for organizational AI systems, addressing how features, interfaces, and integration approaches can be optimized to enhance user trust and adoption while effectively coexisting with commercial alternatives. Third, we open new research directions for investigating how customization aspects, especially organizational AI branding effects, vary across sectors, examining long-term impacts on organizational culture, and exploring the evolving relationship between institutional trust and AI system trust over time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of our survey. The expected completion time is 15 minutes or less.</figDesc><graphic coords="7,137.70,381.48,299.88,144.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Examples of Customization Aspects of AIaaS.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Customization features of the studied LLMaaS.</figDesc><table><row><cell>Category</cell><cell>Customization Details</cell></row><row><cell cols="2">Model fine-tuning &amp; Configuration Temperature 1 set to 0 for deterministic outputs</cell></row><row><cell>Integration and Interoperability</cell><cell>Access to multiple models; image generation via DALL-E for OpenAI models</cell></row><row><cell>Security and Governance</cell><cell>Minimal data collection for service provision; chat data excluded from</cell></row><row><cell></cell><cell>model training; GDPR-compliant data processing within the EU; access</cell></row><row><cell></cell><cell>restricted to internal networks (e.g., via VPN)</cell></row><row><cell>User Interface and Experience</cell><cell>Interface customized with corporate design (e.g., university logo); token</cell></row><row><cell></cell><cell>usage visualized as a percentage in the user interface</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">Research Center Trustworthy Data Science and Security</rs> (https://rc-trust.ai), one of the <rs type="institution">Research Alliance Centers</rs> within the <rs type="funder">UA Ruhr</rs> (https://uaruhr.de).</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep Learning with Differential Privacy</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2016 ACM SIGSAC Conference on Computer and Communications Security<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Knowledge, Perceptions and Attitude of Researchers Towards Using ChatGPT in Research</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Abdelhafiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Maaly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Ziady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Sultan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mahgoub</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10916-024-02044-4</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Systems</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2024-02">2024. Feb 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The effect of propensity to trust and familiarity on perceptions of trustworthiness over time</title>
		<author>
			<persName><forename type="first">Gene</forename><forename type="middle">M</forename><surname>Alarcon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">B</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">C</forename><surname>Christensen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.paid.2016.01.031</idno>
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="309" to="315" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reference Hallucination Score for Medical Artificial Intelligence Chatbots: Development and Usability Study</title>
		<author>
			<persName><forename type="first">Fahad</forename><surname>Aljamaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Majed</forename><surname>Temsah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ibrahim</forename><surname>Altamimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdulrahman</forename><surname>Al-Eyadhy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ammar</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Alhasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tariq</forename><surname>Mesallam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Farahat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Malki</surname></persName>
		</author>
		<idno type="DOI">10.2196/54345</idno>
	</analytic>
	<monogr>
		<title level="j">JMIR Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">54345</biblScope>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><surname>Amani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Balart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Shryock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Brumbelow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Watson</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2304.14415arXivpreprint" />
	</analytic>
	<monogr>
		<title level="m">Generative AI Perceptions: A Survey to Measure the Perceptions of Faculty, Staff, and Students on Generative AI Tools in Academia</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">E-P3P privacy policies and privacy authorization</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Hada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G√ºnter</forename><surname>Karjoth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Schunter</surname></persName>
		</author>
		<idno type="DOI">10.1145/644527.644538</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 ACM Workshop on Privacy in the Electronic Society</title>
		<meeting>the 2002 ACM Workshop on Privacy in the Electronic Society<address><addrLine>Washington, DC; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="103" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Agathe</forename><surname>Balayn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mireia</forename><surname>Yurrita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fanny</forename><surname>Rancourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Casati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ujwal</forename><surname>Gadiraju</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.16310[cs.HC</idno>
		<ptr target="https://arxiv.org/abs/2405.16310" />
		<title level="m">An Empirical Exploration of Trust Dynamics in LLM Supply Chains</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">LLMs Will Always Hallucinate, and We Need to Live With This</title>
		<author>
			<persName><forename type="first">Sourav</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayushi</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saloni</forename><surname>Singla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2409.05746</idno>
		<ptr target="https://arxiv.org/abs/2409.05746" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>stat.ML</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Shall I use ChatGPT? A study on perceived trust and perceived risk towards ChatGPT usage by teachers at higher education institutions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chopra</surname></persName>
		</author>
		<idno type="DOI">10.1108/IJILT-11-2023-0220</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Information and Learning Technology</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="428" to="447" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Privacy explanations -A means to end-user trust</title>
		<author>
			<persName><forename type="first">Wasja</forename><surname>Brunotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larissa</forename><surname>Chazette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Schneider</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jss.2022.111545</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">195</biblScope>
			<biblScope unit="page">111545</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making</title>
		<author>
			<persName><forename type="first">Zana</forename><surname>Bu√ßinca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maja</forename><surname>Barbara Malaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krzysztof</forename><forename type="middle">Z</forename><surname>Gajos</surname></persName>
		</author>
		<idno type="DOI">10.1145/3449287</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">pages</biblScope>
			<date type="published" when="2021-04">2021. April 2021</date>
		</imprint>
	</monogr>
	<note>Article</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">E-learning technology and higher education: the impact of organizational trust</title>
		<author>
			<persName><forename type="first">Tove</forename><surname>B√∏e</surname></persName>
		</author>
		<idno type="DOI">10.1080/13583883.2018.1465991</idno>
		<ptr target="https://doi.org/10.1080/13583883.2018.1465991" />
	</analytic>
	<monogr>
		<title level="j">Tertiary Education and Management</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="362" to="376" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Operating Enterprise AI as a Service</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Casati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kannan</forename><surname>Govindarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baskar</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aniruddha</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Palapudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Firat</forename><surname>Karakusoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debu</forename><surname>Chatterjee</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-33702-5_25</idno>
	</analytic>
	<monogr>
		<title level="m">Service-Oriented Computing</title>
		<title level="s">Lecture Notes in Computer Science, Slimane Yangui</title>
		<editor>
			<persName><forename type="first">Ines</forename><surname>Bouassida Rodriguez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Khalil</forename><surname>Drira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Zahir</forename><surname>Tari</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="volume">11895</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hallucination Rates and Reference Accuracy of ChatGPT and Bard for Systematic Reviews: Comparative Analysis</title>
		<author>
			<persName><forename type="first">Mika√´l</forename><surname>Chelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jules</forename><surname>Descamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Lavou√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Trojani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Deckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Luc</forename><surname>Raynier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Clowez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Boileau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Ruetsch-Chelli</surname></persName>
		</author>
		<idno type="DOI">10.2196/53164</idno>
	</analytic>
	<monogr>
		<title level="j">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">53164</biblScope>
			<date type="published" when="2024-05-22">2024. 22 May 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Combating Security and Privacy Issues</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Cao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Papadimitriou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ovalle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Zampieri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Ferraro</surname></persName>
		</editor>
		<editor>
			<persName><surname>Swayamdipta</surname></persName>
		</editor>
		<meeting><address><addrLine>Mexico City, Mexico</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="16" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks</title>
		<author>
			<persName><forename type="first">Xiaoyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liya</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhikun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haixu</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3658644.3690325</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2024 on ACM SIGSAC Conference on Computer and Communications Security<address><addrLine>Salt Lake City, UT, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1285" to="1299" />
		</imprint>
	</monogr>
	<note>CCS &apos;24)</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Investigating the Impact of User Trust on the Adoption and Use of ChatGPT: Survey Analysis</title>
		<author>
			<persName><forename type="first">Avishek</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Shamszare</surname></persName>
		</author>
		<idno type="DOI">10.2196/47184</idno>
	</analytic>
	<monogr>
		<title level="j">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">47184</biblScope>
			<date type="published" when="2023-06-14">2023. 14 Jun 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Understanding the role and impact of Generative Artificial Intelligence (AI) hallucination within consumers&apos; tourism decision-making processes</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1080/13683500.2023.2300032</idno>
		<ptr target="https://doi.org/10.1080/13683500.2023.2300032" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
	<note>Current Issues in Tourism 0, 0 (2024</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Artificial intelligence as a service: Legal responsibilities, liabilities, and policy challenges</title>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jatinder</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.clsr.2021.105573</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Law &amp; Security Review</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">105573</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Perceived usefulness, perceived ease of use, and user acceptance of information technology</title>
		<author>
			<persName><forename type="first">Fred D</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIS quarterly</title>
		<imprint>
			<biblScope unit="page" from="319" to="340" />
			<date type="published" when="1989">1989. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Design Methodology for Trust Cue Calibration in Cognitive Agents</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Freedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Parasuraman</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-07458-0_24</idno>
	</analytic>
	<monogr>
		<title level="m">Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Shumaker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lackey</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8525</biblScope>
			<biblScope unit="page" from="194" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">When Standard Is Not Enough: A Conceptualization of AI Systems&apos; Customization and its Antecedents</title>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Diaferia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Blohm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><forename type="middle">De</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianluca</forename><surname>Salviotti</surname></persName>
		</author>
		<ptr target="https://aisel.aisnet.org/icis2022/is_implement/is_implement/8" />
	</analytic>
	<monogr>
		<title level="m">ICIS 2022 Proceedings</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Chat AI: A Seamless Slurm-Native Solution for HPC-Based Services</title>
		<author>
			<persName><forename type="first">A</forename><surname>Doosthosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nolte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kunkel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2407.00110" />
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.05804[cs.CL</idno>
		<ptr target="https://arxiv.org/abs/2311.05804" />
		<title level="m">Model-as-a-Service (MaaS): A Survey</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Enhancing Trust in LLM Chatbots for Workplace Support Through User Experience Design and Prompt Engineering</title>
		<author>
			<persName><forename type="first">Zhiyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Birajdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tam</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><forename type="middle">Qing</forename><surname>Khoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chia-Fang</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yassi</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anbang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hridhay</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaditya</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">The Human Side of Service Engineering</title>
		<imprint>
			<biblScope unit="page">139</biblScope>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A value-oriented Artificial Intelligence-as-a-Service business plan using integrated tools and services</title>
		<author>
			<persName><forename type="first">Valiollah</forename><surname>Hajipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeid</forename><surname>Hekmat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Amini</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dajour.2023.100302</idno>
	</analytic>
	<monogr>
		<title level="j">Decision Analytics Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">100302</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exploring Factors Affecting the Adoption of Internet of Things Services</title>
		<author>
			<persName><forename type="first">Chin-Lung</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judy Chuan-Chuan</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1080/08874417.2016.1186524</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Information Systems</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="49" to="57" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weitao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihong</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangyin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haotian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianglong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3703155</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<date type="published" when="2024-11">2024. Nov. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Yue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S Y</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Lichao</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.11507[cs.CL</idno>
		<ptr target="https://arxiv.org/abs/2306.11507" />
		<title level="m">TrustGPT: A Benchmark for Trustworthy and Responsible Large Language Models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI&apos;s ChatGPT Plugins</title>
		<author>
			<persName><forename type="first">U</forename><surname>Iqbal</surname></persName>
			<affiliation>
				<orgName type="collaboration">AIES-24</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kohno</surname></persName>
			<affiliation>
				<orgName type="collaboration">AIES-24</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roesner</surname></persName>
			<affiliation>
				<orgName type="collaboration">AIES-24</orgName>
			</affiliation>
		</author>
		<idno type="DOI">10.1609/aies.v7i1.31664</idno>
	</analytic>
	<monogr>
		<title level="m">AAAI/ACM Conference on AI, Ethics, and Society</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Green</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Varshney</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ganapini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Renda</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="611" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">User Inference Attacks on Large Language Models</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Kandpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><surname>Pillutla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alina</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">A</forename><surname>Choquette-Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.emnlp-main.1014</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Mohit</forename><surname>Al-Onaizan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yun-Nung</forename><surname>Bansal</surname></persName>
		</editor>
		<editor>
			<persName><surname>Chen</surname></persName>
		</editor>
		<meeting>the 2024 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Miami, Florida, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="18238" to="18265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">I&apos;m categorizing LLM as a productivity tool</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kapania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.19876[cs.HC</idno>
		<ptr target="https://arxiv.org/abs/2403" />
	</analytic>
	<monogr>
		<title level="m">Examining ethics of LLM use in HCI research practices</title>
		<imprint>
			<date type="published" when="2024">2024. 19876</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>La Malfa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Weinhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Burnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shadbolt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wooldridge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.16573[cs.CL</idno>
		<ptr target="https://arxiv.org/abs/2309.16573" />
		<title level="m">Language Models as a Service: Overview of a New Paradigm and its Challenges</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Trust in automation: Designing for appropriate reliance</title>
		<author>
			<persName><forename type="first">D</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrina</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>See</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human factors</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="50" to="80" />
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Out of Context: Investigating the Bias and Fairness Concerns of &quot;Artificial Intelligence as a Service</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lewicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.1145/3544548.3581463</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Lins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Pandl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Teigeler</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12599-021-00708-w</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence as a Service. Business &amp; Information Systems Engineering</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="441" to="456" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The effect of familiar logos on trust of websites designed for small user interfaces</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Benjamin Lowry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryce</forename><forename type="middle">Eryn</forename><surname>Caine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th International Conference on Human-Computer Interaction (HCII 2005)</title>
		<meeting><address><addrLine>Las Vegas, Nevada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-07">2005. July</date>
			<biblScope unit="page" from="22" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">An Integrative Model of Organizational Trust</title>
		<author>
			<persName><surname>Mayer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995. 1995</date>
			<publisher>Academy of Management Review</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Sustainable Energy Behaviors through Green Information Systems: An Exploratory Study</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Titiana</forename><surname>Erti√∂</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ciara</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><surname>Kahma</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISTAS57930.2023.10306166</idno>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE International Symposium on Technology and Society (ISTAS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Corporate Social Responsibility: a Theory of the Firm Perspective</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Siegel</surname></persName>
		</author>
		<idno type="DOI">10.5465/amr.2001.4011987</idno>
	</analytic>
	<monogr>
		<title level="j">Academy of Management Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="117" to="127" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Corporate Social Responsibility: Strategic Implications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Wright</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-6486.2006.00580.x</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Management Studies</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Economics and Equity of Large Language Models: Health Care Perspective</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Salas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sezgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Klotzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Godambe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Limon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stephenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Taraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ehwerhemuepha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pandit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pandita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Golden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shippy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Oermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Martel</surname></persName>
		</author>
		<idno type="DOI">10.2196/64226</idno>
	</analytic>
	<monogr>
		<title level="j">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">64226</biblScope>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations</title>
		<author>
			<persName><forename type="first">Mahjabin</forename><surname>Nahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haeseung</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eun-Ju</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aiping</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongwon</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.03745[cs.HC</idno>
		<ptr target="https://arxiv.org/abs/2404.03745" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An initial model of trust in chatbots for customer service-findings from a questionnaire study</title>
		<author>
			<persName><forename type="first">Cecilie</forename><surname>Bertinussen Nordheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asbj√∏rn</forename><surname>F√∏lstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cato</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bj√∏rkli</forename></persName>
		</author>
		<idno type="DOI">10.1093/iwc/iwz022</idno>
	</analytic>
	<monogr>
		<title level="j">Interacting with Computers</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="317" to="335" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Evaluating the Impact of Hallucinations on User Trust and Satisfaction in LLM-based Systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Oelschlager</surname></persName>
		</author>
		<ptr target="https://urn.kb.se/resolve?urn=urn:nbn:se:lnu:diva-130539" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">130539</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Dissertation. Linnaeus University</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Evaluating Generative AI Literacy among HR Personnel to Develop a Framework for an Internal GPT</title>
		<author>
			<persName><forename type="first">Ira</forename><surname>Aurora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paavola</forename></persName>
		</author>
		<ptr target="https://example.com/your-thesis-url" />
	</analytic>
	<monogr>
		<title level="m">Faculty of Information Technology and Communication Sciences</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
		<respStmt>
			<orgName>Tampere University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">B</forename><surname>Parthasarathy</surname></persName>
			<affiliation>
				<orgName type="collaboration">CeADAR Connect Group</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zafar</surname></persName>
			<affiliation>
				<orgName type="collaboration">CeADAR Connect Group</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
			<affiliation>
				<orgName type="collaboration">CeADAR Connect Group</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shahid</surname></persName>
			<affiliation>
				<orgName type="collaboration">CeADAR Connect Group</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Identification of Trust Determinants in LLM Technology Using the DEMATEL Method</title>
		<author>
			<persName><forename type="first">Marta</forename><surname>Paw≈Çowska-Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Research Studies Journal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="694" to="711" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Increasing sustainable user behavior in digital products through transparent sustainability information</title>
		<author>
			<persName><forename type="first">Lydia</forename><surname>Penkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carla</forename><surname>Gr√∂schel</surname></persName>
		</author>
		<idno type="DOI">10.1145/3603555.3608573</idno>
	</analytic>
	<monogr>
		<title level="m">Mensch und Computer</title>
		<editor>
			<persName><forename type="first">Markus</forename><surname>Stolze</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Frieder</forename><surname>Loch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Matthias</forename><surname>Baldauf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Florian</forename><surname>Alt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christina</forename><surname>Schneegass</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Kosch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Teresa</forename><surname>Hirzle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shadan</forename><surname>Sadeghian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Fiona</forename><surname>Draxler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kenan</forename><surname>Bektas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Katrin</forename><surname>Lohan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pascal</forename><surname>Knierim</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2023">2023. 2023</date>
			<biblScope unit="page" from="359" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Foundations of Organizational Trust: What Matters to Different Stakeholders?</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pirson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Malhotra</surname></persName>
		</author>
		<idno type="DOI">10.1287/orsc.1100.0581</idno>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1087" to="1104" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Guidelines for Sustainable Online Behaviors. Green Computing Practices to Reduce the Digital Carbon Footprint</title>
		<author>
			<persName><forename type="first">S√≥nia</forename><surname>Rafael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matilde</forename><surname>Reis</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-47281-7{_}21</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Design and Digital Communication IV</title>
		<editor>
			<persName><forename type="first">Nuno</forename><surname>Martins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Daniel</forename><surname>Brand√£o</surname></persName>
		</editor>
		<meeting><address><addrLine>Nature Switzerland, Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="261" to="275" />
		</imprint>
	</monogr>
	<note>Springer Series in Design and Innovation</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Energy awareness, an important goal for empowering the end customer</title>
		<author>
			<persName><forename type="first">Mihai</forename><surname>Sanduleac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dorel</forename><surname>Stanescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmen</forename><surname>Stanescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><surname>Florea</surname></persName>
		</author>
		<idno type="DOI">10.1109/OPTIM.2017.7975034</idno>
	</analytic>
	<monogr>
		<title level="m">2017 International Conference on Optimization of Electrical and Electronic Equipment (OPTIM) &amp; 2017 Intl Aegean Conference on Electrical Machines and Power Electronics (ACEMP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="599" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">Nadine</forename><surname>Schlicker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alarith</forename><surname>Uhde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Sterz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Langer</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/qhwvx</idno>
		<title level="m">A Micro and Macro Perspective on Trustworthiness: Theoretical Underpinnings of the Trustworthiness Assessment Model (TrAM)</title>
		<imprint>
			<date type="published" when="2023-07">2023. 07 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">Sivan</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avi</forename><surname>Yaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Segev</forename><surname>Shlomov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.05391[cs.AI</idno>
		<ptr target="https://arxiv.org/abs/2308.05391" />
		<title level="m">Enhancing Trust in LLM-Based AI Automation Agents: New Considerations and Future Challenges</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Democratizing artificial intelligence: How no-code AI can leverage machine learning operations</title>
		<author>
			<persName><forename type="first">Leif</forename><surname>Sundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonny</forename><surname>Holmstr√∂m</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bushor.2023.04.003</idno>
	</analytic>
	<monogr>
		<title level="j">Business Horizons</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="777" to="788" />
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Awareness and Perceptions of ChatGPT Among Academics and Research Professionals in Riyadh, Saudi Arabia: Implications for Responsible AI Use</title>
		<author>
			<persName><forename type="first">W</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bashatah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Alharbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Bakarman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Asiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alqahtani</surname></persName>
		</author>
		<idno type="DOI">10.12659/MSM.944993</idno>
	</analytic>
	<monogr>
		<title level="j">Medical Science Monitor</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">944993</biblScope>
			<date type="published" when="2024-07">2024. Jul 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">What drives students toward ChatGPT? An investigation of the factors influencing adoption and usage of ChatGPT</title>
		<author>
			<persName><forename type="first">Chandan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiwari</forename></persName>
		</author>
		<idno type="DOI">10.1108/ITSE-04-2023-0061</idno>
	</analytic>
	<monogr>
		<title level="j">Interactive Technology and Smart Education</title>
		<editor>
			<persName><forename type="middle">Abass</forename><surname>Mohd</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shagufta</forename><surname>Bhat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rajaswaminathan</forename><surname>Tariq Khan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohammad</forename><surname>Subramaniam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Irshad</forename><surname>Atif</surname></persName>
		</editor>
		<editor>
			<persName><surname>Khan</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="333" to="355" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Trust in humanoid robots: implications for services marketing</title>
		<author>
			<persName><forename type="first">Michelle Me</forename><surname>Van Pinxteren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Ruud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Wetzels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>R√ºger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Pluymaekers</surname></persName>
		</author>
		<author>
			<persName><surname>Wetzels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Services Marketing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="507" to="518" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Artificial Intelligence in studies-use of ChatGPT and AI-based tools among students in Germany</title>
		<author>
			<persName><forename type="first">Von</forename><surname>J√∂rg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jana</forename><surname>Garrel</surname></persName>
		</author>
		<author>
			<persName><surname>Mayer</surname></persName>
		</author>
		<idno type="DOI">10.1057/s41599-023-02304-7</idno>
	</analytic>
	<monogr>
		<title level="j">Humanities and Social Sciences Communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">799</biblScope>
			<date type="published" when="2023-11-09">2023. 09 Nov 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Overtrust in the robotic age</title>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">R</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayanna</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="22" to="24" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.03408[cs.CL</idno>
		<ptr target="https://arxiv.org/abs/2402.03408" />
		<title level="m">A Framework for Effective Invocation Methods of Various LLM Services</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Linka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Muryshkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Opgenoorth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Langer</surname></persName>
		</author>
		<ptr target="http://arxiv.org/pdf/2403.00039v1" />
		<title level="m">FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Magdalena</forename><surname>Wischnewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Kr√§mer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Doebler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Beisemann</surname></persName>
		</author>
		<ptr target="https://osf.io/j7wk8" />
		<title level="m">Development of a new Trust in AI scale</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohan</forename><surname>Kankanhalli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.11817[cs.CL</idno>
		<ptr target="https://arxiv.org/abs/2401.11817" />
		<title level="m">Hallucination is Inevitable: An Innate Limitation of Large Language Models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Reflections on Enhancing Higher Education Classroom Effectiveness Through the Introduction of Large Language Models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.53964/jmer.2024019</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Modern Education Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Application of large language models in professional fields</title>
		<author>
			<persName><forename type="first">Mingji</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Senliang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoyu</forename><surname>Dai</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCTech60480.2023.00033</idno>
	</analytic>
	<monogr>
		<title level="m">2023 11th International Conference on Information Systems and Computing Technology</title>
		<meeting><address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="142" to="146" />
		</imprint>
	</monogr>
	<note>ISCTech</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Justyna</forename><surname>≈Åapi≈Ñska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iwona</forename><surname>Escher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joanna</forename><surname>G√≥rka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agata</forename><surname>Sudolska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawe≈Ç</forename><surname>Brzustewicz</surname></persName>
		</author>
		<idno type="DOI">10.3390/en14071942</idno>
	</analytic>
	<monogr>
		<title level="j">Employees&apos; Trust in Artificial Intelligence in Companies: The Case of Energy and Chemical Industries in Poland. Energies</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
